{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naemililia/masterthesis/blob/main/train_contrastive_learning_eurosat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcgvUlriQQBG"
      },
      "source": [
        "I am taking the dataloaders etc from my pretext task\n",
        "\n",
        "the contrastive learning code for simclr I am taking from here:\n",
        "https://medium.com/the-owl/simclr-in-pytorch-5f290cb11dd7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7Go-hVflaxA"
      },
      "source": [
        "## 0. Installations and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezLT1kpjlkK_",
        "outputId": "9eb48005-7c6d-4b62-f38a-cb7a344e4910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.10-cp310-cp310-manylinux2014_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.6.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.10 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx9ajhgplqsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c548375c-aae1-461e-f8a4-e8c9bcd1689d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcjJJJ9fv4bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4299c6e5-27e8-4439-e174-1ae70dc41f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home\n"
          ]
        }
      ],
      "source": [
        "# create a folder for model checkpoints\n",
        "\n",
        "%cd /home\n",
        "!sudo mkdir checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EsQnb-2lutv"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil, time, requests, copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import csv\n",
        "from PIL import Image\n",
        "from scipy.ndimage import zoom\n",
        "import torch\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from matplotlib import pyplot as plt\n",
        "#import segmentation_models_pytorch as smp\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-unhBdTmMHx"
      },
      "source": [
        "## 2. Prepare the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJcGvw1MmLao"
      },
      "outputs": [],
      "source": [
        "# the labels are saved on my google drive\n",
        "BUILT_path_eurosat = '/content/drive/MyDrive/eurosat_BUILT'\n",
        "LC_path_eurosat = '/content/drive/MyDrive/eurosat_LC'\n",
        "\n",
        "\n",
        "test_train_images_path = '/content/drive/MyDrive/EuroSAT_MS_test'\n",
        "train_images_path = '/content/drive/MyDrive/EuroSAT_MS'\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WsAm_4EXmTYi",
        "outputId": "b910cb56-7e5e-46af-9fe1-cb350ae06f0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      0  \\\n",
              "0     HerbaceousVegetation/HerbaceousVegetation_1170...   \n",
              "1                        Residential/Residential_59.tif   \n",
              "2                                  River/River_1162.tif   \n",
              "3     HerbaceousVegetation/HerbaceousVegetation_1205...   \n",
              "4                          AnnualCrop/AnnualCrop_75.tif   \n",
              "...                                                 ...   \n",
              "7123  HerbaceousVegetation/HerbaceousVegetation_151.tif   \n",
              "7124               PermanentCrop/PermanentCrop_1087.tif   \n",
              "7125                       Industrial/Industrial_65.tif   \n",
              "7126  HerbaceousVegetation/HerbaceousVegetation_404.tif   \n",
              "7127                PermanentCrop/PermanentCrop_373.tif   \n",
              "\n",
              "                                        1  \n",
              "0     HerbaceousVegetation_1170_label.npy  \n",
              "1                Residential_59_label.npy  \n",
              "2                    River_1162_label.npy  \n",
              "3     HerbaceousVegetation_1205_label.npy  \n",
              "4                 AnnualCrop_75_label.npy  \n",
              "...                                   ...  \n",
              "7123   HerbaceousVegetation_151_label.npy  \n",
              "7124         PermanentCrop_1087_label.npy  \n",
              "7125              Industrial_65_label.npy  \n",
              "7126   HerbaceousVegetation_404_label.npy  \n",
              "7127          PermanentCrop_373_label.npy  \n",
              "\n",
              "[7128 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b38e4638-f609-46c7-acd0-e1cdd4cbd620\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HerbaceousVegetation/HerbaceousVegetation_1170...</td>\n",
              "      <td>HerbaceousVegetation_1170_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Residential/Residential_59.tif</td>\n",
              "      <td>Residential_59_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>River/River_1162.tif</td>\n",
              "      <td>River_1162_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HerbaceousVegetation/HerbaceousVegetation_1205...</td>\n",
              "      <td>HerbaceousVegetation_1205_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AnnualCrop/AnnualCrop_75.tif</td>\n",
              "      <td>AnnualCrop_75_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7123</th>\n",
              "      <td>HerbaceousVegetation/HerbaceousVegetation_151.tif</td>\n",
              "      <td>HerbaceousVegetation_151_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7124</th>\n",
              "      <td>PermanentCrop/PermanentCrop_1087.tif</td>\n",
              "      <td>PermanentCrop_1087_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7125</th>\n",
              "      <td>Industrial/Industrial_65.tif</td>\n",
              "      <td>Industrial_65_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7126</th>\n",
              "      <td>HerbaceousVegetation/HerbaceousVegetation_404.tif</td>\n",
              "      <td>HerbaceousVegetation_404_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7127</th>\n",
              "      <td>PermanentCrop/PermanentCrop_373.tif</td>\n",
              "      <td>PermanentCrop_373_label.npy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7128 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b38e4638-f609-46c7-acd0-e1cdd4cbd620')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b38e4638-f609-46c7-acd0-e1cdd4cbd620 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b38e4638-f609-46c7-acd0-e1cdd4cbd620');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4fd71d94-cde7-4fa0-a145-0ac26ceba298\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fd71d94-cde7-4fa0-a145-0ac26ceba298')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4fd71d94-cde7-4fa0-a145-0ac26ceba298 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d1733521-facf-4baf-8db6-7548ec6325f6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d1733521-facf-4baf-8db6-7548ec6325f6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 7128,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7128,\n        \"samples\": [\n          \"Pasture/Pasture_933.tif\",\n          \"HerbaceousVegetation/HerbaceousVegetation_1516.tif\",\n          \"HerbaceousVegetation/HerbaceousVegetation_2402.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7128,\n        \"samples\": [\n          \"Pasture_933_label.npy\",\n          \"HerbaceousVegetation_1516_label.npy\",\n          \"HerbaceousVegetation_2402_label.npy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/EuroSAT_MS/pretext_train_data.csv', header=None)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KPU9gbrcmVON",
        "outputId": "125889fb-8966-42ef-c569-d84617203761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      0  \\\n",
              "0                                 Forest/Forest_913.tif   \n",
              "1                              Highway/Highway_1488.tif   \n",
              "2                              SeaLake/SeaLake_1598.tif   \n",
              "3     HerbaceousVegetation/HerbaceousVegetation_2796...   \n",
              "4                              Highway/Highway_1127.tif   \n",
              "...                                                 ...   \n",
              "1777  HerbaceousVegetation/HerbaceousVegetation_179.tif   \n",
              "1778                           SeaLake/SeaLake_1060.tif   \n",
              "1779                           Pasture/Pasture_1008.tif   \n",
              "1780                             Forest/Forest_1329.tif   \n",
              "1781                   Residential/Residential_1192.tif   \n",
              "\n",
              "                                        1  \n",
              "0                    Forest_913_label.npy  \n",
              "1                  Highway_1488_label.npy  \n",
              "2                  SeaLake_1598_label.npy  \n",
              "3     HerbaceousVegetation_2796_label.npy  \n",
              "4                  Highway_1127_label.npy  \n",
              "...                                   ...  \n",
              "1777   HerbaceousVegetation_179_label.npy  \n",
              "1778               SeaLake_1060_label.npy  \n",
              "1779               Pasture_1008_label.npy  \n",
              "1780                Forest_1329_label.npy  \n",
              "1781           Residential_1192_label.npy  \n",
              "\n",
              "[1782 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b28452cb-fd5a-4bb1-873b-2d26b7109af3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Forest/Forest_913.tif</td>\n",
              "      <td>Forest_913_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Highway/Highway_1488.tif</td>\n",
              "      <td>Highway_1488_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SeaLake/SeaLake_1598.tif</td>\n",
              "      <td>SeaLake_1598_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HerbaceousVegetation/HerbaceousVegetation_2796...</td>\n",
              "      <td>HerbaceousVegetation_2796_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Highway/Highway_1127.tif</td>\n",
              "      <td>Highway_1127_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1777</th>\n",
              "      <td>HerbaceousVegetation/HerbaceousVegetation_179.tif</td>\n",
              "      <td>HerbaceousVegetation_179_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1778</th>\n",
              "      <td>SeaLake/SeaLake_1060.tif</td>\n",
              "      <td>SeaLake_1060_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>Pasture/Pasture_1008.tif</td>\n",
              "      <td>Pasture_1008_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1780</th>\n",
              "      <td>Forest/Forest_1329.tif</td>\n",
              "      <td>Forest_1329_label.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1781</th>\n",
              "      <td>Residential/Residential_1192.tif</td>\n",
              "      <td>Residential_1192_label.npy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1782 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b28452cb-fd5a-4bb1-873b-2d26b7109af3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b28452cb-fd5a-4bb1-873b-2d26b7109af3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b28452cb-fd5a-4bb1-873b-2d26b7109af3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2ab1a5a-c1cf-459f-a165-60da654e9dee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2ab1a5a-c1cf-459f-a165-60da654e9dee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2ab1a5a-c1cf-459f-a165-60da654e9dee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6ab78b2f-a40a-42be-974f-c9e9bf195ebb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('val_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6ab78b2f-a40a-42be-974f-c9e9bf195ebb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('val_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_data",
              "summary": "{\n  \"name\": \"val_data\",\n  \"rows\": 1782,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1782,\n        \"samples\": [\n          \"Forest/Forest_1188.tif\",\n          \"PermanentCrop/PermanentCrop_1810.tif\",\n          \"Residential/Residential_2174.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1782,\n        \"samples\": [\n          \"Forest_1188_label.npy\",\n          \"PermanentCrop_1810_label.npy\",\n          \"Residential_2174_label.npy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "val_data = pd.read_csv('/content/drive/MyDrive/EuroSAT_MS/pretext_val_data.csv', header=None)\n",
        "val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82KjmG-UmeOr"
      },
      "outputs": [],
      "source": [
        "# functions needed for the loading of the data\n",
        "\n",
        "def getArrFlood(fname):\n",
        "    \"\"\"Load .tif data into array\"\"\"\n",
        "    return rasterio.open(fname).read()\n",
        "\n",
        "def iloader(path):\n",
        "    image = np.asarray((io.imread(path))/5000,dtype='float32')\n",
        "    return image.transpose(2,0,1)\n",
        "\n",
        "def download_data_from_list_singlelabel(l):\n",
        "    \"\"\"\n",
        "    Download and prepare training data from file list.\n",
        "\n",
        "    Gets training_list from load_flood_train_data\n",
        "    downloads/reads each of the files (image and the 1 label) for each row\n",
        "    returns a list of tuples, where teh first entry is the array of the image, and the second is a list of the label array\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    flood_data = []\n",
        "    for (im_fname, mask_fname1) in l:\n",
        "        if os.path.exists(mask_fname1):\n",
        "          # Load the satelite image with rasterio (it is a .tif)\n",
        "          arr_x = iloader(im_fname)\n",
        "\n",
        "          # Load masks from different roots using numpy\n",
        "          arr_y1 = np.load(mask_fname1)\n",
        "\n",
        "          if i % 100 == 0:\n",
        "            print(im_fname)\n",
        "          i += 1\n",
        "\n",
        "          flood_data.append((arr_x, [arr_y1]))\n",
        "\n",
        "    return flood_data\n",
        "\n",
        "def load_flood_train_data_multilabel(input_root, label_root_1):\n",
        "    \"\"\"\n",
        "    Load training data including single label defined above in step 2 from specified roots.\n",
        "\n",
        "    creates training_list that it hands over to next function: download_flood_water_data_from_list\n",
        "\n",
        "    training_list has length of the training dataset csv + 1 (because it also creates path for the header, this will be discarded later on as it will not pass the .is_file() check\n",
        "    each entry of the training_list is a tuple with 2 paths: image_path, label_path1\n",
        "    \"\"\"\n",
        "    fname = \"/content/drive/MyDrive/EuroSAT_MS/pretext_train_data.csv\" # train_data_subset / test_train_filenames / S1weak_train_filenames_final\n",
        "    training_files = []\n",
        "    with open(fname) as f:\n",
        "        for line in csv.reader(f):\n",
        "            image_path = os.path.join(input_root, line[0])\n",
        "            label_path1 = os.path.join(label_root_1, line[1])\n",
        "            training_files.append((image_path, label_path1))\n",
        "\n",
        "    return  download_data_from_list_singlelabel(training_files)\n",
        "\n",
        "def load_flood_valid_data_multilabel(input_root, label_root_1):\n",
        "    \"\"\"\n",
        "    Load validation data including label from specified roots.\n",
        "\n",
        "    creates validation_list that it hands over to next function: download_flood_water_data_from_list\n",
        "\n",
        "    validation_list has length of the validation dataset csv + 1 (because it also creates path for the header, this will be discarded later on as it will not pass the .is_file() check\n",
        "    each entry of the validation_list is a tuple with 2 paths: image_path, label_path1\n",
        "    \"\"\"\n",
        "    fname = \"/content/drive/MyDrive/EuroSAT_MS/pretext_val_data.csv\" # val_data_subset / test_val_filenames / S1weak_val_filenames_final\n",
        "    val_files = []\n",
        "    with open(fname) as f:\n",
        "        for line in csv.reader(f):\n",
        "            image_path = os.path.join(input_root, line[0])\n",
        "            label_path1 = os.path.join(label_root_1, line[1])\n",
        "            val_files.append((image_path, label_path1))\n",
        "\n",
        "    return download_data_from_list_singlelabel(val_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H_KHJWtmjiP"
      },
      "outputs": [],
      "source": [
        "# functions needed for the processing of the labels\n",
        "\n",
        "quantiles_built = [1.000e+00, 9.200e+01, 7.140e+02, 1.532e+03, 2.165e+03, 6.375e+03]\n",
        "\n",
        "def make_BUILT_categorical(array_label):\n",
        "  categorical_label = np.digitize(array_label, quantiles_built, right=True)\n",
        "\n",
        "  categorical_label = categorical_label.astype(np.uint8)\n",
        "  return categorical_label\n",
        "\n",
        "# possible LC label values\n",
        "possible_label_vals = [20,  30,  40,  50,  60,  70,  80,  90, 100, 111, 114, 115, 116,\n",
        "       121, 124, 125, 126, 200]\n",
        "\n",
        "# create a mapping dictioanry\n",
        "label_to_class_id = {label: idx for idx, label in enumerate(possible_label_vals)}\n",
        "vectorized_map = np.vectorize(label_to_class_id.get, otypes=[np.uint32])\n",
        "\n",
        "def class_id_transformation_LC(array_label):\n",
        "  \"\"\"\n",
        "  Transforms all LC label values to class_id values. The class IDs are defined above\n",
        "  \"\"\"\n",
        "  return vectorized_map(array_label)\n",
        "\n",
        "def resize_the_label_for_eurosat(array_label):\n",
        "  \"\"\"\n",
        "  Resizes each label to the Senfloods image size of 512 x 512.\n",
        "  BUILT & POP are resized with order = 1, a liniear interpolation\n",
        "  LC is resized with order = 0, a nearest neighbor technique\n",
        "  \"\"\"\n",
        "  original_shape = array_label.shape\n",
        "\n",
        "  new_shape = (64, 64) # this is a senfloods specific function\n",
        "\n",
        "  zoom_factors = [n / o for n, o in zip(new_shape, original_shape)]\n",
        "\n",
        "  resized_label = zoom(array_label, zoom_factors, order = 0)\n",
        "\n",
        "  return resized_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG-zlAfZmznp"
      },
      "outputs": [],
      "source": [
        "# the actual processing function for training data\n",
        "\n",
        "def processAndAugmentMultipleLabels(data):\n",
        "  \"\"\"\n",
        "  Preprocessing of training data (images and labels).\n",
        "\n",
        "  Labels are scaled and resized.\n",
        "\n",
        "  Random cropping to 256 x 256 and horizontal & vertical flipping of images & labels.\n",
        "\n",
        "  Normalization of images with mean and standard deviation.\n",
        "\n",
        "  Stacking of tensor image channels (2, 256, 256) and tensor labels (2, 256, 256)\n",
        "  \"\"\"\n",
        "  (x, ys) = data\n",
        "  im = x.copy() # (13,64,64), array\n",
        "  labels = [y.copy() for y in ys] # list of 1 array, shape 6,10\n",
        "  # # depening on AUXILIARY-DATASOURCE do different preprocessing\n",
        "  # # hier findet label processing statt\n",
        "\n",
        "  if AUXILIARY_DATASOURCE == 'BUILT':\n",
        "    #labels[0] = log_scale_label(labels[0])\n",
        "    #labels[0] = min_max_scale_BUILT(labels[0])\n",
        "    labels[0] = make_BUILT_categorical(labels[0])\n",
        "    labels[0] = resize_the_label_for_eurosat(labels[0])\n",
        "  elif AUXILIARY_DATASOURCE == 'LC':\n",
        "    labels[0] = class_id_transformation_LC(labels[0])\n",
        "    labels[0] = resize_the_label_for_eurosat(labels[0]) # jetzt shape 64,64\n",
        "\n",
        "  # Convert to PIL for easier transforms\n",
        "  im1 = Image.fromarray(im[0])\n",
        "  im2 = Image.fromarray(im[1])\n",
        "  im3 = Image.fromarray(im[2])\n",
        "  im4 = Image.fromarray(im[3])\n",
        "  im5 = Image.fromarray(im[4])\n",
        "  im6 = Image.fromarray(im[5])\n",
        "  im7 = Image.fromarray(im[6])\n",
        "  im8 = Image.fromarray(im[7])\n",
        "  im9 = Image.fromarray(im[8])\n",
        "  im10 = Image.fromarray(im[9])\n",
        "  im11 = Image.fromarray(im[10])\n",
        "  im12 = Image.fromarray(im[11])\n",
        "  im13 = Image.fromarray(im[12])\n",
        "  labels = [Image.fromarray(label.squeeze()) for label in labels]\n",
        "\n",
        "  # # do the random rotation (but the same one to all)\n",
        "  # random_int = random.randint(-3,3)\n",
        "  # angle = random_int * 90\n",
        "\n",
        "  # im1 = im1.rotate(angle)\n",
        "  # im2 = im2.rotate(angle)\n",
        "  # im3 = im3.rotate(angle)\n",
        "  # im4 = im4.rotate(angle)\n",
        "  # im5 = im5.rotate(angle)\n",
        "  # im6 = im6.rotate(angle)\n",
        "  # im7 = im7.rotate(angle)\n",
        "  # im8 = im8.rotate(angle)\n",
        "  # im9 = im9.rotate(angle)\n",
        "  # im10 = im10.rotate(angle)\n",
        "  # im11 = im11.rotate(angle)\n",
        "  # im12 = im12.rotate(angle)\n",
        "  # im13 = im13.rotate(angle)\n",
        "\n",
        "\n",
        "  # if random.random() > 0.5:\n",
        "  #     im1 = F.hflip(im1)\n",
        "  #     im2 = F.hflip(im2)\n",
        "  #     im3 = F.hflip(im3)\n",
        "  #     im4 = F.hflip(im4)\n",
        "  #     im5 = F.hflip(im5)\n",
        "  #     im6 = F.hflip(im6)\n",
        "  #     im7 = F.hflip(im7)\n",
        "  #     im8 = F.hflip(im8)\n",
        "  #     im9 = F.hflip(im9)\n",
        "  #     im10 = F.hflip(im10)\n",
        "  #     im11 = F.hflip(im11)\n",
        "  #     im12 = F.hflip(im12)\n",
        "  #     im13 = F.hflip(im13)\n",
        "  #     labels = [F.hflip(label) for label in labels]\n",
        "  # if random.random() > 0.5:\n",
        "  #     im1 = F.vflip(im1)\n",
        "  #     im2 = F.vflip(im2)\n",
        "  #     im3 = F.vflip(im3)\n",
        "  #     im4 = F.vflip(im4)\n",
        "  #     im5 = F.vflip(im5)\n",
        "  #     im6 = F.vflip(im6)\n",
        "  #     im7 = F.vflip(im7)\n",
        "  #     im8 = F.vflip(im8)\n",
        "  #     im9 = F.vflip(im9)\n",
        "  #     im10 = F.vflip(im10)\n",
        "  #     im11 = F.vflip(im11)\n",
        "  #     im12 = F.vflip(im12)\n",
        "  #     im13 = F.vflip(im13)\n",
        "  #     labels = [F.vflip(label) for label in labels]\n",
        "\n",
        "  norm = transforms.Normalize([0.2703, 0.2232, 0.2084, 0.1894, 0.2401, 0.4013, 0.4757, 0.4612, 0.1468,\n",
        "          0.0024, 0.3646, 0.2237, 0.5209], [0.0484, 0.0663, 0.0787, 0.1184, 0.1126, 0.1717, 0.2170, 0.2235, 0.0811,\n",
        "          0.0009, 0.2001, 0.1517, 0.2461])\n",
        "  im = torch.stack([transforms.ToTensor()(im1).squeeze(),\n",
        "                    transforms.ToTensor()(im2).squeeze(),\n",
        "                    transforms.ToTensor()(im3).squeeze(),\n",
        "                    transforms.ToTensor()(im4).squeeze(),\n",
        "                    transforms.ToTensor()(im5).squeeze(),\n",
        "                    transforms.ToTensor()(im6).squeeze(),\n",
        "                    transforms.ToTensor()(im7).squeeze(),\n",
        "                    transforms.ToTensor()(im8).squeeze(),\n",
        "                    transforms.ToTensor()(im9).squeeze(),\n",
        "                    transforms.ToTensor()(im10).squeeze(),\n",
        "                    transforms.ToTensor()(im11).squeeze(),\n",
        "                    transforms.ToTensor()(im12).squeeze(),\n",
        "                    transforms.ToTensor()(im13).squeeze(),\n",
        "                    ]) # tensor of size (13, 64, 64) (or 256x256 if we crop), still same values\n",
        "\n",
        "  #im = CustomToTensor(im) # tensor of size (2, 512, 512) (or 256x256 if we crop), still same values\n",
        "  im = norm(im)\n",
        "  labels = [torch.tensor(np.array(label)) for label in labels] # hier das , dtype=torch.long würde alles zu ints machen --> dann verliert aber auch built und pop jede information\n",
        "  labels = torch.stack(labels) # torch.size(1, 64, 64)\n",
        "\n",
        "  return im, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i20TdFLnPBy"
      },
      "outputs": [],
      "source": [
        "# the processing function for validation data (similar to training processing)\n",
        "# there is a different version of this in the train_pretext_prep file\n",
        "\n",
        "def processTestImMultipleLabels_likeTrain(data):\n",
        "  \"\"\"\n",
        "  Preprocessing of validation data (images and labels).\n",
        "\n",
        "  Labels are scaled and resized.\n",
        "\n",
        "  Non-random cropping to the middle 256 x 256 image.\n",
        "\n",
        "  No random flipping either\n",
        "\n",
        "  Normalization of images with mean and standard deviation of training data.\n",
        "\n",
        "  Stacking of tensor image channels (2, 256, 256) and tensor labels (3, 256, 256)\n",
        "  \"\"\"\n",
        "  (x,ys) = data\n",
        "  im = x.copy() # (13,64,64), array\n",
        "  labels = [y.copy() for y in ys] # list of 1 array, shape 6,10\n",
        "  # # depening on AUXILIARY-DATASOURCE do different preprocessing\n",
        "  # # hier findet label processing statt\n",
        "\n",
        "  if AUXILIARY_DATASOURCE == 'BUILT':\n",
        "    #labels[0] = log_scale_label(labels[0])\n",
        "    #labels[0] = min_max_scale_BUILT(labels[0])\n",
        "    labels[0] = make_BUILT_categorical(labels[0])\n",
        "    labels[0] = resize_the_label_for_eurosat(labels[0])\n",
        "  elif AUXILIARY_DATASOURCE == 'LC':\n",
        "    labels[0] = class_id_transformation_LC(labels[0])\n",
        "    labels[0] = resize_the_label_for_eurosat(labels[0]) # jetzt shape 64,64\n",
        "\n",
        "  # Convert to PIL for easier transforms\n",
        "  im1 = Image.fromarray(im[0])\n",
        "  im2 = Image.fromarray(im[1])\n",
        "  im3 = Image.fromarray(im[2])\n",
        "  im4 = Image.fromarray(im[3])\n",
        "  im5 = Image.fromarray(im[4])\n",
        "  im6 = Image.fromarray(im[5])\n",
        "  im7 = Image.fromarray(im[6])\n",
        "  im8 = Image.fromarray(im[7])\n",
        "  im9 = Image.fromarray(im[8])\n",
        "  im10 = Image.fromarray(im[9])\n",
        "  im11 = Image.fromarray(im[10])\n",
        "  im12 = Image.fromarray(im[11])\n",
        "  im13 = Image.fromarray(im[12])\n",
        "  labels = [Image.fromarray(label.squeeze()) for label in labels]\n",
        "\n",
        "  norm = transforms.Normalize([0.2703, 0.2232, 0.2084, 0.1894, 0.2401, 0.4013, 0.4757, 0.4612, 0.1468,\n",
        "          0.0024, 0.3646, 0.2237, 0.5209], [0.0484, 0.0663, 0.0787, 0.1184, 0.1126, 0.1717, 0.2170, 0.2235, 0.0811,\n",
        "          0.0009, 0.2001, 0.1517, 0.2461])\n",
        "  im = torch.stack([transforms.ToTensor()(im1).squeeze(),\n",
        "                    transforms.ToTensor()(im2).squeeze(),\n",
        "                    transforms.ToTensor()(im3).squeeze(),\n",
        "                    transforms.ToTensor()(im4).squeeze(),\n",
        "                    transforms.ToTensor()(im5).squeeze(),\n",
        "                    transforms.ToTensor()(im6).squeeze(),\n",
        "                    transforms.ToTensor()(im7).squeeze(),\n",
        "                    transforms.ToTensor()(im8).squeeze(),\n",
        "                    transforms.ToTensor()(im9).squeeze(),\n",
        "                    transforms.ToTensor()(im10).squeeze(),\n",
        "                    transforms.ToTensor()(im11).squeeze(),\n",
        "                    transforms.ToTensor()(im12).squeeze(),\n",
        "                    transforms.ToTensor()(im13).squeeze(),\n",
        "                    ]) # tensor of size (13, 64, 64) (or 256x256 if we crop), still same values\n",
        "\n",
        "  #im = CustomToTensor(im) # tensor of size (2, 512, 512) (or 256x256 if we crop), still same values\n",
        "  im = norm(im)\n",
        "  labels = [torch.tensor(np.array(label)) for label in labels] # hier das , dtype=torch.long würde alles zu ints machen --> dann verliert aber auch built und pop jede information\n",
        "  labels = torch.stack(labels) # torch.size(1, 64, 64)\n",
        "\n",
        "  return im, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScyfFN_znK-4"
      },
      "outputs": [],
      "source": [
        "# the dataset class i am using\n",
        "class InMemoryDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, data_list, preprocess_func):\n",
        "    self.data_list = data_list\n",
        "    self.preprocess_func = preprocess_func\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.preprocess_func(self.data_list[i])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUXILIARY_DATASOURCE = 'LC' # / 'LC'"
      ],
      "metadata": {
        "id": "FjG45iH99qtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHoaPANSng37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc85eb41-25a7-4676-de09-1b49c3998888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_1170.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_2931.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_1642.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_2519.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_1340.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_244.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_1446.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_1912.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/River/River_510.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_2576.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_1988.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/River/River_1956.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_178.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_35.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_1301.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/River/River_2487.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_2274.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_2162.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_2361.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_1320.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_2163.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_2244.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_452.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/AnnualCrop/AnnualCrop_289.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_1953.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/River/River_2463.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_1426.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_537.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_2085.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_111.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_2068.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_3.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_614.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_617.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_2373.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_1713.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_1768.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_2685.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_359.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/River/River_439.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_2364.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Pasture/Pasture_1265.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/River/River_422.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_777.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_708.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/AnnualCrop/AnnualCrop_1487.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_1785.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_926.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_2001.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_2430.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_2540.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_1004.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_1034.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_2548.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_1444.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_256.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_307.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_2058.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_2904.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_2410.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_1735.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_2223.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_200.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_1516.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_837.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_1584.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/River/River_1613.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_344.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_1141.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_2036.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_2429.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_1884.tif\n"
          ]
        }
      ],
      "source": [
        "# creating the dataloaders\n",
        "from skimage import io\n",
        "train_data = load_flood_train_data_multilabel(train_images_path, LC_path_eurosat) # test_train_images_path, path_to_data\n",
        "train_dataset = InMemoryDataset(train_data, processAndAugmentMultipleLabels)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, sampler=None,\n",
        "                  batch_sampler=None, num_workers=0, collate_fn=None,\n",
        "                  pin_memory=True, drop_last=True, timeout=0,\n",
        "                  worker_init_fn=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP1tJNCkn6yQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5607ce0-ba49-4d33-9d42-9340ac1bcd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_913.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Pasture/Pasture_77.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_1345.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_1198.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_1142.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/AnnualCrop/AnnualCrop_45.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_2030.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/SeaLake/SeaLake_1816.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_476.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Highway/Highway_575.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Forest/Forest_533.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/AnnualCrop/AnnualCrop_332.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/HerbaceousVegetation/HerbaceousVegetation_1682.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Industrial/Industrial_1395.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_1420.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/PermanentCrop/PermanentCrop_139.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_624.tif\n",
            "/content/drive/MyDrive/EuroSAT_MS/Residential/Residential_1979.tif\n"
          ]
        }
      ],
      "source": [
        "valid_data = load_flood_valid_data_multilabel(train_images_path, LC_path_eurosat) # test_val_images_path, path_to_data\n",
        "valid_dataset = InMemoryDataset(valid_data, processTestImMultipleLabels_likeTrain)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=256, shuffle=True, sampler=None,\n",
        "                  batch_sampler=None, num_workers=0, #collate_fn=lambda x: (torch.cat([a[0] for a in x], 0), torch.cat([a[1] for a in x], 0)),\n",
        "                  pin_memory=True, drop_last=True, timeout=0,\n",
        "                  worker_init_fn=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA7DSEjQoT7E"
      },
      "source": [
        "## 3. Define the network, loss function & optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36YMIfWPS9DZ"
      },
      "source": [
        "SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7urjf7jaIifi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(ProjectionHead, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512), # 512 ist eine intermediate dimension um etwas komplexere representations zu lernen\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "class TwoStrandModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwoStrandModel, self).__init__()\n",
        "        # Initialize ResNet-18 models, each input type gets its own encoder (but they start out to be the same one)\n",
        "        self.encoder_im1 = self.create_encoder(num_input_channels=13)  # for EuroSAT\n",
        "        self.encoder_built = self.create_encoder(num_input_channels=1) # for BUILT or POP (might need a new model for LC, but actually not, because all teh classes are in the one channel)\n",
        "\n",
        "        # Dimension of the ResNet-50 output before the fully connected layer\n",
        "        feature_dim = 512 # 512 for resnet-18, 2048 for resnet50\n",
        "\n",
        "        # Projection heads\n",
        "        self.projection_im1 = ProjectionHead(input_dim=feature_dim, output_dim=128) # Jain, Wilson also use 128\n",
        "        self.projection_built = ProjectionHead(input_dim=feature_dim, output_dim=128) # Jain, Wilson also use 128\n",
        "\n",
        "    def create_encoder(self, num_input_channels):\n",
        "        encoder = models.resnet18(weights='IMAGENET1K_V1') # pretrained on Imagenet might have a good effect and could counteract our single GPU disadvantage (der medium article lässt hoffen)\n",
        "        encoder.conv1 = nn.Conv2d(num_input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        # Remove the final fully connected layer\n",
        "        encoder.fc = nn.Identity()\n",
        "        return encoder\n",
        "\n",
        "    def forward(self, im1, built):\n",
        "\n",
        "        if built.dim() == 3 and built.shape[1] != 1:\n",
        "            built = built.unsqueeze(1)  # Add a channel dimension\n",
        "\n",
        "        # Pass inputs through their respective encoders\n",
        "        features_im1 = self.encoder_im1(im1)\n",
        "        features_built = self.encoder_built(built)\n",
        "\n",
        "        # Pass through projection heads\n",
        "        projected_im1 = self.projection_im1(features_im1)\n",
        "        projected_built = self.projection_built(features_built)\n",
        "\n",
        "        return projected_im1, projected_built\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# model = TwoStrandModel()\n",
        "# criterion = ContrastiveLoss()\n",
        "\n",
        "# # Model forward pass\n",
        "# projected_im1, projected_built = model(im1, built)\n",
        "\n",
        "# # Compute loss\n",
        "# loss = criterion(projected_im1, projected_built)\n",
        "# print('Loss:', loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1x26BrCmx9n"
      },
      "outputs": [],
      "source": [
        "net = TwoStrandModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7yfu-usV30V"
      },
      "source": [
        "##Loss function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXEkDO85Vji_"
      },
      "outputs": [],
      "source": [
        "# loss acc. to medium article\n",
        "class SimCLR_Loss(nn.Module):\n",
        "    def __init__(self, batch_size, temperature):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.temperature = temperature\n",
        "\n",
        "        # this is supposed to identify positive pairs\n",
        "        self.mask = self.mask_correlated_samples(batch_size)\n",
        "\n",
        "        # chatgpt: 'This sets up the cross-entropy loss for comparing the logits from concatenated positive and negative sample similarities against labels that are all zeros (indicating the first class is the correct class for all positive samples).'\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "\n",
        "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
        "\n",
        "    def mask_correlated_samples(self, batch_size):\n",
        "        # we have N entries in a batch, and we have two views of the same location: SAR and the aux info\n",
        "        N = 2 * batch_size\n",
        "\n",
        "        # chatgpt: Creates an N x N mask initialized to True, to later exclude specific pairs from being considered as negative samples.\n",
        "        mask = torch.ones((N, N), dtype=bool)\n",
        "\n",
        "        # chatgpt: Sets the diagonal elements of the mask to False (0 in a boolean context), ensuring that each example is not compared with itself.\n",
        "        mask = mask.fill_diagonal_(0)\n",
        "\n",
        "        # These lines set the mask to False for each pair of correlated samples (i.e., each original and its augmented version), ensuring they are not considered as negative pairs.\n",
        "        for i in range(batch_size):\n",
        "            mask[i, batch_size + i] = 0\n",
        "            mask[batch_size + i, i] = 0\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "\n",
        "        N = 2 * self.batch_size\n",
        "\n",
        "        # chatgpt: results in 2N total embeddings\n",
        "        z = torch.cat((z_i, z_j), dim=0)\n",
        "\n",
        "        # chaptgpt: Calculates the cosine similarity matrix for all pairs of embeddings, scaled by the temperature. unsqueeze is used to make the tensors compatible for pairwise similarity computation.\n",
        "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
        "\n",
        "        # chatgpt: Extracts the similarities of correlated (positive) pairs z_i to z_j and z_j to z_i from the similarity matrix.\n",
        "        sim_i_j = torch.diag(sim, self.batch_size)\n",
        "        sim_j_i = torch.diag(sim, -self.batch_size)\n",
        "\n",
        "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
        "        # chatgpt: Concatenates the similarities of positive pairs and reshapes them for compatibility with the loss function.\n",
        "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
        "\n",
        "        # chatgpt: Selects and reshapes the similarities of negative pairs as per the mask.\n",
        "        negative_samples = sim[self.mask].reshape(N, -1)\n",
        "\n",
        "        #SIMCLR\n",
        "\n",
        "        # chatgpt: Creates labels, all set to 0, corresponding to the index of positive samples in concatenated logits. It ensures the labels are on the same device as the embeddings.\n",
        "        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(positive_samples.device).long() #.float()\n",
        "\n",
        "        # chatgpt: Concatenates the positive samples with the negative samples to form the logits.\n",
        "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
        "\n",
        "        # chatgpt: Calculates the cross-entropy loss and normalizes it by the number of pairs (N).\n",
        "        loss = self.criterion(logits, labels)\n",
        "        loss /= N\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "107r8tJ94DHC"
      },
      "outputs": [],
      "source": [
        "criterion = SimCLR_Loss(batch_size=256, temperature=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNHuZlpXrX4u"
      },
      "source": [
        "#### Optimizer\n",
        "\n",
        "the paper uses LARS optimizer, because it is good at handling the very huge batch sizes.\n",
        "\n",
        "Now with rather small batch sizes of 128, it might be overkill and i could also go with Adam optimizer instead?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj9Bh8Qyo2CR"
      },
      "outputs": [],
      "source": [
        "# # optimizer:\n",
        "\n",
        "\n",
        "# from torch.optim.optimizer import Optimizer, required\n",
        "# import re\n",
        "\n",
        "# # chatgpt: eeta scales learning rate during trust ratio computation\n",
        "# EETA_DEFAULT = 0.001\n",
        "\n",
        "\n",
        "# class LARS(Optimizer):\n",
        "#     \"\"\"\n",
        "#     Layer-wise Adaptive Rate Scaling for large batch training.\n",
        "#     Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n",
        "#     I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         params,\n",
        "#         lr=required,\n",
        "#         momentum=0.9,\n",
        "#         use_nesterov=False,\n",
        "#         weight_decay=0.0, # L2 regularization factor\n",
        "#         exclude_from_weight_decay=None,\n",
        "#         exclude_from_layer_adaptation=None,\n",
        "#         classic_momentum=True,\n",
        "#         eeta=EETA_DEFAULT,\n",
        "#     ):\n",
        "#         \"\"\"Constructs a LARSOptimizer.\n",
        "#         Args:\n",
        "#         lr: A `float` for learning rate.\n",
        "#         momentum: A `float` for momentum.\n",
        "#         use_nesterov: A 'Boolean' for whether to use nesterov momentum.\n",
        "#         weight_decay: A `float` for weight decay.\n",
        "#         exclude_from_weight_decay: A list of `string` for variable screening, if\n",
        "#             any of the string appears in a variable's name, the variable will be\n",
        "#             excluded for computing weight decay. For example, one could specify\n",
        "#             the list like ['batch_normalization', 'bias'] to exclude BN and bias\n",
        "#             from weight decay.\n",
        "#         exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but\n",
        "#             for layer adaptation. If it is None, it will be defaulted the same as\n",
        "#             exclude_from_weight_decay.\n",
        "#         classic_momentum: A `boolean` for whether to use classic (or popular)\n",
        "#             momentum. The learning rate is applied during momeuntum update in\n",
        "#             classic momentum, but after momentum for popular momentum.\n",
        "#         eeta: A `float` for scaling of learning rate when computing trust ratio.\n",
        "#         name: The name for the scope.\n",
        "#         \"\"\"\n",
        "\n",
        "#         self.epoch = 0\n",
        "#         defaults = dict(\n",
        "#             lr=lr,\n",
        "#             momentum=momentum,\n",
        "#             use_nesterov=use_nesterov,\n",
        "#             weight_decay=weight_decay,\n",
        "#             exclude_from_weight_decay=exclude_from_weight_decay,\n",
        "#             exclude_from_layer_adaptation=exclude_from_layer_adaptation,\n",
        "#             classic_momentum=classic_momentum,\n",
        "#             eeta=eeta,\n",
        "#         )\n",
        "#         # chatgpt: initialize bas e'Optimizer' class with parameters and default values\n",
        "#         super(LARS, self).__init__(params, defaults)\n",
        "#         self.lr = lr\n",
        "#         self.momentum = momentum\n",
        "#         self.weight_decay = weight_decay\n",
        "#         self.use_nesterov = use_nesterov\n",
        "#         self.classic_momentum = classic_momentum\n",
        "#         self.eeta = eeta\n",
        "#         self.exclude_from_weight_decay = exclude_from_weight_decay\n",
        "#         # exclude_from_layer_adaptation is set to exclude_from_weight_decay if the\n",
        "#         # arg is None.\n",
        "#         if exclude_from_layer_adaptation:\n",
        "#             self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
        "#         else:\n",
        "#             self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
        "\n",
        "#     def step(self, epoch=None, closure=None):\n",
        "#         loss = None\n",
        "#         if closure is not None:\n",
        "#             loss = closure() # is used to calculate loss again after an optimizer step\n",
        "\n",
        "#         if epoch is None:\n",
        "#             epoch = self.epoch\n",
        "#             self.epoch += 1\n",
        "\n",
        "#         for group in self.param_groups:\n",
        "#             weight_decay = group[\"weight_decay\"]\n",
        "#             momentum = group[\"momentum\"]\n",
        "#             eeta = group[\"eeta\"]\n",
        "#             lr = group[\"lr\"]\n",
        "\n",
        "#             for p in group[\"params\"]:\n",
        "#                 if p.grad is None:\n",
        "#                     continue\n",
        "\n",
        "#                 param = p.data\n",
        "#                 grad = p.grad.data\n",
        "\n",
        "#                 param_state = self.state[p]\n",
        "\n",
        "#                 # TODO: get param names\n",
        "#                 # if self._use_weight_decay(param_name):\n",
        "#                 grad += self.weight_decay * param\n",
        "\n",
        "#                 if self.classic_momentum:\n",
        "#                     trust_ratio = 1.0\n",
        "\n",
        "#                     # TODO: get param names\n",
        "#                     # if self._do_layer_adaptation(param_name):\n",
        "#                     w_norm = torch.norm(param)\n",
        "#                     g_norm = torch.norm(grad)\n",
        "\n",
        "#                     device = g_norm.get_device()\n",
        "#                     trust_ratio = torch.where(\n",
        "#                         w_norm.gt(0),\n",
        "#                         torch.where(\n",
        "#                             g_norm.gt(0),\n",
        "#                             (self.eeta * w_norm / g_norm),\n",
        "#                             torch.Tensor([1.0]).to(device),\n",
        "#                         ),\n",
        "#                         torch.Tensor([1.0]).to(device),\n",
        "#                     ).item()\n",
        "\n",
        "#                     scaled_lr = lr * trust_ratio\n",
        "#                     if \"momentum_buffer\" not in param_state:\n",
        "#                         next_v = param_state[\"momentum_buffer\"] = torch.zeros_like(\n",
        "#                             p.data\n",
        "#                         )\n",
        "#                     else:\n",
        "#                         next_v = param_state[\"momentum_buffer\"]\n",
        "\n",
        "#                     next_v.mul_(momentum).add_(scaled_lr, grad)\n",
        "#                     if self.use_nesterov:\n",
        "#                         update = (self.momentum * next_v) + (scaled_lr * grad)\n",
        "#                     else:\n",
        "#                         update = next_v\n",
        "\n",
        "#                     p.data.add_(-update)\n",
        "#                 else:\n",
        "#                     raise NotImplementedError\n",
        "\n",
        "#         return loss\n",
        "\n",
        "#     def _use_weight_decay(self, param_name):\n",
        "#         \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
        "#         if not self.weight_decay:\n",
        "#             return False\n",
        "#         if self.exclude_from_weight_decay:\n",
        "#             for r in self.exclude_from_weight_decay:\n",
        "#                 if re.search(r, param_name) is not None:\n",
        "#                     return False\n",
        "#         return True\n",
        "\n",
        "#     def _do_layer_adaptation(self, param_name):\n",
        "#         \"\"\"Whether to do layer-wise learning rate adaptation for `param_name`.\"\"\"\n",
        "#         if self.exclude_from_layer_adaptation:\n",
        "#             for r in self.exclude_from_layer_adaptation:\n",
        "#                 if re.search(r, param_name) is not None:\n",
        "#                     return False\n",
        "#         return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUZkuTrwuDiZ"
      },
      "outputs": [],
      "source": [
        "# other option would be to just use the adam optiizer\n",
        "LR = 0.0001\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
        "# für den scheduler kann ich ja wieder den cosineannealingwarmretarts nehmen\n",
        "\n",
        "#SCHEDULER OR LINEAR EWARMUP\n",
        "warmupscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch : (epoch+1)/10.0) # verbose=True stand vorher da\n",
        "\n",
        "#SCHEDULER FOR COSINE DECAY\n",
        "mainscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 500, eta_min=0.05, last_epoch=-1)  # verbose=True stand vorher da\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOi8xv9OorIS"
      },
      "source": [
        "## 4. Define the metrics\n",
        "\n",
        "in contrastive learning there isnt really a lot of metrics to keep track of during training - the main thing is the loss value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-rrMic_oqUr"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(outputs_lc, labels_lc, num_classes=23):\n",
        "  output = torch.argmax(outputs_lc, dim=1)#.flatten()\n",
        "  label = labels_lc#.flatten()\n",
        "\n",
        "  iou_per_class = []\n",
        "  for cls in range(num_classes):\n",
        "    tp = (output == cls) & (label == cls)\n",
        "    fp = (output == cls) & (label != cls)\n",
        "    fn = (output != cls) & (label == cls)\n",
        "    intersection = tp.sum()\n",
        "    union = tp.sum() + fp.sum() + fn.sum()\n",
        "\n",
        "    if union == 0:\n",
        "      iou = torch.tensor(1.0) # if there is no GT, no prediction, i will set the intersection to 1\n",
        "    else:\n",
        "      iou = intersection.float() / union.float()\n",
        "\n",
        "    iou_per_class.append(iou.cuda())\n",
        "\n",
        "  mean_iou = torch.mean(torch.stack(iou_per_class))\n",
        "\n",
        "  return mean_iou.item()\n",
        "\n",
        "def calculate_accuracy(outputs_lc, labels_lc):\n",
        "  predicted_classes = torch.argmax(outputs_lc, dim=1)\n",
        "\n",
        "  correct_predictions = (predicted_classes == labels_lc).float()\n",
        "  accuracy = correct_predictions.sum() / correct_predictions.numel()\n",
        "\n",
        "  return accuracy.item()\n",
        "\n",
        "def calculate_r_squared(outputs, targets):\n",
        "    total_variance = torch.sum((targets - torch.mean(targets))**2)\n",
        "    explained_variance = torch.sum((targets - outputs)**2)\n",
        "    r2 = 1 - explained_variance / total_variance\n",
        "    return r2\n",
        "\n",
        "def calculate_mae(outputs, targets):\n",
        "    return torch.mean(torch.abs(outputs - targets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTKVWTRmox-0"
      },
      "source": [
        "## 5. Define the training, validation scheme, and actually train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UShUAci_5Kgr"
      },
      "outputs": [],
      "source": [
        "RUNNAME = f'CL_allData_{AUXILIARY_DATASOURCE}_0001_eurosat_256'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUXILIARY_DATASOURCE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3Il0bIvkDWfH",
        "outputId": "25b3b6d5-770b-4d60-e301-321101f81756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LC'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cUBsYCACwffa",
        "outputId": "0aa59858-2ce4-4223-8c48-54eb486c3221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100]\t\n",
            "Training Step [0/27]\t Loss: 7.05907\n",
            "Training Step [10/27]\t Loss: 5.90615\n",
            "Training Step [20/27]\t Loss: 5.51777\n",
            "Validation Step [0/6]\t Loss: 5.44138\n",
            "Epoch [0/100]\t Training Loss: 5.8593005074395075\t lr: 2e-05\n",
            "Epoch [0/100]\t Validation Loss: 5.421813488006592\t lr: 2e-05\n",
            "Epoch [0/100]\t Time Taken: 0.3237132708231608 minutes\n",
            "Epoch [1/100]\t\n",
            "Training Step [0/27]\t Loss: 5.33732\n",
            "Training Step [10/27]\t Loss: 5.2096\n",
            "Training Step [20/27]\t Loss: 5.17483\n",
            "Validation Step [0/6]\t Loss: 5.30011\n",
            "Epoch [1/100]\t Training Loss: 5.251436463108769\t lr: 3e-05\n",
            "Epoch [1/100]\t Validation Loss: 5.256770690282186\t lr: 3e-05\n",
            "Epoch [1/100]\t Time Taken: 0.3235170761744181 minutes\n",
            "Epoch [2/100]\t\n",
            "Training Step [0/27]\t Loss: 5.17528\n",
            "Training Step [10/27]\t Loss: 5.16368\n",
            "Training Step [20/27]\t Loss: 5.05586\n",
            "Validation Step [0/6]\t Loss: 5.14957\n",
            "Epoch [2/100]\t Training Loss: 5.118893852940312\t lr: 4e-05\n",
            "Epoch [2/100]\t Validation Loss: 5.16801905632019\t lr: 4e-05\n",
            "Epoch [2/100]\t Time Taken: 0.3250869631767273 minutes\n",
            "Epoch [3/100]\t\n",
            "Training Step [0/27]\t Loss: 5.07463\n",
            "Training Step [10/27]\t Loss: 5.03512\n",
            "Training Step [20/27]\t Loss: 5.03028\n",
            "Validation Step [0/6]\t Loss: 5.08863\n",
            "Epoch [3/100]\t Training Loss: 5.012786088166414\t lr: 5e-05\n",
            "Epoch [3/100]\t Validation Loss: 5.104309479395549\t lr: 5e-05\n",
            "Epoch [3/100]\t Time Taken: 0.32558875481287636 minutes\n",
            "Epoch [4/100]\t\n",
            "Training Step [0/27]\t Loss: 4.97904\n",
            "Training Step [10/27]\t Loss: 4.90802\n",
            "Training Step [20/27]\t Loss: 4.90317\n",
            "Validation Step [0/6]\t Loss: 5.07336\n",
            "Epoch [4/100]\t Training Loss: 4.938733683692084\t lr: 6e-05\n",
            "Epoch [4/100]\t Validation Loss: 5.076345920562744\t lr: 6e-05\n",
            "Epoch [4/100]\t Time Taken: 0.32735970815022786 minutes\n",
            "Epoch [5/100]\t\n",
            "Training Step [0/27]\t Loss: 4.87868\n",
            "Training Step [10/27]\t Loss: 4.90746\n",
            "Training Step [20/27]\t Loss: 4.87101\n",
            "Validation Step [0/6]\t Loss: 5.02361\n",
            "Epoch [5/100]\t Training Loss: 4.8779176429465965\t lr: 7e-05\n",
            "Epoch [5/100]\t Validation Loss: 5.046803553899129\t lr: 7e-05\n",
            "Epoch [5/100]\t Time Taken: 0.326676865418752 minutes\n",
            "Epoch [6/100]\t\n",
            "Training Step [0/27]\t Loss: 4.82424\n",
            "Training Step [10/27]\t Loss: 4.86052\n",
            "Training Step [20/27]\t Loss: 4.8248\n",
            "Validation Step [0/6]\t Loss: 5.03298\n",
            "Epoch [6/100]\t Training Loss: 4.822478506300184\t lr: 8e-05\n",
            "Epoch [6/100]\t Validation Loss: 5.023675203323364\t lr: 8e-05\n",
            "Epoch [6/100]\t Time Taken: 0.3244274377822876 minutes\n",
            "Epoch [7/100]\t\n",
            "Training Step [0/27]\t Loss: 4.77611\n",
            "Training Step [10/27]\t Loss: 4.77153\n",
            "Training Step [20/27]\t Loss: 4.76377\n",
            "Validation Step [0/6]\t Loss: 5.07003\n",
            "Epoch [7/100]\t Training Loss: 4.781405448913574\t lr: 9e-05\n",
            "Epoch [7/100]\t Validation Loss: 5.025132020314534\t lr: 9e-05\n",
            "Epoch [7/100]\t Time Taken: 0.32818040053049724 minutes\n",
            "Epoch [8/100]\t\n",
            "Training Step [0/27]\t Loss: 4.74336\n",
            "Training Step [10/27]\t Loss: 4.75634\n",
            "Training Step [20/27]\t Loss: 4.74063\n",
            "Validation Step [0/6]\t Loss: 5.04434\n",
            "Epoch [8/100]\t Training Loss: 4.745159908577248\t lr: 0.0001\n",
            "Epoch [8/100]\t Validation Loss: 5.024983565012614\t lr: 0.0001\n",
            "Epoch [8/100]\t Time Taken: 0.32630491654078164 minutes\n",
            "Epoch [9/100]\t\n",
            "Training Step [0/27]\t Loss: 4.71661\n",
            "Training Step [10/27]\t Loss: 4.71117\n",
            "Training Step [20/27]\t Loss: 4.71783\n",
            "Validation Step [0/6]\t Loss: 5.02321\n",
            "Epoch [9/100]\t Training Loss: 4.719155187960024\t lr: 0.00011\n",
            "Epoch [9/100]\t Validation Loss: 5.016703923543294\t lr: 0.00011\n",
            "Epoch [9/100]\t Time Taken: 0.32679877678553265 minutes\n",
            "Epoch [10/100]\t\n",
            "Training Step [0/27]\t Loss: 4.69559\n",
            "Training Step [10/27]\t Loss: 4.71706\n",
            "Training Step [20/27]\t Loss: 4.70852\n",
            "Validation Step [0/6]\t Loss: 5.01448\n",
            "Epoch [10/100]\t Training Loss: 4.703769630855984\t lr: 0.0001\n",
            "Epoch [10/100]\t Validation Loss: 5.012286265691121\t lr: 0.0001\n",
            "Epoch [10/100]\t Time Taken: 0.3288374503453573 minutes\n",
            "Epoch [11/100]\t\n",
            "Training Step [0/27]\t Loss: 4.66974\n",
            "Training Step [10/27]\t Loss: 4.67187\n",
            "Training Step [20/27]\t Loss: 4.67432\n",
            "Validation Step [0/6]\t Loss: 4.97741\n",
            "Epoch [11/100]\t Training Loss: 4.681345215550175\t lr: 0.0001\n",
            "Epoch [11/100]\t Validation Loss: 4.998989741007487\t lr: 0.0001\n",
            "Epoch [11/100]\t Time Taken: 0.32091156641642254 minutes\n",
            "Epoch [12/100]\t\n",
            "Training Step [0/27]\t Loss: 4.6758\n",
            "Training Step [10/27]\t Loss: 4.65912\n",
            "Training Step [20/27]\t Loss: 4.66118\n",
            "Validation Step [0/6]\t Loss: 5.0045\n",
            "Epoch [12/100]\t Training Loss: 4.664711793263753\t lr: 0.0001\n",
            "Epoch [12/100]\t Validation Loss: 5.016457239786784\t lr: 0.0001\n",
            "Epoch [12/100]\t Time Taken: 0.31973795890808104 minutes\n",
            "Epoch [13/100]\t\n",
            "Training Step [0/27]\t Loss: 4.66623\n",
            "Training Step [10/27]\t Loss: 4.63988\n",
            "Training Step [20/27]\t Loss: 4.63957\n",
            "Validation Step [0/6]\t Loss: 5.04692\n",
            "Epoch [13/100]\t Training Loss: 4.648499347545482\t lr: 0.00011\n",
            "Epoch [13/100]\t Validation Loss: 5.001700401306152\t lr: 0.00011\n",
            "Epoch [13/100]\t Time Taken: 0.31846254666646323 minutes\n",
            "Epoch [14/100]\t\n",
            "Training Step [0/27]\t Loss: 4.64804\n",
            "Training Step [10/27]\t Loss: 4.64067\n",
            "Training Step [20/27]\t Loss: 4.6343\n",
            "Validation Step [0/6]\t Loss: 5.00126\n",
            "Epoch [14/100]\t Training Loss: 4.6447052249202025\t lr: 0.00011\n",
            "Epoch [14/100]\t Validation Loss: 5.001899798711141\t lr: 0.00011\n",
            "Epoch [14/100]\t Time Taken: 0.3284693678220113 minutes\n",
            "Epoch [15/100]\t\n",
            "Training Step [0/27]\t Loss: 4.64622\n",
            "Training Step [10/27]\t Loss: 4.66285\n",
            "Training Step [20/27]\t Loss: 4.63184\n",
            "Validation Step [0/6]\t Loss: 5.02287\n",
            "Epoch [15/100]\t Training Loss: 4.634161083786576\t lr: 0.00012\n",
            "Epoch [15/100]\t Validation Loss: 5.006684064865112\t lr: 0.00012\n",
            "Epoch [15/100]\t Time Taken: 0.32730674743652344 minutes\n",
            "Epoch [16/100]\t\n",
            "Training Step [0/27]\t Loss: 4.626\n",
            "Training Step [10/27]\t Loss: 4.61821\n",
            "Training Step [20/27]\t Loss: 4.61282\n",
            "Validation Step [0/6]\t Loss: 5.04986\n",
            "Epoch [16/100]\t Training Loss: 4.618806450455277\t lr: 0.00012\n",
            "Epoch [16/100]\t Validation Loss: 5.009217739105225\t lr: 0.00012\n",
            "Epoch [16/100]\t Time Taken: 0.31921615997950237 minutes\n",
            "Epoch [17/100]\t\n",
            "Training Step [0/27]\t Loss: 4.60359\n",
            "Training Step [10/27]\t Loss: 4.63168\n",
            "Training Step [20/27]\t Loss: 4.62118\n",
            "Validation Step [0/6]\t Loss: 5.00983\n",
            "Epoch [17/100]\t Training Loss: 4.617466997217249\t lr: 0.00013\n",
            "Epoch [17/100]\t Validation Loss: 5.0008227825164795\t lr: 0.00013\n",
            "Epoch [17/100]\t Time Taken: 0.32414902448654176 minutes\n",
            "Epoch [18/100]\t\n",
            "Training Step [0/27]\t Loss: 4.64445\n",
            "Training Step [10/27]\t Loss: 4.59108\n",
            "Training Step [20/27]\t Loss: 4.60445\n",
            "Validation Step [0/6]\t Loss: 4.97919\n",
            "Epoch [18/100]\t Training Loss: 4.610900402069092\t lr: 0.00014\n",
            "Epoch [18/100]\t Validation Loss: 4.999950806299846\t lr: 0.00014\n",
            "Epoch [18/100]\t Time Taken: 0.3191658775011698 minutes\n",
            "Epoch [19/100]\t\n",
            "Training Step [0/27]\t Loss: 4.60566\n",
            "Training Step [10/27]\t Loss: 4.60313\n",
            "Training Step [20/27]\t Loss: 4.61013\n",
            "Validation Step [0/6]\t Loss: 5.12218\n",
            "Epoch [19/100]\t Training Loss: 4.6092049634015115\t lr: 0.00015\n",
            "Epoch [19/100]\t Validation Loss: 5.055902719497681\t lr: 0.00015\n",
            "Epoch [19/100]\t Time Taken: 0.32393266757329303 minutes\n",
            "Epoch [20/100]\t\n",
            "Training Step [0/27]\t Loss: 4.64381\n",
            "Training Step [10/27]\t Loss: 4.60693\n",
            "Training Step [20/27]\t Loss: 4.61519\n",
            "Validation Step [0/6]\t Loss: 4.98877\n",
            "Epoch [20/100]\t Training Loss: 4.612783008151585\t lr: 0.00016\n",
            "Epoch [20/100]\t Validation Loss: 5.016192436218262\t lr: 0.00016\n",
            "Epoch [20/100]\t Time Taken: 0.3246395707130432 minutes\n",
            "Epoch [21/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59312\n",
            "Training Step [10/27]\t Loss: 4.61263\n",
            "Training Step [20/27]\t Loss: 4.60555\n",
            "Validation Step [0/6]\t Loss: 4.98842\n",
            "Epoch [21/100]\t Training Loss: 4.602973266884133\t lr: 0.00017\n",
            "Epoch [21/100]\t Validation Loss: 5.009642680486043\t lr: 0.00017\n",
            "Epoch [21/100]\t Time Taken: 0.3182481646537781 minutes\n",
            "Epoch [22/100]\t\n",
            "Training Step [0/27]\t Loss: 4.60753\n",
            "Training Step [10/27]\t Loss: 4.599\n",
            "Training Step [20/27]\t Loss: 4.60803\n",
            "Validation Step [0/6]\t Loss: 5.00282\n",
            "Epoch [22/100]\t Training Loss: 4.600715019084789\t lr: 0.00018\n",
            "Epoch [22/100]\t Validation Loss: 5.018782774607341\t lr: 0.00018\n",
            "Epoch [22/100]\t Time Taken: 0.32408574819564817 minutes\n",
            "Epoch [23/100]\t\n",
            "Training Step [0/27]\t Loss: 4.5982\n",
            "Training Step [10/27]\t Loss: 4.59659\n",
            "Training Step [20/27]\t Loss: 4.59755\n",
            "Validation Step [0/6]\t Loss: 4.96226\n",
            "Epoch [23/100]\t Training Loss: 4.602101643880208\t lr: 0.0002\n",
            "Epoch [23/100]\t Validation Loss: 5.028239727020264\t lr: 0.0002\n",
            "Epoch [23/100]\t Time Taken: 0.3175231655438741 minutes\n",
            "Epoch [24/100]\t\n",
            "Training Step [0/27]\t Loss: 4.57281\n",
            "Training Step [10/27]\t Loss: 4.58589\n",
            "Training Step [20/27]\t Loss: 4.62503\n",
            "Validation Step [0/6]\t Loss: 5.05458\n",
            "Epoch [24/100]\t Training Loss: 4.61099750024301\t lr: 0.00021\n",
            "Epoch [24/100]\t Validation Loss: 5.068262894948323\t lr: 0.00021\n",
            "Epoch [24/100]\t Time Taken: 0.3253662109375 minutes\n",
            "Epoch [25/100]\t\n",
            "Training Step [0/27]\t Loss: 4.60238\n",
            "Training Step [10/27]\t Loss: 4.63535\n",
            "Training Step [20/27]\t Loss: 4.6062\n",
            "Validation Step [0/6]\t Loss: 5.10965\n",
            "Epoch [25/100]\t Training Loss: 4.614028188917372\t lr: 0.00023\n",
            "Epoch [25/100]\t Validation Loss: 5.091167449951172\t lr: 0.00023\n",
            "Epoch [25/100]\t Time Taken: 0.3184081474939982 minutes\n",
            "Epoch [26/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59374\n",
            "Training Step [10/27]\t Loss: 4.59735\n",
            "Training Step [20/27]\t Loss: 4.6012\n",
            "Validation Step [0/6]\t Loss: 5.05183\n",
            "Epoch [26/100]\t Training Loss: 4.611231221093072\t lr: 0.00024\n",
            "Epoch [26/100]\t Validation Loss: 5.071006774902344\t lr: 0.00024\n",
            "Epoch [26/100]\t Time Taken: 0.32101211945215863 minutes\n",
            "Epoch [27/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59714\n",
            "Training Step [10/27]\t Loss: 4.59099\n",
            "Training Step [20/27]\t Loss: 4.64763\n",
            "Validation Step [0/6]\t Loss: 5.02818\n",
            "Epoch [27/100]\t Training Loss: 4.619263613665545\t lr: 0.00026\n",
            "Epoch [27/100]\t Validation Loss: 5.035274108250936\t lr: 0.00026\n",
            "Epoch [27/100]\t Time Taken: 0.3213622808456421 minutes\n",
            "Epoch [28/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59765\n",
            "Training Step [10/27]\t Loss: 4.62217\n",
            "Training Step [20/27]\t Loss: 4.62018\n",
            "Validation Step [0/6]\t Loss: 4.9806\n",
            "Epoch [28/100]\t Training Loss: 4.609281575238263\t lr: 0.00028\n",
            "Epoch [28/100]\t Validation Loss: 5.031799395879109\t lr: 0.00028\n",
            "Epoch [28/100]\t Time Taken: 0.3249021132787069 minutes\n",
            "Epoch [29/100]\t\n",
            "Training Step [0/27]\t Loss: 4.57899\n",
            "Training Step [10/27]\t Loss: 4.60144\n",
            "Training Step [20/27]\t Loss: 4.58359\n",
            "Validation Step [0/6]\t Loss: 5.07167\n",
            "Epoch [29/100]\t Training Loss: 4.600626150767009\t lr: 0.0003\n",
            "Epoch [29/100]\t Validation Loss: 5.128384033838908\t lr: 0.0003\n",
            "Epoch [29/100]\t Time Taken: 0.32882577180862427 minutes\n",
            "Epoch [30/100]\t\n",
            "Training Step [0/27]\t Loss: 4.62071\n",
            "Training Step [10/27]\t Loss: 4.59665\n",
            "Training Step [20/27]\t Loss: 4.62063\n",
            "Validation Step [0/6]\t Loss: 5.09946\n",
            "Epoch [30/100]\t Training Loss: 4.610432147979736\t lr: 0.00032\n",
            "Epoch [30/100]\t Validation Loss: 5.095778703689575\t lr: 0.00032\n",
            "Epoch [30/100]\t Time Taken: 0.3217212239901225 minutes\n",
            "Epoch [31/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59189\n",
            "Training Step [10/27]\t Loss: 4.64156\n",
            "Training Step [20/27]\t Loss: 4.60789\n",
            "Validation Step [0/6]\t Loss: 5.01942\n",
            "Epoch [31/100]\t Training Loss: 4.617462264166938\t lr: 0.00034\n",
            "Epoch [31/100]\t Validation Loss: 5.046657959620158\t lr: 0.00034\n",
            "Epoch [31/100]\t Time Taken: 0.3208202878634135 minutes\n",
            "Epoch [32/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59299\n",
            "Training Step [10/27]\t Loss: 4.5903\n",
            "Training Step [20/27]\t Loss: 4.60637\n",
            "Validation Step [0/6]\t Loss: 5.11133\n",
            "Epoch [32/100]\t Training Loss: 4.604124740318015\t lr: 0.00036\n",
            "Epoch [32/100]\t Validation Loss: 5.072468996047974\t lr: 0.00036\n",
            "Epoch [32/100]\t Time Taken: 0.31965521176656086 minutes\n",
            "Epoch [33/100]\t\n",
            "Training Step [0/27]\t Loss: 4.56827\n",
            "Training Step [10/27]\t Loss: 4.60332\n",
            "Training Step [20/27]\t Loss: 4.63131\n",
            "Validation Step [0/6]\t Loss: 5.23664\n",
            "Epoch [33/100]\t Training Loss: 4.600318378872341\t lr: 0.00038\n",
            "Epoch [33/100]\t Validation Loss: 5.17695156733195\t lr: 0.00038\n",
            "Epoch [33/100]\t Time Taken: 0.3227604587872823 minutes\n",
            "Epoch [34/100]\t\n",
            "Training Step [0/27]\t Loss: 4.60644\n",
            "Training Step [10/27]\t Loss: 4.61095\n",
            "Training Step [20/27]\t Loss: 4.61388\n",
            "Validation Step [0/6]\t Loss: 5.04703\n",
            "Epoch [34/100]\t Training Loss: 4.604836446267587\t lr: 0.00041\n",
            "Epoch [34/100]\t Validation Loss: 5.0541157722473145\t lr: 0.00041\n",
            "Epoch [34/100]\t Time Taken: 0.3269583940505981 minutes\n",
            "Epoch [35/100]\t\n",
            "Training Step [0/27]\t Loss: 4.57004\n",
            "Training Step [10/27]\t Loss: 4.58186\n",
            "Training Step [20/27]\t Loss: 4.62428\n",
            "Validation Step [0/6]\t Loss: 5.16681\n",
            "Epoch [35/100]\t Training Loss: 4.607264995574951\t lr: 0.00043\n",
            "Epoch [35/100]\t Validation Loss: 5.119591395060222\t lr: 0.00043\n",
            "Epoch [35/100]\t Time Taken: 0.32060577472050983 minutes\n",
            "Epoch [36/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59664\n",
            "Training Step [10/27]\t Loss: 4.55568\n",
            "Training Step [20/27]\t Loss: 4.61654\n",
            "Validation Step [0/6]\t Loss: 5.09324\n",
            "Epoch [36/100]\t Training Loss: 4.610805564456516\t lr: 0.00046\n",
            "Epoch [36/100]\t Validation Loss: 5.100401163101196\t lr: 0.00046\n",
            "Epoch [36/100]\t Time Taken: 0.32580397923787435 minutes\n",
            "Epoch [37/100]\t\n",
            "Training Step [0/27]\t Loss: 4.58861\n",
            "Training Step [10/27]\t Loss: 4.58768\n",
            "Training Step [20/27]\t Loss: 4.59583\n",
            "Validation Step [0/6]\t Loss: 5.46416\n",
            "Epoch [37/100]\t Training Loss: 4.608415444691976\t lr: 0.00049\n",
            "Epoch [37/100]\t Validation Loss: 5.434985160827637\t lr: 0.00049\n",
            "Epoch [37/100]\t Time Taken: 0.32010857661565145 minutes\n",
            "Epoch [38/100]\t\n",
            "Training Step [0/27]\t Loss: 4.61087\n",
            "Training Step [10/27]\t Loss: 4.66522\n",
            "Training Step [20/27]\t Loss: 4.81259\n",
            "Validation Step [0/6]\t Loss: 6.03746\n",
            "Epoch [38/100]\t Training Loss: 4.761457090024595\t lr: 0.00051\n",
            "Epoch [38/100]\t Validation Loss: 6.029739141464233\t lr: 0.00051\n",
            "Epoch [38/100]\t Time Taken: 0.3247935970624288 minutes\n",
            "Epoch [39/100]\t\n",
            "Training Step [0/27]\t Loss: 5.15622\n",
            "Training Step [10/27]\t Loss: 4.82181\n",
            "Training Step [20/27]\t Loss: 4.77631\n",
            "Validation Step [0/6]\t Loss: 5.18412\n",
            "Epoch [39/100]\t Training Loss: 4.843399718955711\t lr: 0.00054\n",
            "Epoch [39/100]\t Validation Loss: 5.201852798461914\t lr: 0.00054\n",
            "Epoch [39/100]\t Time Taken: 0.3243180314699809 minutes\n",
            "Epoch [40/100]\t\n",
            "Training Step [0/27]\t Loss: 4.72689\n",
            "Training Step [10/27]\t Loss: 4.75673\n",
            "Training Step [20/27]\t Loss: 4.71618\n",
            "Validation Step [0/6]\t Loss: 5.12934\n",
            "Epoch [40/100]\t Training Loss: 4.713298214806451\t lr: 0.00057\n",
            "Epoch [40/100]\t Validation Loss: 5.081304470698039\t lr: 0.00057\n",
            "Epoch [40/100]\t Time Taken: 0.32384709517161053 minutes\n",
            "Epoch [41/100]\t\n",
            "Training Step [0/27]\t Loss: 4.63972\n",
            "Training Step [10/27]\t Loss: 4.66296\n",
            "Training Step [20/27]\t Loss: 4.64951\n",
            "Validation Step [0/6]\t Loss: 5.02164\n",
            "Epoch [41/100]\t Training Loss: 4.670341685966209\t lr: 0.0006\n",
            "Epoch [41/100]\t Validation Loss: 5.032785813013713\t lr: 0.0006\n",
            "Epoch [41/100]\t Time Taken: 0.32444053490956626 minutes\n",
            "Epoch [42/100]\t\n",
            "Training Step [0/27]\t Loss: 4.63927\n",
            "Training Step [10/27]\t Loss: 4.68733\n",
            "Training Step [20/27]\t Loss: 4.63581\n",
            "Validation Step [0/6]\t Loss: 5.07062\n",
            "Epoch [42/100]\t Training Loss: 4.659418759522615\t lr: 0.00063\n",
            "Epoch [42/100]\t Validation Loss: 5.071225881576538\t lr: 0.00063\n",
            "Epoch [42/100]\t Time Taken: 0.31829495429992677 minutes\n",
            "Epoch [43/100]\t\n",
            "Training Step [0/27]\t Loss: 4.68301\n",
            "Training Step [10/27]\t Loss: 4.64898\n",
            "Training Step [20/27]\t Loss: 4.66666\n",
            "Validation Step [0/6]\t Loss: 4.9993\n",
            "Epoch [43/100]\t Training Loss: 4.660501091568558\t lr: 0.00067\n",
            "Epoch [43/100]\t Validation Loss: 5.092134952545166\t lr: 0.00067\n",
            "Epoch [43/100]\t Time Taken: 0.3238114396731059 minutes\n",
            "Epoch [44/100]\t\n",
            "Training Step [0/27]\t Loss: 4.666\n",
            "Training Step [10/27]\t Loss: 4.62677\n",
            "Training Step [20/27]\t Loss: 4.61233\n",
            "Validation Step [0/6]\t Loss: 5.1563\n",
            "Epoch [44/100]\t Training Loss: 4.63439416885376\t lr: 0.0007\n",
            "Epoch [44/100]\t Validation Loss: 5.126067558924357\t lr: 0.0007\n",
            "Epoch [44/100]\t Time Taken: 0.32267711957295736 minutes\n",
            "Epoch [45/100]\t\n",
            "Training Step [0/27]\t Loss: 4.62544\n",
            "Training Step [10/27]\t Loss: 4.59039\n",
            "Training Step [20/27]\t Loss: 4.61103\n",
            "Validation Step [0/6]\t Loss: 5.13744\n",
            "Epoch [45/100]\t Training Loss: 4.622068687721535\t lr: 0.00074\n",
            "Epoch [45/100]\t Validation Loss: 5.121787945429484\t lr: 0.00074\n",
            "Epoch [45/100]\t Time Taken: 0.323913582166036 minutes\n",
            "Epoch [46/100]\t\n",
            "Training Step [0/27]\t Loss: 4.63386\n",
            "Training Step [10/27]\t Loss: 4.61376\n",
            "Training Step [20/27]\t Loss: 4.63234\n",
            "Validation Step [0/6]\t Loss: 5.17499\n",
            "Epoch [46/100]\t Training Loss: 4.620540530593307\t lr: 0.00077\n",
            "Epoch [46/100]\t Validation Loss: 5.173438310623169\t lr: 0.00077\n",
            "Epoch [46/100]\t Time Taken: 0.3218100150426229 minutes\n",
            "Epoch [47/100]\t\n",
            "Training Step [0/27]\t Loss: 4.57413\n",
            "Training Step [10/27]\t Loss: 4.59161\n",
            "Training Step [20/27]\t Loss: 4.63187\n",
            "Validation Step [0/6]\t Loss: 5.10781\n",
            "Epoch [47/100]\t Training Loss: 4.610122821949147\t lr: 0.00081\n",
            "Epoch [47/100]\t Validation Loss: 5.139817714691162\t lr: 0.00081\n",
            "Epoch [47/100]\t Time Taken: 0.3247273564338684 minutes\n",
            "Epoch [48/100]\t\n",
            "Training Step [0/27]\t Loss: 4.56384\n",
            "Training Step [10/27]\t Loss: 4.60246\n",
            "Training Step [20/27]\t Loss: 4.59624\n",
            "Validation Step [0/6]\t Loss: 5.10124\n",
            "Epoch [48/100]\t Training Loss: 4.608044694971155\t lr: 0.00085\n",
            "Epoch [48/100]\t Validation Loss: 5.118266026178996\t lr: 0.00085\n",
            "Epoch [48/100]\t Time Taken: 0.32589472134908043 minutes\n",
            "Epoch [49/100]\t\n",
            "Training Step [0/27]\t Loss: 4.57773\n",
            "Training Step [10/27]\t Loss: 4.60074\n",
            "Training Step [20/27]\t Loss: 4.62588\n",
            "Validation Step [0/6]\t Loss: 5.14201\n",
            "Epoch [49/100]\t Training Loss: 4.612926765724465\t lr: 0.00088\n",
            "Epoch [49/100]\t Validation Loss: 5.094641288121541\t lr: 0.00088\n",
            "Epoch [49/100]\t Time Taken: 0.32703233559926354 minutes\n",
            "Epoch [50/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59946\n",
            "Training Step [10/27]\t Loss: 4.55946\n",
            "Training Step [20/27]\t Loss: 4.59572\n",
            "Validation Step [0/6]\t Loss: 5.08073\n",
            "Epoch [50/100]\t Training Loss: 4.593544783415617\t lr: 0.00092\n",
            "Epoch [50/100]\t Validation Loss: 5.073456287384033\t lr: 0.00092\n",
            "Epoch [50/100]\t Time Taken: 0.32314452330271404 minutes\n",
            "Epoch [51/100]\t\n",
            "Training Step [0/27]\t Loss: 4.61\n",
            "Training Step [10/27]\t Loss: 4.57785\n",
            "Training Step [20/27]\t Loss: 4.60966\n",
            "Validation Step [0/6]\t Loss: 5.20225\n",
            "Epoch [51/100]\t Training Loss: 4.60367617783723\t lr: 0.00096\n",
            "Epoch [51/100]\t Validation Loss: 5.147211631139119\t lr: 0.00096\n",
            "Epoch [51/100]\t Time Taken: 0.31869097153345743 minutes\n",
            "Epoch [52/100]\t\n",
            "Training Step [0/27]\t Loss: 4.57943\n",
            "Training Step [10/27]\t Loss: 4.59077\n",
            "Training Step [20/27]\t Loss: 4.61904\n",
            "Validation Step [0/6]\t Loss: 5.06421\n",
            "Epoch [52/100]\t Training Loss: 4.602987095161721\t lr: 0.00101\n",
            "Epoch [52/100]\t Validation Loss: 5.13345472017924\t lr: 0.00101\n",
            "Epoch [52/100]\t Time Taken: 0.32198975086212156 minutes\n",
            "Epoch [53/100]\t\n",
            "Training Step [0/27]\t Loss: 4.55821\n",
            "Training Step [10/27]\t Loss: 4.67024\n",
            "Training Step [20/27]\t Loss: 5.24139\n",
            "Validation Step [0/6]\t Loss: 6.14254\n",
            "Epoch [53/100]\t Training Loss: 4.742781815705476\t lr: 0.00105\n",
            "Epoch [53/100]\t Validation Loss: 6.0955023765563965\t lr: 0.00105\n",
            "Epoch [53/100]\t Time Taken: 0.3211622397104899 minutes\n",
            "Epoch [54/100]\t\n",
            "Training Step [0/27]\t Loss: 4.82455\n",
            "Training Step [10/27]\t Loss: 4.83307\n",
            "Training Step [20/27]\t Loss: 4.70172\n",
            "Validation Step [0/6]\t Loss: 5.25753\n",
            "Epoch [54/100]\t Training Loss: 4.789613017329463\t lr: 0.00109\n",
            "Epoch [54/100]\t Validation Loss: 5.305707613627116\t lr: 0.00109\n",
            "Epoch [54/100]\t Time Taken: 0.32937326828638713 minutes\n",
            "Epoch [55/100]\t\n",
            "Training Step [0/27]\t Loss: 4.672\n",
            "Training Step [10/27]\t Loss: 4.69606\n",
            "Training Step [20/27]\t Loss: 4.70822\n",
            "Validation Step [0/6]\t Loss: 5.17754\n",
            "Epoch [55/100]\t Training Loss: 4.703598040121573\t lr: 0.00113\n",
            "Epoch [55/100]\t Validation Loss: 5.162109454472859\t lr: 0.00113\n",
            "Epoch [55/100]\t Time Taken: 0.32470056613286336 minutes\n",
            "Epoch [56/100]\t\n",
            "Training Step [0/27]\t Loss: 4.6612\n",
            "Training Step [10/27]\t Loss: 4.65739\n",
            "Training Step [20/27]\t Loss: 4.66514\n",
            "Validation Step [0/6]\t Loss: 5.19834\n",
            "Epoch [56/100]\t Training Loss: 4.669533076109709\t lr: 0.00118\n",
            "Epoch [56/100]\t Validation Loss: 5.227033774058024\t lr: 0.00118\n",
            "Epoch [56/100]\t Time Taken: 0.32151611646016437 minutes\n",
            "Epoch [57/100]\t\n",
            "Training Step [0/27]\t Loss: 4.62928\n",
            "Training Step [10/27]\t Loss: 4.64454\n",
            "Training Step [20/27]\t Loss: 4.65692\n",
            "Validation Step [0/6]\t Loss: 5.15235\n",
            "Epoch [57/100]\t Training Loss: 4.6518543737905995\t lr: 0.00123\n",
            "Epoch [57/100]\t Validation Loss: 5.16559910774231\t lr: 0.00123\n",
            "Epoch [57/100]\t Time Taken: 0.3230889360109965 minutes\n",
            "Epoch [58/100]\t\n",
            "Training Step [0/27]\t Loss: 4.59803\n",
            "Training Step [10/27]\t Loss: 4.62161\n",
            "Training Step [20/27]\t Loss: 4.65356\n",
            "Validation Step [0/6]\t Loss: 5.21184\n",
            "Epoch [58/100]\t Training Loss: 4.622479809655084\t lr: 0.00127\n",
            "Epoch [58/100]\t Validation Loss: 5.208185275395711\t lr: 0.00127\n",
            "Epoch [58/100]\t Time Taken: 0.31738436619440713 minutes\n",
            "Epoch [59/100]\t\n",
            "Training Step [0/27]\t Loss: 4.63583\n",
            "Training Step [10/27]\t Loss: 4.58598\n",
            "Training Step [20/27]\t Loss: 4.6392\n",
            "Validation Step [0/6]\t Loss: 5.22627\n",
            "Epoch [59/100]\t Training Loss: 4.631545596652561\t lr: 0.00132\n",
            "Epoch [59/100]\t Validation Loss: 5.238160212834676\t lr: 0.00132\n",
            "Epoch [59/100]\t Time Taken: 0.326209032535553 minutes\n",
            "Epoch [60/100]\t\n",
            "Training Step [0/27]\t Loss: 4.62511\n",
            "Training Step [10/27]\t Loss: 4.62963\n",
            "Training Step [20/27]\t Loss: 4.62693\n",
            "Validation Step [0/6]\t Loss: 5.17707\n",
            "Epoch [60/100]\t Training Loss: 4.625788529713948\t lr: 0.00137\n",
            "Epoch [60/100]\t Validation Loss: 5.172374804814656\t lr: 0.00137\n",
            "Epoch [60/100]\t Time Taken: 0.3246341864267985 minutes\n",
            "Epoch [61/100]\t\n",
            "Training Step [0/27]\t Loss: 4.57789\n",
            "Training Step [10/27]\t Loss: 4.59628\n",
            "Training Step [20/27]\t Loss: 4.58085\n",
            "Validation Step [0/6]\t Loss: 5.11398\n",
            "Epoch [61/100]\t Training Loss: 4.595986172004983\t lr: 0.00142\n",
            "Epoch [61/100]\t Validation Loss: 5.1841535568237305\t lr: 0.00142\n",
            "Epoch [61/100]\t Time Taken: 0.3237466931343079 minutes\n",
            "Epoch [62/100]\t\n",
            "Training Step [0/27]\t Loss: 4.58905\n",
            "Training Step [10/27]\t Loss: 4.61934\n",
            "Training Step [20/27]\t Loss: 4.61723\n",
            "Validation Step [0/6]\t Loss: 5.17202\n",
            "Epoch [62/100]\t Training Loss: 4.59930783730966\t lr: 0.00147\n",
            "Epoch [62/100]\t Validation Loss: 5.242589871088664\t lr: 0.00147\n",
            "Epoch [62/100]\t Time Taken: 0.3253731330235799 minutes\n",
            "Epoch [63/100]\t\n",
            "Training Step [0/27]\t Loss: 4.62397\n",
            "Training Step [10/27]\t Loss: 4.59574\n",
            "Training Step [20/27]\t Loss: 4.61757\n",
            "Validation Step [0/6]\t Loss: 5.24395\n",
            "Epoch [63/100]\t Training Loss: 4.620409312071623\t lr: 0.00152\n",
            "Epoch [63/100]\t Validation Loss: 5.226518154144287\t lr: 0.00152\n",
            "Epoch [63/100]\t Time Taken: 0.32469333012898766 minutes\n",
            "Epoch [64/100]\t\n",
            "Training Step [0/27]\t Loss: 4.61319\n",
            "Training Step [10/27]\t Loss: 4.59685\n",
            "Training Step [20/27]\t Loss: 4.62855\n",
            "Validation Step [0/6]\t Loss: 5.27112\n",
            "Epoch [64/100]\t Training Loss: 4.611398025795266\t lr: 0.00158\n",
            "Epoch [64/100]\t Validation Loss: 5.194252808888753\t lr: 0.00158\n",
            "Epoch [64/100]\t Time Taken: 0.3287965099016825 minutes\n",
            "Epoch [65/100]\t\n",
            "Training Step [0/27]\t Loss: 4.5914\n",
            "Training Step [10/27]\t Loss: 4.59665\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-f09aaec37c97>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Step [{step}/{len(train_loader)}]\\t Loss: {round(loss.item(), 5)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtr_loss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# for the first 10 epochs do a warmup of the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "nr = 0\n",
        "current_epoch = 0\n",
        "epochs = 100\n",
        "tr_loss = []\n",
        "val_loss = []\n",
        "\n",
        "# 1000 times do the following:\n",
        "for epoch in range(1000):\n",
        "\n",
        "    # print current epoch\n",
        "    print(f\"Epoch [{epoch}/{epochs}]\\t\")\n",
        "    stime = time.time()\n",
        "\n",
        "    # set model to training mode\n",
        "    net.train()\n",
        "    net.to('cuda:0')\n",
        "\n",
        "    # for the current epoch, set the training_loss to 0\n",
        "    tr_loss_epoch = 0\n",
        "\n",
        "    # training one epoch here, i.e. once through entire training dataset:\n",
        "    for step, (x_i, x_j) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x_i = x_i.squeeze().to('cuda:0').float()\n",
        "        x_j = x_j.squeeze().to('cuda:0').float()\n",
        "\n",
        "        # positive pair, with encoding\n",
        "        z_i, z_j = net(x_i, x_j)\n",
        "        #z_j = net(x_j)\n",
        "\n",
        "        # get the loss with the SimCLR_Loss Criterion\n",
        "        loss = criterion(z_i, z_j)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # every 10 steps print the loss at that step\n",
        "        if nr == 0 and step % 10 == 0:\n",
        "            print(f\"Training Step [{step}/{len(train_loader)}]\\t Loss: {round(loss.item(), 5)}\")\n",
        "\n",
        "        tr_loss_epoch += loss.item()\n",
        "\n",
        "    # for the first 10 epochs do a warmup of the learning rate\n",
        "    if nr == 0 and epoch < 10:\n",
        "        warmupscheduler.step()\n",
        "    # for the remaining epochs use the main scheduler (cosineannealingwarmrestarts) for learning rate updates\n",
        "    if nr == 0 and epoch >= 10:\n",
        "        mainscheduler.step()\n",
        "\n",
        "\n",
        "    lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    #every 5 epochs, save the model state dict, the optimizer state dict and the scheudler state dict\n",
        "    if nr == 0 and (epoch+1) % 5 == 0:\n",
        "        save_base_path = '/content/drive/MyDrive/Uni/TUB/Semester/5 - Masterarbeit/models/contrastive_learning/'\n",
        "        #save_path = os.path.join(\"checkpoints\", \"{}_{}_{}.cp\".format(RUNNAME, i, iou.item()))\n",
        "        save_path = save_base_path + '{}_{}_{}.cp'.format(RUNNAME, epoch, tr_loss_epoch)\n",
        "        torch.save(net.state_dict(), save_path)\n",
        "\n",
        "    # after the model has seen all teh training data once, immediatley do validation part\n",
        "    # this is different than in my pretext task where i did validation only every few epochs\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # set validation loss for this epoch to 0\n",
        "        val_loss_epoch = 0\n",
        "\n",
        "        # go though all the validation data\n",
        "        for step, (x_i, x_j) in enumerate(valid_loader):\n",
        "\n",
        "          x_i = x_i.squeeze().to('cuda:0').float()\n",
        "          x_j = x_j.squeeze().to('cuda:0').float()\n",
        "\n",
        "          # positive pair, with encoding\n",
        "          z_i, z_j = net(x_i, x_j)\n",
        "           #z_j = net(x_j)\n",
        "\n",
        "          loss = criterion(z_i, z_j)\n",
        "\n",
        "          # print the loss of the validation data\n",
        "          if nr == 0 and step % 50 == 0:\n",
        "              print(f\"Validation Step [{step}/{len(valid_loader)}]\\t Loss: {round(loss.item(),5)}\")\n",
        "\n",
        "          val_loss_epoch += loss.item()\n",
        "\n",
        "    # after training and validation, track losses and learning rates\n",
        "    if nr == 0:\n",
        "        # keep track of the mean losses\n",
        "        tr_loss.append(tr_loss_epoch / len(train_loader))\n",
        "        val_loss.append(val_loss_epoch / len(valid_loader))\n",
        "        print(f\"Epoch [{epoch}/{epochs}]\\t Training Loss: {tr_loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\")\n",
        "        print(f\"Epoch [{epoch}/{epochs}]\\t Validation Loss: {val_loss_epoch / len(valid_loader)}\\t lr: {round(lr, 5)}\")\n",
        "        current_epoch += 1\n",
        "\n",
        "    # track teh time each epoch takes\n",
        "    time_taken = (time.time()-stime)/60\n",
        "    print(f\"Epoch [{epoch}/{epochs}]\\t Time Taken: {time_taken} minutes\")\n",
        "\n",
        "\n",
        "save_base_path = '/content/drive/MyDrive/Uni/TUB/Semester/5 - Masterarbeit/models/contrastive_learning/'\n",
        "#save_path = os.path.join(\"checkpoints\", \"{}_{}_{}.cp\".format(RUNNAME, i, iou.item()))\n",
        "save_path = save_base_path + '{}_{}_{}.cp'.format(RUNNAME, epoch, tr_loss_epoch)\n",
        "torch.save(net.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK-fwziAsN9A"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(f'/content/drive/MyDrive/Uni/TUB/Semester/5 - Masterarbeit/models/contrastive_learning/{RUNNAME}.json', 'w') as f:\n",
        "    json.dump({'tr_loss': tr_loss,\n",
        "               'val_loss': val_loss}, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tr_loss), len(val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCkw5g2XIkQ8",
        "outputId": "d66d192e-a520-4544-81c0-860a3fa813c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "0BecVz0ywbDh",
        "outputId": "d3aa0689-f8ce-4921-ac69-c95f4c4959ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHWCAYAAABACtmGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADGLUlEQVR4nOzdd3hT1RvA8W+S7k2h0BbK3htBEJClIEsU3CBLUVRwoYgiDqoyRMSBP8WNC0ERcQAytEWmgMgS2RvKLKUtpSu5vz9OkzadSZtV+n6ep0+Se29uTnJv2/vmvOc9Ok3TNIQQQgghhBBCFEnv7gYIIYQQQgghhKeTwEkIIYQQQgghSiCBkxBCCCGEEEKUQAInIYQQQgghhCiBBE5CCCGEEEIIUQIJnIQQQgghhBCiBBI4CSGEEEIIIUQJJHASQgghhBBCiBJI4CSEEEIIIYQQJZDASQjhkUaOHEnt2rVL9dzJkyej0+kc2yAPc+TIEXQ6HXPnznX5a+t0OiZPnmx5PHfuXHQ6HUeOHCnxubVr12bkyJEObU9ZzhUhPIFOp+PRRx91dzOEECWQwEkIYRedTmfTT3x8vLubWuE9/vjj6HQ6Dhw4UOQ2kyZNQqfTsWPHDhe2zH6nTp1i8uTJbNu2zd1NsTAHrzNnznR3U1zu2LFjPPzww9SuXRtfX1+qVq3KwIEDWbdunbubVqji/lY9/PDD7m6eEKKc8HJ3A4QQ5ctXX31l9fjLL79k5cqVBZY3adKkTK/z8ccfYzKZSvXcF154geeee65Mr381uPfee5k9ezbz5s3jpZdeKnSbb7/9lhYtWtCyZctSv86wYcO455578PX1LfU+SnLq1CliY2OpXbs2rVu3tlpXlnNF2G/dunX069cPgAceeICmTZty+vRp5s6dS5cuXXjnnXd47LHH3NzKgnr16sXw4cMLLG/YsKEbWiOEKI8kcBJC2GXo0KFWjzdu3MjKlSsLLM8vLS2NgIAAm1/H29u7VO0D8PLywstL/rx16NCB+vXr8+233xYaOG3YsIHDhw8zffr0Mr2OwWDAYDCUaR9lUZZzRdjn4sWL3HHHHfj7+7Nu3Trq1atnWffUU0/Ru3dvnnzySdq2bUunTp1c1q709HR8fHzQ64tOpGnYsGGJf6eEEKI4kqonhHC47t2707x5c/7++2+6du1KQEAAzz//PAA//fQT/fv3Jzo6Gl9fX+rVq8err76K0Wi02kf+cSt506I++ugj6tWrh6+vL9deey2bN2+2em5hY5zMYwgWL15M8+bN8fX1pVmzZvz2228F2h8fH0+7du3w8/OjXr16fPjhhzaPm1qzZg133nknNWvWxNfXl5iYGMaNG8eVK1cKvL+goCBOnjzJwIEDCQoKIiIigvHjxxf4LJKSkhg5ciShoaGEhYUxYsQIkpKSSmwLqF6nPXv2sHXr1gLr5s2bh06nY/DgwWRmZvLSSy/Rtm1bQkNDCQwMpEuXLsTFxZX4GoWNcdI0jddee40aNWoQEBBAjx49+Pfffws8NzExkfHjx9OiRQuCgoIICQmhb9++bN++3bJNfHw81157LQD33XefJcXKPL6rsDFOly9f5umnnyYmJgZfX18aNWrEzJkz0TTNajt7zovSOnv2LKNGjaJatWr4+fnRqlUrvvjiiwLbzZ8/n7Zt2xIcHExISAgtWrTgnXfesazPysoiNjaWBg0a4OfnR+XKlbn++utZuXKl1X727NnDHXfcQXh4OH5+frRr146ff/7Zahtb95Xfhx9+yOnTp3njjTesgiYAf39/vvjiC3Q6Ha+88goAW7ZsQafTFfp+ly9fjk6n49dff7UsO3nyJPfffz/VqlWzHIvPPvvM6nnx8fHodDrmz5/PCy+8QPXq1QkICCA5ObnYttsi79+uTp064e/vT506dZgzZ06BbW09riaTiXfeeYcWLVrg5+dHREQEffr0YcuWLQW2Lek8TElJ4cknn7RKkezVq1ehv99CCMeTr2SFEE5x4cIF+vbtyz333MPQoUOpVq0aoC6yg4KCeOqppwgKCuKPP/7gpZdeIjk5mTfeeKPE/c6bN4+UlBQeeughdDodM2bM4LbbbuPQoUMl9jysXbuWRYsWMWbMGIKDg3n33Xe5/fbbOXbsGJUrVwbgn3/+oU+fPkRFRREbG4vRaOSVV14hIiLCpvf9/fffk5aWxiOPPELlypXZtGkTs2fP5sSJE3z//fdW2xqNRnr37k2HDh2YOXMmq1at4s0336RevXo88sgjgApAbr31VtauXcvDDz9MkyZN+PHHHxkxYoRN7bn33nuJjY1l3rx5XHPNNVav/d1339GlSxdq1qzJ+fPn+eSTTxg8eDAPPvggKSkpfPrpp/Tu3ZtNmzYVSI8ryUsvvcRrr71Gv3796NevH1u3buWmm24iMzPTartDhw6xePFi7rzzTurUqcOZM2f48MMP6datG7t37yY6OpomTZrwyiuv8NJLLzF69Gi6dOkCUGSPhqZp3HLLLcTFxTFq1Chat27N8uXLeeaZZzh58iRvvfWW1fa2nBeldeXKFbp3786BAwd49NFHqVOnDt9//z0jR44kKSmJJ554AoCVK1cyePBgbrzxRl5//XUA/vvvP9atW2fZZvLkyUybNo0HHniA9u3bk5yczJYtW9i6dSu9evUC4N9//6Vz585Ur16d5557jsDAQL777jsGDhzIDz/8wKBBg2zeV2F++eUX/Pz8uOuuuwpdX6dOHa6//nr++OMPrly5Qrt27ahbty7fffddgXN2wYIFVKpUid69ewNw5swZrrvuOkswGxERwbJlyxg1ahTJyck8+eSTVs9/9dVX8fHxYfz48WRkZODj41PssUhPT+f8+fMFloeEhFg99+LFi/Tr14+77rqLwYMH89133/HII4/g4+PD/fffD9h+XAFGjRrF3Llz6du3Lw888ADZ2dmsWbOGjRs30q5dO8t2tpyHDz/8MAsXLuTRRx+ladOmXLhwgbVr1/Lff/9Z/X4LIZxEE0KIMhg7dqyW/09Jt27dNECbM2dOge3T0tIKLHvooYe0gIAALT093bJsxIgRWq1atSyPDx8+rAFa5cqVtcTERMvyn376SQO0X375xbLs5ZdfLtAmQPPx8dEOHDhgWbZ9+3YN0GbPnm1ZNmDAAC0gIEA7efKkZdn+/fs1Ly+vAvssTGHvb9q0aZpOp9OOHj1q9f4A7ZVXXrHatk2bNlrbtm0tjxcvXqwB2owZMyzLsrOztS5dumiA9vnnn5fYpmuvvVarUaOGZjQaLct+++03DdA+/PBDyz4zMjKsnnfx4kWtWrVq2v3332+1HNBefvlly+PPP/9cA7TDhw9rmqZpZ8+e1Xx8fLT+/ftrJpPJst3zzz+vAdqIESMsy9LT063apWnqWPv6+lp9Nps3by7y/eY/V8yf2WuvvWa13R133KHpdDqrc8DW86Iw5nPyjTfeKHKbt99+WwO0r7/+2rIsMzNT69ixoxYUFKQlJydrmqZpTzzxhBYSEqJlZ2cXua9WrVpp/fv3L7ZNN954o9aiRQur3yWTyaR16tRJa9CggV37KkxYWJjWqlWrYrd5/PHHNUDbsWOHpmmaNnHiRM3b29vq9zYjI0MLCwuzOrdGjRqlRUVFaefPn7fa3z333KOFhoZafrfi4uI0QKtbt26hv2+FAYr8+fbbby3bmf92vfnmm1Ztbd26tVa1alUtMzNT0zTbj+sff/yhAdrjjz9eoE15fzdsPQ9DQ0O1sWPH2vSehRCOJ6l6Qgin8PX15b777iuw3N/f33I/JSWF8+fP06VLF9LS0tizZ0+J+7377rupVKmS5bG59+HQoUMlPrdnz55W6UUtW7YkJCTE8lyj0ciqVasYOHAg0dHRlu3q169P3759S9w/WL+/y5cvc/78eTp16oSmafzzzz8Fts9f0atLly5W72Xp0qV4eXlZeqBAjSmyZ/D90KFDOXHiBH/++adl2bx58/Dx8eHOO++07NP8rbvJZCIxMZHs7GzatWtndxrQqlWryMzM5LHHHrNKb8zfYwDqPDGPSzEajVy4cIGgoCAaNWpU6vSjpUuXYjAYePzxx62WP/3002iaxrJly6yWl3RelMXSpUuJjIxk8ODBlmXe3t48/vjjpKamsnr1agDCwsK4fPlysalyYWFh/Pvvv+zfv7/Q9YmJifzxxx/cddddlt+t8+fPc+HCBXr37s3+/fs5efKkTfsqSkpKCsHBwcVuY15vTp27++67ycrKYtGiRZZtVqxYQVJSEnfffTegegl/+OEHBgwYgKZplrafP3+e3r17c+nSpQLnw4gRI6x+30py6623snLlygI/PXr0sNrOy8uLhx56yPLYx8eHhx56iLNnz/L3338Dth/XH374AZ1Ox8svv1ygPflTf205D8PCwvjrr784deqUze9bCOE4EjgJIZyievXqhabO/PvvvwwaNIjQ0FBCQkKIiIiwDNi+dOlSifutWbOm1WNzEHXx4kW7n2t+vvm5Z8+e5cqVK9SvX7/AdoUtK8yxY8cYOXIk4eHhlnFL3bp1Awq+P/N4h6LaA3D06FGioqIICgqy2q5Ro0Y2tQfgnnvuwWAwMG/ePEClLP3444/07dvXKgj94osvaNmypWXMS0REBEuWLLHpuOR19OhRABo0aGC1PCIiwur1QAVpb731Fg0aNMDX15cqVaoQERHBjh077H7dvK8fHR1d4ALfXOnR3D6zks6Lsjh69CgNGjQoULQgf1vGjBlDw4YN6du3LzVq1OD+++8vML7llVdeISkpiYYNG9KiRQueeeYZqzLyBw4cQNM0XnzxRSIiIqx+zBfuZ8+etWlfRQkODiYlJaXYbczrzZ9/q1ataNy4MQsWLLBss2DBAqpUqcINN9wAwLlz50hKSuKjjz4q0HbzFzDmtpvVqVOnxPbmVaNGDXr27Fngx5xGbBYdHU1gYKDVMnPlPfM4PluP68GDB4mOjiY8PLzE9tlyHs6YMYNdu3YRExND+/btmTx5skMCfCGEbSRwEkI4RWHfBCclJdGtWze2b9/OK6+8wi+//MLKlSstYzpsKSldVPU2Ld+gf0c/1xZGo5FevXqxZMkSnn32WRYvXszKlSstRQzyvz9XVaIzDyD/4YcfyMrK4pdffiElJYV7773Xss3XX3/NyJEjqVevHp9++im//fYbK1eu5IYbbnBqqe+pU6fy1FNP0bVrV77++muWL1/OypUradasmctKjDv7vLBF1apV2bZtGz///LNlfFbfvn2txgV17dqVgwcP8tlnn9G8eXM++eQTrrnmGj755BMg9/waP358oT0rK1eutHwBUNK+itKkSRP27t1LRkZGkdvs2LEDb29vq8D57rvvJi4ujvPnz5ORkcHPP//M7bffbql+aW770KFDi2x7586drV7Hnt6m8sCW8/Cuu+7i0KFDzJ49m+joaN544w2aNWtWoBdVCOEcUhxCCOEy8fHxXLhwgUWLFtG1a1fL8sOHD7uxVbmqVq2Kn59foRPGFjeJrNnOnTvZt28fX3zxhdV8MSVVKitOrVq1+P3330lNTbXqddq7d69d+7n33nv57bffWLZsGfPmzSMkJIQBAwZY1i9cuJC6deuyaNEiqxSiwlKMbGkzwP79+6lbt65l+blz5wr04ixcuJAePXrw6aefWi1PSkqiSpUqlse2VDTM+/qrVq0qkFZmTgU1t88VatWqxY4dOzCZTFa9E4W1xcfHhwEDBjBgwABMJhNjxozhww8/5MUXX7QEPOHh4dx3333cd999pKam0rVrVyZPnswDDzxg+ay9vb3p2bNniW0rbl9Fufnmm9mwYQPff/99oaW9jxw5wpo1a+jZs6dVYHP33XcTGxvLDz/8QLVq1UhOTuaee+6xrI+IiCA4OBij0WhT253p1KlTXL582arXad++fQCW6o22Htd69eqxfPlyEhMTbep1skVUVBRjxoxhzJgxnD17lmuuuYYpU6bYnE4shCg96XESQriM+RvVvN+gZmZm8v7777urSVYMBgM9e/Zk8eLFVmMIDhw4YNM3uoW9P03TrEpK26tfv35kZ2fzwQcfWJYZjUZmz55t134GDhxIQEAA77//PsuWLeO2227Dz8+v2Lb/9ddfbNiwwe429+zZE29vb2bPnm21v7fffrvAtgaDoUDPzvfff28Zi2Nmvoi1pQx7v379MBqNvPfee1bL33rrLXQ6nUsvMPv168fp06et0tSys7OZPXs2QUFBljTOCxcuWD1Pr9dbJiU29+7k3yYoKIj69etb1letWpXu3bvz4YcfkpCQUKAt586ds9wvaV9Feeihh6hatSrPPPNMgRSx9PR07rvvPjRNKzBvWJMmTWjRogULFixgwYIFREVFWX15YjAYuP322/nhhx/YtWtXsW13tuzsbD788EPL48zMTD788EMiIiJo27YtYPtxvf3229E0jdjY2AKvY2+PptFoLJC+WrVqVaKjo0s8bkIIx5AeJyGEy3Tq1IlKlSoxYsQIHn/8cXQ6HV999ZVLU6JKMnnyZFasWEHnzp155JFHLBfgzZs3Z9u2bcU+t3HjxtSrV4/x48dz8uRJQkJC+OGHH8o0VmbAgAF07tyZ5557jiNHjtC0aVMWLVpk9/ifoKAgBg4caBnnlDdND1RPwqJFixg0aBD9+/fn8OHDzJkzh6ZNm5KammrXa5nno5o2bRo333wz/fr1459//mHZsmVWvUjm133llVe477776NSpEzt37uSbb76x6qkC9c19WFgYc+bMITg4mMDAQDp06FDoOJcBAwbQo0cPJk2axJEjR2jVqhUrVqzgp59+4sknnyww/1BZ/f7776SnpxdYPnDgQEaPHs2HH37IyJEj+fvvv6lduzYLFy5k3bp1vP3225YesQceeIDExERuuOEGatSowdGjR5k9ezatW7e2jJtp2rQp3bt3p23btoSHh7NlyxZLaWqz//3vf1x//fW0aNGCBx98kLp163LmzBk2bNjAiRMnLPNj2bKvwlSuXJmFCxfSv39/rrnmGh544AGaNm3K6dOnmTt3LgcOHOCdd94ptFT83XffzUsvvYSfnx+jRo0qMD5o+vTpxMXF0aFDBx588EGaNm1KYmIiW7duZdWqVSQmJtp3YPLZt28fX3/9dYHl1apVsyrBHh0dzeuvv86RI0do2LAhCxYsYNu2bXz00UeWKQ9sPa49evRg2LBhvPvuu+zfv58+ffpgMplYs2YNPXr0KPHzzislJYUaNWpwxx130KpVK4KCgli1ahWbN2/mzTffLNNnI4SwkYur+AkhrjJFlSNv1qxZoduvW7dOu+666zR/f38tOjpamzBhgrZ8+XIN0OLi4izbFVWOvLDSz+Qrj11UOfLCyvjWqlXLqjy2pmna77//rrVp00bz8fHR6tWrp33yySfa008/rfn5+RXxKeTavXu31rNnTy0oKEirUqWK9uCDD1rKCuctpT1ixAgtMDCwwPMLa/uFCxe0YcOGaSEhIVpoaKg2bNgw7Z9//rG5HLnZkiVLNECLiooqUALcZDJpU6dO1WrVqqX5+vpqbdq00X799dcCx0HTSi5HrmmaZjQatdjYWC0qKkrz9/fXunfvru3atavA552enq49/fTTlu06d+6sbdiwQevWrZvWrVs3q9f96aeftKZNm1pKw5vfe2FtTElJ0caNG6dFR0dr3t7eWoMGDbQ33njDqgS0+b3Yel7kZz4ni/r56quvNE3TtDNnzmj33XefVqVKFc3Hx0dr0aJFgeO2cOFC7aabbtKqVq2q+fj4aDVr1tQeeughLSEhwbLNa6+9prVv314LCwvT/P39tcaNG2tTpkyxlMg2O3jwoDZ8+HAtMjJS8/b21qpXr67dfPPN2sKFC+3eV3Hv/cEHH9Rq1qypeXt7a1WqVNFuueUWbc2aNUU+Z//+/ZbPZu3atYVuc+bMGW3s2LFaTEyM5u3trUVGRmo33nij9tFHH1m2MZcj//77721qq6YVX44873lm/tu1ZcsWrWPHjpqfn59Wq1Yt7b333iu0rSUdV01Tpf7feOMNrXHjxpqPj48WERGh9e3bV/v777+t2lfSeZiRkaE988wzWqtWrbTg4GAtMDBQa9Wqlfb+++/b/DkIIcpGp2ke9FWvEEJ4qIEDB5aqfLMQovzo3r0758+fLzRdUAghZIyTEELkc+XKFavH+/fvZ+nSpXTv3t09DRJCCCGE28kYJyGEyKdu3bqMHDmSunXrcvToUT744AN8fHyYMGGCu5smhBBCCDeRwEkIIfLp06cP3377LadPn8bX15eOHTsyderUAhO6CiGEEKLikDFOQgghhBBCCFECGeMkhBBCCCGEECWQwEkIIYQQQgghSlDhxjiZTCZOnTpFcHAwOp3O3c0RQgghhBBCuImmaaSkpBAdHV1gYu78KlzgdOrUKWJiYtzdDCGEEEIIIYSHOH78ODVq1Ch2mwoXOAUHBwPqwwkJCXH4/rOyslixYgU33XQT3t7eDt+/cB45duWTHLfySY5b+STHrXyS41Y+yXFzjeTkZGJiYiwxQnEqXOBkTs8LCQlxWuAUEBBASEiInOTljBy78kmOW/kkx618kuNWPslxK5/kuLmWLUN4pDiEEEIIIYQQQpRAAichhBBCCCGEKIEETkIIIYQQQghRggo3xskWmqaRnZ2N0Wi0+7lZWVl4eXmRnp5equcL93HFsTMYDHh5eUkpfCGEEEKIckYCp3wyMzNJSEggLS2tVM/XNI3IyEiOHz8uF8fljKuOXUBAAFFRUfj4+DjtNYQQQgghhGNJ4JSHyWTi8OHDGAwGoqOj8fHxsfsC2mQykZqaSlBQUImTaAnP4uxjp2kamZmZnDt3jsOHD9OgQQM5R4QQQgghygkJnPLIzMzEZDIRExNDQEBAqfZhMpnIzMzEz89PLorLGVccO39/f7y9vTl69KjltYQQQgghhOeTK/tCSMAjnEnOLyGEEEKI8keu4IQQQgghhBCiBBI4CSGEEEIIIUQJJHByEqNJY8PBC/y07SQbDl7AaNLc3SS71a5dm7ffftvm7ePj49HpdCQlJTmtTUIIIYS4CsVNg9UzCl+3eoZaL4SbSXEIJ/h97wXe+P1vTienW5ZFhfrx8oCm9Gke5fDXK6ny38svv8zkyZPt3u/mzZsJDAy0eftOnTqRkJBAaGio3a9lj/j4eHr06MHFixcJCwtz6msJIYQQwgX0Boibou53m5C7fPUMtbzHJPe0S4g8JHBysN92nWb8j3vI3790+lI6j3y9lQ+GXuPw4CkhIcFyf8GCBbz00kvs3bvXsiwoKMhyX9M0jEYjXl4lH/qIiAi72uHj40NkZKRdzxFCCCGEsARLeYOnvEFT3mBKCDeRVL0SaJpGWma2TT8p6VnE/rq7QNAEWJZN/nk3KelZNu1P02xL74uMjLT8hIaGotPpLI/37NlDcHAwy5Yto23btvj6+rJ27VoOHjzIrbfeSrVq1QgKCuLaa69l1apVVvvNn6qn0+n45JNPGDRoEAEBATRo0ICff/7Zsj5/qt7cuXMJCwtj+fLlNGnShKCgIPr06WMV6GVnZ/P4448TFhZG5cqVefbZZxkxYgQDBw606b0X5uLFiwwfPpxKlSoREBBA37592b9/v2X90aNHGTBgAJUqVSIwMJBmzZqxdOlSAJKSkhg6dCgRERH4+/vToEEDPv/881K3RQghhBA26jYBuj+vgqXYcAmahMeRHqcSXMky0vSl5Q7ZlwacTk6nxeQVNm2/+5XeBPg45hA999xzzJw5k7p161KpUiWOHz9Ov379mDJlCr6+vnz55ZcMGDCAvXv3UrNmzSL3Exsby4wZM3jjjTeYPXs29957L0ePHiU8PLzQ7dPS0pg5cyZfffUVer2eoUOHMn78eL755hsAXn/9db755hs+//xzmjRpwjvvvMPixYvp0aNHqd/ryJEj2b9/Pz///DMhISE8++yz9OvXj927d+Pt7c3YsWPJzMzkzz//JDAwkN27d1t65aZMmcJ///3HsmXLqFKlCgcOHODKlSulbosQQggh7NB2JMRPBc0IBh8JmoRHkcCpgnjllVfo1auX5XF4eDitWrWyPH711Vf58ccf+fnnn3n00UeL3M/IkSMZPHgwAFOnTuXdd99l06ZN9OnTp9Dts7KymDNnDvXq1QPg0Ucf5ZVXXrGsnz17NhMnTmTQoEEAvPfee5ben9IwB0zr1q2jU6dOAHzzzTfExMSwePFi7rzzTo4dO8btt99OixYtAKhbty6gJsA9ceIErVu3pl27doDqdRNCCCGEi6ydlXvfmKnS9SR4Eh5CAqcS+Hsb2P1Kb5u23XQ4kZGfby5xu7n3XUv7OoX30OR/bUcxBwJmqampTJ48mSVLlpCQkEB2djZXrlzh2LFjxe6nZcuWlvuBgYGEhIRw9uzZIrcPCAiwBE0AUVFRlu0vXbrEmTNnaN++vWW9wWCgbdu2mEwmu96f2X///YeXlxcdOnSwLKtcuTKNGjXiv//+A+Dxxx/nkUceYcWKFfTs2ZPbb7/d8r7uv/9+RowYwT///MNNN93EwIEDLQGYEEIIIZxo9Qz4a07u4+seKbxghBBuImOcSqDT6Qjw8bLpp0uDCCJD/Ciqxp0OVV2vS4MIm/ZXUrU8e+Svjjd+/Hh+/PFHpk6dypo1a9i2bRstWrQgMzOz2P14e3tbvyedrtggp7DtbR275SwPPPAAhw4dYtiwYezcuZN27doxe/ZsAHr16sXhw4cZN24cp06d4sYbb2T8+PFuba8QQghx1TMXgmh9b+6ylveoMU5xU4ouVS6EC0ng5EAGvY6Xbm4CUCB4Mj9+eUBTDHrHBUSltW7dOkaOHMmgQYNo0aIFkZGRHDlyxKVtCA0NpVq1amzenNtLZzQa2bp1a6n32aRJE7Kzs/nrr78syy5cuMDevXtp2rSpZVlMTAwPP/wwixYt4umnn+bjjz+2rIuIiGDEiBF8/fXXvP3223z00Uelbo8QQgghbGAyqiCpyS25yzKSVU9Tj0lqvRBuJql6DtaneSQzBzXmjd+PWM3jFOnEeZxKo0GDBixatIgBAwag0+l48cUXS50eVxaPPfYY06ZNo379+jRu3JjZs2dz8eJFm3rbdu7cSXBwsOWxTqejVatW3HrrrTz44IN8+OGHBAcH89xzz1G9enVuvfVWAJ588kn69u1Lw4YNuXjxInFxcTRpogLeqVOn0rFjR1q0aEFGRga//vqrZZ0QQgghnKTHRHW7c2HusvRL6lbS9ISHkMDJCW5sVJlb2tZmy9EkzqakUzXYj/Z1wj2ip8ls1qxZ3H///XTq1IkqVarw7LPPkpyc7PJ2PPvss5w+fZrhw4djMBgYPXo0vXv3xmAoeXxX165drR4bDAays7P5/PPPeeKJJ7j55pvJzMyka9euLF261JI2aDQaGTt2LCdOnCAkJIQ+ffrw1ltvAWouqkmTJnHkyBH8/f3p0qUL8+fPd/wbF0IIIURBmam599Ndf10iRHF0mrsHnLhYcnIyoaGhXLp0iZCQEKt16enpHD58mDp16uDn51eq/ZtMJpKTkwkJCUGvl0xIe5lMJpo0acJdd93Fq6++6vLXdsWxc8R5JnJlZWWxdOlS+vXrV2BMnfBcctzKJzlu5VO5Om7r34MVk9T9PtNVgYgKqlwdt3KsuNggP+lxEm519OhRVqxYQbdu3cjIyOC9997j8OHDDBkyxN1NE0IIIYSrZV7OvW9O1RPCQ0iXiHArvV7P3Llzufbaa+ncuTM7d+5k1apVMq5ICCGEqIgyU3LvS6qe8DDS4yTcKiYmhnXr1rm7GUIIIYTwBBl5xjhlSI+T8CzS4ySEEEIIITyDVaqe9DgJzyKBkxBCCFHRxE0rekLR1TPUeiHcwaqqnvQ4Cc8igZMQQghR0egNEDelYPC0eoZari95SgghnCJv4JQhPU7Cs8gYJyGEEKKiMU8oGjcFzvwLXZ6Gfb+pxz0myYSjwn0yZB4n4bkkcBJCCCEqom4TIPUsbP4Ydv8EaBI0CfeTcuTCg0mqnhBCCFFR1e+Zc0cDg48ETcL9JFVPeDAJnIRF9+7defLJJy2Pa9euzdtvv13sc3Q6HYsXLy7zaztqP0IIIezwz1e5942ZRReMEMJV8qbqGTMhK919bREiHwmcHEwXPx3fv94pfKWTKhUNGDCAPn36FLpuzZo16HQ6duzYYfd+N2/ezOjRo8vaPCuTJ0+mdevWBZYnJCTQt29fh75WfnPnziUsLMypryGEEOXG6hmw59fcx12fKbxghBCuomnWPU4g6XrCo7g9cDp58iRDhw6lcuXK+Pv706JFC7Zs2VLsc+Lj47nmmmvw9fWlfv36zJ071zWNtYGmN+C/YRb8+Yb1CidWKho1ahQrV67kxIkTBdZ9/vnntGvXjpYtW9q934iICAICAhzRxBJFRkbi6+vrktcSQogKz/w/qeZ1ucuufVCNcZLgSbhLdjpoRnVfnzMMX9L1hAdxa+B08eJFOnfujLe3N8uWLWP37t28+eabVKpUqcjnHD58mP79+9OjRw+2bdvGk08+yQMPPMDy5cud00hNUwMVbf25bgxX2j+GPn4q/PGaWvbHa+ofUddnoONY2/elaTY18eabbyYiIqJAAJmamsr333/PqFGjuHDhAoMHD6Z69eoEBATQokULvv3222L3mz9Vb//+/XTt2hU/Pz+aNm3KypUrCzzn2WefpWHDhgQEBFC3bl1efPFFsrKyANXjExsby/bt29HpdOh0Okub86fq7dy5kxtuuAF/f38qV67M6NGjSU3N/RZq5MiRDBw4kJkzZxIVFUXlypUZO3as5bVK49ixYwwZMoSQkBBCQkK46667OHPmjGX99u3b6dGjB8HBwYSEhNC2bVtLkH/06FEGDBhApUqVCAwMpFmzZixdurTUbRFCCKcyGVWQVLl+7rKMZDXGqccktV4IV8tbGCKomrqVynrCg7i1qt7rr79OTEwMn3/+uWVZnTp1in3OnDlzqFOnDm+++SYATZo0Ye3atbz11lv07t27wPYZGRlkZGRYHicnq1/ArKysAhfZWVlZaJqGyWTCZDKphZmX0U+vYfN70gP+5gd/vmHd85T/cQlMz50An8CSX1OvZ9iwYcydO5eJEyei0+kAWLBgAUajkbvvvpvU1FSuueYannnmGUJCQli6dCnDhg2jTp06tG/f3rIv8/vP/9hkMnHbbbdRrVo1NmzYwKVLl3jqqadUO/N8XkFBQXz22WdER0ezc+dOHnroIYKCgnjmmWe488472blzJ8uXL2fFihUAhIaGWp5r3s/ly5fp3bs31113HX/99Rdnz55l9OjRjB071nKuaJpGXFwckZGR/P777xw4cIDBgwfTsmVLHnzwwcI/zzyvU9i6QYMG4efnxx9//IHRaOSxxx7j7rvv5o8//gDg3nvvpXXr1vzvf//DYDCwbds2DAYDJpOJMWPGkJmZSXx8PIGBgezevZuAgIAiX0vTNLKysjAYZK6UsjL/HpclaBauJ8fNza4fD4Dhu6GWb1CzUxPRQrOg0zi1oJBjI8etfCo3x+3yRbwBzTsQ/MLQJZ8k+/IFNE9vt5OUm+NWztnz+bo1cPr555/p3bs3d955J6tXr6Z69eqMGTOmyAtfgA0bNtCzZ0+rZb1797YqapDXtGnTiI2NLbB8xYoVBdLQvLy8iIyMJDU1lczMTLUwK40wu96V4ySnpIC3bd/63XnnncycOZNly5Zx/fXXA/Dpp58yYMAAdDodwcHBVp/r8OHDWbJkCd988w2NGzcGIDs7m8zMTEtwaTKZSE9PJzk5mT/++IM9e/bw3XffERUVBcDzzz/PnXfeyZUrVyzPeeyxxyyv0a1bN8aOHcv8+fN56KGHAPD29kan01k++7wBrHk/X3zxBVeuXGH27NkEBgZSs2ZNpk+fzuDBg5k0aRJVq1YlKyuL0NBQpkyZgsFgIDo6mptuuonly5dz9913F/oZpaeno2mapa15xcXFsXPnTrZt20aNGipQfu+99+jYsaMlNfTYsWOMHTuW6OhoAEugnpyczJEjR7jllluoVasWAF27drWsyy8zM5MrV67w559/kp2dXdxhFXYorAdUeD45bu7V5dQBwnPub1qzinMhp216nhy38snTj1tI2jF6ABmaF6mXs6kC/LNhNaf2XHF309zK049beZeWlmbztm4NnA4dOsQHH3zAU089xfPPP8/mzZt5/PHH8fHxYcSIEYU+5/Tp01SrVs1qWbVq1UhOTubKlSv4+/tbrZs4caKlZwTUhWxMTAw33XQTISEhVtump6dz/PhxgoKC8PPzUwu1YNXzYyNN00hJTSVk+yfo176JZvBBZ8zE1GU8dH7S5v0AhHgHQE7vUUnatWtHp06dWLBgAf369ePAgQNs2LCB1157jZCQEIxGI9OmTeP777/n5MmTZGZmkpGRYUlLAxU4+vj4WB7r9Xr8/PwICQnh2LFjxMTE0KhRI8tr3njjjQD4+/tbnrNgwQLee+89Dh48SGpqKtnZ2Vav4evri8FgKPDZ593PkSNHaN26tSVAA+jVqxcmk4lTp05Rv359vL29ad68uVVaZ0xMDLt27Sp03wB+fn7odLpC15vfX40aNQgODkan09G+fXvCwsI4duwY3bt3Z9y4cTz++OP88MMP3Hjjjdxxxx3Uq1cPgCeeeIKxY8fy559/cuONN3LbbbcVOa4sPT0df39/S9qjKJusrCxWrlxJr1698Pb2dndzhI3kuHkGr6OTISc7qn3rJmiN+xW7vRy38qm8HDfd8b9gL/gGh+NTuRYc2EubpvVo3ab48/JqVV6OW3lX2JfcRXFr4GQymWjXrh1Tp04FoE2bNuzatYs5c+YUGTjZy9fXt9CiA97e3gVOQqPRiE6nQ6/Xo9fnGf5lCLb59UwmE75/voV+wyzoMQldtwmwegb6uCng5evUOTJGjRrFY489xvvvv88XX3xBvXr16NGjBzqdjhkzZvDuu+/y9ttv06JFCwIDA3nyySfJysqyeq/m95//sTn9L+86833z57VhwwaGDRtGbGwsvXv3JjQ0lPnz5/Pmm29ati1sP3n3Z+tr6XQ6fHx8CmxjMpkK3Xf+feSnyxOg5v8MzK8ZGxvLvffey5IlS1i2bBmTJ09m/vz5DBo0iNGjR9O3b1+WLFnCihUrmD59Om+++aZVD1ze/el0ukLPQVF68nmWT3Lc3Cwt0XLXKzsNbDwWctzKJ48/bkZVelznG4wuQH0x6pWVavN5ebXy+ONWztnz2bq1OERUVBRNmza1WtakSROOHTtW5HMiIyOtBuwDnDlzhpCQkAK9TW7x5xv4b5iFqfvzuUGSebCtkysV3XXXXej1eubNm8eXX37J/fffbwkI1q1bx6233srQoUNp1aoVdevWZd++fTbvu0mTJhw/fpyEhATLso0bN1pts379emrVqsWkSZNo164dDRo04OjRo1bb+Pj4YDQWn37YpEkTtm/fzuXLuYNE161bh16vt+rxciTz+8tbmXD37t0kJSVZnaMNGzZk3LhxrFixgttuu81qfF5MTAwPP/wwixYt4umnn+bjjz92SluFEMIhjFmQnpT7WAbhC3czlyL3CQLfnOwQqaonPIhbA6fOnTuzd+9eq2X79u2zjBMpTMeOHfn999+tlq1cuZKOHTs6pY320pmMXOn4lKqgl5cLKhUFBQVx9913M3HiRBISEhg5cqRlXYMGDVi5ciXr16/nv//+46GHHioQgBanZ8+eNGzYkBEjRrB9+3bWrFnDpEmTrLZp0KABx44dY/78+Rw8eJB3332XH3/80Wqb2rVrc/jwYbZt28b58+etCneY3Xvvvfj5+TFixAh27dpFXFwcjz32GMOGDSuQpmkvo9HItm3brH7+++8/evbsSYsWLRg9ejRbt25l06ZNDB8+nG7dutGuXTuuXLnCo48+Snx8PEePHmXdunVs3ryZJk2aAPDkk0+yfPlyDh8+zNatW4mLi7OsE0IIj3TlovVjuUAV7mYOnHyDwC8ncJKAXngQtwZO48aNY+PGjUydOpUDBw4wb948PvroI8aOHWvZZuLEiQwfPtzy+OGHH+bQoUNMmDCBPXv28P777/Pdd98xbtw4d7yFArTuz5HR4YnCV3abAD0mOvX1R40axcWLF+ndu7eliAHACy+8wDXXXEPv3r3p3r07kZGRDBw40Ob96vV6fvzxR65cuUL79u154IEHmDJlitU2t9xyC+PGjePRRx+ldevWrF+/nhdffNFqm9tvv50+ffrQo0cPIiIiCi2JHhAQwPLly0lMTOTaa6/ljjvu4MYbb+S9996z78MoRGpqKm3atLH6MRfQ+PHHHwkLC6N79+707NmTunXrsmDBAgAMBgMXLlxg+PDhNGzYkLvuuou+fftaCo8YjUbGjh1LkyZN6NOnDw0bNuT9998vc3uFEMJp0i5YP85IcU87hDAzlyP3CQS/UHVfAnrhQXSaZuNkQU7y66+/MnHiRPbv30+dOnV46qmnrKq/jRw5kiNHjhAfH29ZFh8fz7hx49i9ezc1atTgxRdftOpdKU5ycjKhoaFcunSp0OIQhw8fpk6dOqUetG8ymUhOTiYkJKTIsTbCM7nq2DniPBO5srKyWLp0Kf369ZMc8HJEjpsHOLwGvrg593GbYXBr8V9QyXErn8rNcftzJvzxqjoXq7eFX5+ERv1gcPHzTl6tys1xK+eKiw3yc2txCFCTt958881Frs8/qStA9+7d+eeff5zYKiGEEOIqV6DHSb7ZF26Wd4yTpOoJDyRdIkIIIURFJKl6wtOYU/V8g8DXnKp3yX3tESIfCZyEEEKIisgcOAVGqFv5Zl+4W0beHqecwCldAifhOSRwEkIIISoic+BUqba6lR4n4W6WVL1ASdUTHkkCp0K4uV6GuMrJ+SWE8AjmwCm8rrqVMU7C3SzlyIOt53GS/5vCQ0jglIe5YklaWpqbWyKuZubzSyrkCCHc6vJ5dVupjrqVb/aFuxVWjlwz5QZUQriZ26vqeRKDwUBYWBhnz54F1HxCOp3Orn2YTCYyMzNJT0+XcuTljLOPnaZppKWlcfbsWcLCwjAYDA5/DSGEsFn+VL2sy2qSdr38bRJukneMk7c/6L3AlK2Cet9g97ZNCCRwKiAyMhLAEjzZS9M0rly5gr+/v91Bl3AvVx27sLAwy3kmhBBuk5aobsPr5C7LSAb/Su5pjxCZOePsfIJAp1PpelcSc9JIq7u1aUKABE4F6HQ6oqKiqFq1KllZWXY/Pysriz///JOuXbtKKlY544pj5+3tLT1NQgj30zRIy0nVC44ELz/ITlcFIiRwEu6Stxw5qHS9K4lSWU94DAmcimAwGEp1gWswGMjOzsbPz08Cp3JGjp0QosLISlOBEkBAZfXNfna6jHMS7pU3VQ+ksp7wODIIRwghhKhozOObDD45c+bkqWAmhDsYs8CYoe77BKpbXzkvhWeRwEkIIYSoaMwV9QKq5IwlyRl4L3M5CXfJWznPJ0+qHkB6ksubI0RhJHASQgghKhpzYYiAyurWV1KihJuZxzcZfMDLR923BE5yXgrPIIGTEEIIUdGYU/UCwtWtpcdJLlCFm+Qf3wSSqic8jgROQgghREVjrqgXWEXdmr/ZlwtU4S6ZhQRO0uMkPIwETkIIIURFY+lxklQ94SHMgZNv3sDJfF5KOXLhGSRwEkIIISqaAoGTFIcQbiapeqIckMBJCCGEqGgsVfVyAicpRy7czVwcwlyKHGQeJ+FxJHASQgghKpoCVfWkx0m4WWbOuedb2BgnSdUTnkECJyGEEKKikTFOwtNYepwkVU94LgmchBBCiIqmQFU98wWqfLMv3KSwMU5SVU94GC93N6AiM5o0Nh1O5GxKOlWD/WhfJxyDXufuZgkhhLiamYxw5aK6n7/HSVL1hLtYypHnHeOUEzhlpqjzVm9wfbuEyEMCJzf5bVcCsb/sJuFSumVZVKgfLw9oSp/mUW5smRBCiKta+iXQTOq+v3kCXEnVE25WWDly83kJKl3Pv5Jr2yREPpKq5wa/7Urgka+3WgVNAKcvpfPI11v5bVeCm1omhBDiqmeuqOcbCl4+OffNxSGSQdPc0y5RsVlS9YJzl3n5gJefui9BvfAAEji5mNGkEfvLbgr7t2ReFvvLbowm+cclhBDCCSyFIcJzl5nHOJmyITu94HOEcLbCypGDVNYTHkUCJxfbdDixQE9TXhqQcCmdTYcTXdcoIYQQFUf+inqQMyA/Z4ytfLMv3KGwVD2QynrCo0jg5GJnU2z7Js/W7YQQQgi75K+oB6DTSYEI4V6ZhVTVA5kEV3gUCZxcrGqwn0O3E0IIIexSWI8TSEly4V6FlSMHSdUTHkUCJxdrXyecqFA/iio6rkNV12tfJ7yILYQQQogySMtJBQ/I93/GXCBCvtkX7lBYOXKQVD3hUSRwcjGDXsfLA5oWus4cTL08oKnM5ySEEMI5zFX1AqpYL5dUPeFO5uIQ+cc4Saqe8CASOLlBn+ZRfDD0GioH+lgtjwz144Oh18g8TkIIIZynxFQ9uUAVLmYy5elxCrZeZ07VkxRS4QFkAlw36dM8ikbVQujxZjw+Bh1f3N+B9nXCpadJCCGEcxUVOFnmcpIeJ+FiWWm59wuk6skYJ+E5pMfJjaoEqx6nTKNGm5phEjQJIYRwvsKq6kFuqp6kRAlXM/c26fTg7W+9TlL1hAeRwMmNgny98DaoYOliWqabWyOEEKJCsBSHKKrHSS5QhYtZJr8NUqXx87Kk6sl5KdxPAic30ul0hAWoXqfEyxI4CSGEcLKs9Nxv9/NX1ZMxTsJdzOmh+UuRQ56eUEnVE+4ngZObhecEThcvZ7m5JUIIIa565vFNOgP4hVmvs4wlkcBJuFhRpchBUvWER3Fr4DR58mR0Op3VT+PGjYt9zttvv02jRo3w9/cnJiaGcePGkZ6e7qIWO16lQG8AEiVVTwghhLPlLQyRPyVKikMIdymqFDnIPE7Co7i9ql6zZs1YtWqV5bGXV9FNmjdvHs899xyfffYZnTp1Yt++fYwcORKdTsesWbNc0VyHC88pSZ4kgZMQQghnK6qiHkiqnnCf4lL1/KSqnvAcbg+cvLy8iIyMtGnb9evX07lzZ4YMGQJA7dq1GTx4MH/99Zczm+hUlWSMkxBCCFcxB075K+qBVNUT7pO3OER+5oA+Ox2yM8HLp+A2QriI2wOn/fv3Ex0djZ+fHx07dmTatGnUrFmz0G07derE119/zaZNm2jfvj2HDh1i6dKlDBs2rMj9Z2RkkJGRYXmcnKz+IWRlZZGV5fhxReZ92rrvUD91CC6kpDulPcJ29h474RnkuJVPctzcQ59yFgNg8quEMf9nb/DHG9Ayksku4rjIcSufPP246a9cUueld0DB81KvzkuArNQLhQf9VylPP25XC3s+X52maZoT21KsZcuWkZqaSqNGjUhISCA2NpaTJ0+ya9cugoODC33Ou+++y/jx49E0jezsbB5++GE++OCDIl9j8uTJxMbGFlg+b948AgICHPZeSis+QcePRwxcU9nEiIYmdzdHCCHEVaxRwiIan17M4So3sCNmpNW6gIwz9Nr9DNl6P5a0+sg9DRQVUsPTi2mSsIgjlXuwveZ9Bdb32z4ab1M6q5rM4LKfbVlKQtgqLS2NIUOGcOnSJUJCQord1q2BU35JSUnUqlWLWbNmMWrUqALr4+Pjueeee3jttdfo0KEDBw4c4IknnuDBBx/kxRdfLHSfhfU4xcTEcP78+RI/nNLIyspi5cqV9OrVC29v7xK3/2l7AuMX7qRTvXC+GNnO4e0RtrP32AnPIMetfJLj5h76Zc9g2Po5xuufxtRtovXKy+fxflsVaMqaeAb0hgLPl+NWPnn6cdP/PhnDxvcwdhiDqecrBdZ7vdsSXcopsu9biRbdxg0tdA9PP25Xi+TkZKpUqWJT4OT2VL28wsLCaNiwIQcOHCh0/YsvvsiwYcN44IEHAGjRogWXL19m9OjRTJo0Cb2+YJFAX19ffH19Cyz39vZ26klo6/4jQtQM2Ulp2fJL4SGcfW4I55DjVj7JcXOx9IsAGIKqYsj/uQflFozwNqWDb1iRu5HjVj557HHLTgPA4BdS8LwEVSAi5RRexjTwxPY7mccet6uEPZ+tR83jlJqaysGDB4mKiip0fVpaWoHgyGBQ34h5UMeZXSoFqIN1UarqCSGEcLbiqup5+YCXn7ovlfWEKxVXjhzyVNaT81K4l1sDp/Hjx7N69WqOHDnC+vXrGTRoEAaDgcGDBwMwfPhwJk7MTSUYMGAAH3zwAfPnz+fw4cOsXLmSF198kQEDBlgCqPImb1W98hr8CSGEKCcsVfUKCZxA5nIS7pFhngC3qMDJXPFRSpIL93Jrqt6JEycYPHgwFy5cICIiguuvv56NGzcSEREBwLFjx6x6mF544QV0Oh0vvPACJ0+eJCIiggEDBjBlyhR3vYUyM8/jlJFt4kqWkQAfj8qeFEIIcTUprscJVEnyy+fkm33hWpklBE4yCa7wEG69Sp8/f36x6+Pj460ee3l58fLLL/Pyyy87sVWuFeBjwMdLT2a2icTLmRI4CSGEcA5NyxM4FVHS2dLjJBeowoXMgZOk6gkP51FjnCoinU5HeE66XlKa1OkXQgjhJOmXwJSt7geEF76NOSVKUvWEK1kmwA0sfL2k6gkPIYGTB6gUmDvOSQghhHAKc2+TdyB4+xe+ja9coAo3KGmMk6TqCQ8hgZMHCA+UynpCCCGcLC1R3RZVGALyXKBKj5Nwocyc863I4hDmVD0J6IV7SeDkAfJW1hNCCCGcIu28ui2qMATkSdWTb/aFi2iaHeXIJXAS7iWBkwcwV9a7KIGTEEIIZympoh7kFoeQQfjCVbIzcsfeSaqe8HASOHkAS4+TpOoJIYRwlpIq6oGk6gnXM/c2gQ3FISRwEu4lgZMHqBSQM8bpslTVE0II4SSXJVVPeCDz+CbvANAbCt9GUvWEh5DAyQNIVT0hhBBOZy4OUVQpcsgzj5P0OAkXKakUOVin6mma89skRBEkcPIAljFOkqonhBDCWcypeoHFperJN/vCxUoqRQ65PaGmbMi64vw2CVEECZw8gFTVE0II4XT2FIeQVD3hKiWVIjev0+VcskpQL9xIAicPYO5xSkrLQpMuaCGEEM5gVzlySdUTLlJSKXIAnU4q6wmPIIGTBzD3OGUaTVzONLq5NUIIIa5K9lTVS5exJMJFbEnVA6msJzyCBE4ewN/HgL+3qiQjczkJIYRwOGNWboqTLal6piw1v44QzmZLcQjIrayXIal6wn0kcPIQ4VJZTwghhLOYK+qhA/+worfzCVLbgKRECdcwj3EqLlUPpHCJ8AgSOHmISoFqLieZBFcIIYTDWdL0woueKwdAr8/tdZKUKOEKlh4nSdUTnk8CJw9hHuckqXpCCCEczpaKemYyCF+4ks1jnMypenJeCveRwMlDSElyIYQQTmNLRT0zPwmchAtlmgOnEsY4WQqXSKqecB8JnDyETIIrhBDCaezqcZJUPeFC5sDJfN4VRVL1hAeQwMlD5PY4Zbm5JUIIIa465uIQdqXqyVxOwgUkVU+UIxI4eYjwnOIQMsZJCCGEw122I1XP/M2/XKAKV7C1HLmk6gkPIIGTh6gkqXpCCCGcxZyqF1jM5LdmftLjJFzIkqonVfWE55PAyUOEB0jgJIQQwklKU1VPvtkXrpBpY6qeVHsUHkACJw9RKVDGOAkhhHASe6rqyQWqcCWbxziFqVsJ6IUbSeDkIfJW1dM0zc2tEUIIcVWxpziEpOoJV7K1HLmk6gkPIIGThwgLUMUhjCaN5PRsN7dGCCHEVUPTpBy58EzGbMhOV/dLKkeetyfUZHJuu4QoggROHsLXy0CgjwGQynpCCCEcKPNy7sWplCMXnsTc2wS2lyNHg0w5N4V7SODkQSzjnKRAhBBCCEcx9zZ5+ZWcDgV5UvWkx0k4mbkUud4bvHyK39bbDww520hvqHATCZw8iGWck/Q4CSGEcJS8aXo6XcnbS6qecBVbS5GbSeES4WYSOHmQSgHmynoSOAkhhHAQS+AUbtv2kqonXMXWUuRm5nQ9CeqFm0jg5EHCZRJcIYQQjmYJnGyY/BZyA6fMFDAZndMmIcD2UuRmfjLHmHAvCZw8SG6Pk8zlJIQQwkHsqagHuRenYD14XwhHs7UUuZmk6gk3k8DJg4QHqpLkSdLjJIQQwlEu2zH5LYCXLxh81X1JiRLOZC4OYesYJ0uqnvQ4CfeQwMmDWKrqyRgnIYQQjmLucQq0MVUPcgtEyDf7wpnM4+gkVU+UExI4eZDwABnjJIQQwsHsLQ4BeUqSS4EI4UTmHidbAyffnB4nCeiFm0jg5EGkx0kIIYTD2TvGCXLHkkiqnnAme8uRS1U94WYSOHmQSpYeJykOIYQQwkHsraoHkqonXMPS42RjcQhJ1RNu5tbAafLkyeh0Oqufxo0bF/ucpKQkxo4dS1RUFL6+vjRs2JClS5e6qMXOVSlPcQijSXNza4QQQlwVStPj5CcpUcIFLGOcgm3bXqrqCTfzcncDmjVrxqpVqyyPvbyKblJmZia9evWiatWqLFy4kOrVq3P06FHCwsJc0FLnM/c4mTRIvpJlSd0TQgghSsVkhLREdd+uVL2cC1lJiRLOZG85cknVE27m9sDJy8uLyMhIm7b97LPPSExMZP369Xh7q96Z2rVrO7F1ruVt0BPs50VKejaJaZkSOAkhhCibK0lATgaDPcUhfKU4hHABu8uRS6qecC+3B0779+8nOjoaPz8/OnbsyLRp06hZs2ah2/7888907NiRsWPH8tNPPxEREcGQIUN49tlnMRgMhT4nIyODjIwMy+PkZPUtRVZWFllZjh9LZN5nafddKcCblPRszl1Ko2aYryObJkpQ1mMn3EOOW/kkx81Fks/gDWh+oWSbAJNtn7feOwgDYLyShCnPMZLjVj556nEzpCejB7IN/mi2tM0QoM7n9Etke9h7cQZPPW5XG3s+X52maW4bTLNs2TJSU1Np1KgRCQkJxMbGcvLkSXbt2kVwcMF818aNG3PkyBHuvfdexowZw4EDBxgzZgyPP/44L7/8cqGvMXnyZGJjYwssnzdvHgEBAQ5/T2U1a6eBo6k6HmhkpEW4jHMSQghReuGpe+myfwqpvtX4vekbNj+v/pklNDu1gOOVOrO19kNObKGoyLrteYmwK0fYUPdpzoa2KnH7gIwz9Nr9DNl6X5a0+tgFLRQVQVpaGkOGDOHSpUuEhIQUu61bA6f8kpKSqFWrFrNmzWLUqFEF1jds2JD09HQOHz5s6WGaNWsWb7zxBgkJCYXus7Aep5iYGM6fP1/ih1MaWVlZrFy5kl69elnSCe3x4Fdbid93nqkDm3Fn2+oOb58oWlmPnXAPOW7lkxw319DtWYLXDyMwVb8W48hltj9v6xd4LXsaU8O+GO/8yrJcjlv55KnHzeuDDugSD5I97Be0mh1LfkJaIt5vNQQg67kEMHjOe3EGTz1uV5vk5GSqVKliU+Dk9lS9vMLCwmjYsCEHDhwodH1UVBTe3t5WaXlNmjTh9OnTZGZm4uNTcEyQr68vvr4FU968vb2dehKWdv+Vg/wASM4wyi+Jmzj73BDOIcetfJLj5mSZSQDoA6ugt+dzDghTz8tMLfR5ctzKJ487bllpAHgFhIIt7QrKHafnbUoHP8/LHHIGjztuVxl7PluPmscpNTWVgwcPEhUVVej6zp07c+DAAUwmk2XZvn37iIqKKjRoKo/Cc0qSX5RJcIUQQpTV5fPq1p6KeiDlyIVrZJir6tlYHMLgDd45wZIUiBBu4NbAafz48axevZojR46wfv16Bg0ahMFgYPDgwQAMHz6ciRMnWrZ/5JFHSExM5IknnmDfvn0sWbKEqVOnMnbsWHe9BYcLyylJniiBkxBCiLIylyIPtDNwMlfVk7LPwlk0LU85chsDJ5CgXriVW1P1Tpw4weDBg7lw4QIRERFcf/31bNy4kYiICACOHTuGXp8b28XExLB8+XLGjRtHy5YtqV69Ok888QTPPvusu96Cw4XnlCC/mCaBkxBCiDIqzeS3kDuPk1ycCmfJSsNSKt/WcuSggvqUBOlxEm7h1sBp/vz5xa6Pj48vsKxjx45s3LjRSS1yv0rS4ySEEMJR0kqbqifzOAknM6fpoctNv7OFn/SGCvfxqDFOIm+Pk9TsF0IIUUaWHqcq9j3P3ONkzISsdMe2SQiwTtPT6Wx/nqTqCTeSwMnDmItDSI+TEEKIMittqp5PMJBzMSu9TsIZzIGTPWl6kGf8naTqCdeTwMnDmFP1Ll3JIttoKmFrIYQQohiXzYFTePHb5afXyzgn4VyZl9WtT6B9z5NUPeFGEjh5mFB/b0uPddIVSdcTQghRSllXICvn4jTQzlQ9yA2c5Jt94Qz2liI3k1Q94UYSOHkYL4OeUH+VrpcklfWEEEKUlrkUud4rN73JHr5SIEI4UWbOeWVv4GRJ1UtyaHOEsIUETh4o3FJZT3qchBBClFLeinr2DL43k1Q94UzmVD17xziZe5wkVU+4gQROHqhSoJQkF0IIUUalrahnJiXJhTNJqp4ohyRw8kCVAlSqnkyCK4QQotTMqXr2FoYw85VB+MKJSlscQqrqCTeSwMkDySS4QgghyuxyKSe/NZNUPeFM5jFO5vPMVlJVT7iRBE4eyDIJrgROQgghSsucqleainqQJ1VPLlCFE5S1x0nOS+EGEjh5IMsYJ0nVE0IIUVqlnfzWTFL1hDOVdYyTpOoJN5DAyQOZq+pJj5MQQohSSytrqp4UhxBOlGkOnEo5Aa4xE7LSHdsmIUoggZMHyu1xknLkQgghSslSHKKUgZOk6glnMgdO9o5x8gkGcsrry7kpXEwCJw8UHphTVU96nIQQQpRWmVP1ci5oJVVPOENpU/X0ekkjFW4jgZMHMlfVk3LkQgghSq3MVfUkVU84UWmLQ0Ceynoyzkm4lgROHshcVS8lPZsso8nNrRFCCFHuaFrZq+pJOXLhTJZUPTt7nCBPUC+Bk3AtCZw8UIifN/qc9F3pdRJCCGG39EugGdX9Uo9xMlcvk8BJOEFmKVP1QM5N4TYSOHkgvV5HmKWynhSIEEIIYSdzb5NPMHj5lm4f5m/1M1PAJNkPwsFKO8YJJFVPuI0ETh6qUoAqEJEoBSKEEELYy1IYIrz0+8hb7SxTxjkJB8rOAFPOF8OlGeMkk+AKN5HAyUOZxzlJqp4QQgi7lbWiHoC3HxjU/yIpECEcylwYAiRVT5QrEjh5KHNlPelxEkIIYTdzRb3SFoYwk5LkwhnMgbiXPxi87H++pOoJN5HAyUNZepwkcBJCCGEvR/Q4gaRECecoSylykPNSuI0ETh6qUk7glCipekIIIezlqMDJT+ZyEk5QllLkIKl6wm0kcPJQ4QHS4ySEEKKUHN3jJClRwpHKUoocJFVPuI0ETh6qkqU4hJQjF0IIYSeHp+pJj5NwoLKUIgfwzelxkglwhYtJ4OShwgNVOXKpqieEEMJuDk/Vk5Qo4UCWHqdSjnGy9DjJeSlcSwInDxUmVfWEEEKUllTVE57MXByizGOcpMdJuJYETh5KxjgJIYSwS9w0WD1D3U9LVLfmHqfVM9R6e0mqnnAG8/nkE1z8dkXJe15qmmPaJIQNJHDyUOYxTpczjaRnGd3cGiGEEB5Pb4C4KSpAMo/9CKicEzRNUevtZe5xklQ94UhlLUduTtXTjNaT6QrhZKWYdUy4QoifFwa9DqNJIykti8jQUvzDE0IIUXF0m6Bu46aoW50eNn0M8VOhx6Tc9faQcuTCGcpajtw7APReYMpWQX1p9yOEnaTHyR3yplPkl5NOodPpqCTjnIQQQtij2wS49kF1XzOVLWgCKUcunCOjjMUhdDo5N4VbSODkDuZ0ivzBU750CqmsJ4QQwm4Ne+feN/iUPmiCPGNJJFVPOJClql4pxziBVNYTbiGpeu6QN51C06DreFjzpnqc55tB6XESQghht00fqVudHoyZ6ku50gZPkqonnKGs5cght7KeBPXChSRwcpduE+DYRpVG8ecMlaebL50i3DIJrgROQgghbLB6Buxfoe53fFQVdzCPeSpN8CTlyIUzlLUcOUiqnnALCZzcKaY9HPxdBU2FpFOYK+tdvJzljtYJIYQoT8zp3uH1IPEgVK4HbUeqdaUNnqQcuXAGyxinMgROMpeTcAO3jnGaPHkyOp3O6qdx48Y2PXf+/PnodDoGDhzo3EY6U8rp3PvmdIo8LHM5SY+TEEKIkpiMKnNBp1OPw+uq224T1HJTKaa2MKfqGTMgO8Mx7RQi04GBk6TqCRdye49Ts2bNWLVqleWxl1fJTTpy5Ajjx4+nS5cuzmyac62eAX9/Dt7+kHUF2gwt8I1gWIAqDiFjnIQQQpSox0QwZud+CWcOnKD0Y5zyXtimJ4NvWKmbJ4RFWcuRg6TqCbdwe1U9Ly8vIiMjLT9VqlQpdnuj0ci9995LbGwsdevWLXZbj2VOp+gxCRoPUMsCI9TjPNX2ZIyTEEIIu1w6DqYsMPhCcHTZ96c35FY+k2/2haOUtRw5SFU94RZu73Hav38/0dHR+Pn50bFjR6ZNm0bNmjWL3P6VV16hatWqjBo1ijVr1pS4/4yMDDIyctMLkpPVL1hWVhZZWY4fO2TeZ3H71mdnQtfnMHUah27XQrx2foe2bwXZD65GbzRCdiamrCxCfFVceyE1wyltFdZsOXbC88hxK5/kuDmH7tx+vACtUm2yjUYwliI9Lx8v3yB0mSlkXU4kyz8KkONW3njU75vJiHf2FQCy9H5QyjbpvYMwAKYrSRg94X05gUcdt6uYPZ+vTtM0zYltKdayZctITU2lUaNGJCQkEBsby8mTJ9m1axfBwQVr+69du5Z77rmHbdu2UaVKFUaOHElSUhKLFy8u8jUmT55MbGxsgeXz5s0jICDAkW+nVHyyU+iz81F0aCxv9jbpPuGWdUdTYdZOL8J8NGLblv2fnxBCiKtb7XOraHXiSxJC27Cp7jiH7LPHfxMJST/JuvrPcT64qUP2KSouL2Ma/Xc8DMAvrT7BpPcp1X5qXlhNm2OfcjqkFX/Ve9qRTRQVTFpaGkOGDOHSpUuEhIQUu61be5z69u1rud+yZUs6dOhArVq1+O677xg1apTVtikpKQwbNoyPP/64xHS+vCZOnMhTTz1leZycnExMTAw33XRTiR9OaWRlZbFy5Up69eqFt7e3Tc/RLnyG7tTf3FgbtNb9LMuPX0xj1s61pGsG+vXrXfQOhEOU5tgJ95PjVj7JcXMO/cr1cAKqNr6Ofj37lfwEGxjOzoaTJ+nQuimZdXvJcSuHPOr3LTkBdoCm96JP/1tzi5nYSbfHCMc+pWqIH/36OeZc9zQeddyuYuZsNFuUKnA6fvw4Op2OGjVqALBp0ybmzZtH06ZNGT16dGl2CUBYWBgNGzbkwIEDBdYdPHiQI0eOMGDAAMsyk8kEqHFSe/fupV69egWe5+vri6+vb4Hl3t7eTj0J7dp/w95w6m+8Dv0B195nWVw1VOX+pmeZyNb0+PsYnNFUkY+zzw3hHHLcyic5bg6WdBQAQ5UGGBz1ueaMJfHKvoyWs085buWTRxw3UzoAOp8gvH1K19sEQKDK0NFnpqB393tyMo84blcxez7bUhWHGDJkCHFxcQCcPn2aXr16sWnTJiZNmsQrr7xSml0CkJqaysGDB4mKiiqwrnHjxuzcuZNt27ZZfm655RZ69OjBtm3biImJKfXrul2Dnur2UDwYc/MsA30M+BjUIUqUAhFCCCFKknhI3YY7sHiSn8zlJBzIEaXIIU9VPSkOIVynVIHTrl27aN++PQDfffcdzZs3Z/369XzzzTfMnTvX5v2MHz+e1atXc+TIEdavX8+gQYMwGAwMHjwYgOHDhzNx4kQA/Pz8aN68udVPWFgYwcHBNG/eHJ+yfGvhblFtIKCKqlh0/C/LYp1OR6VAFQVflJLkQgghimMywsXD6r4jAyffnDHHcoEqHMERpchBJsAVblGqwCkrK8uS/rZq1SpuueUWQPUKJSQk2LyfEydOMHjwYBo1asRdd91F5cqV2bhxIxEREQAcO3bMrv2VW3o91L9R3d+/0mpVpZxJcGUuJyGEEMVKPqkmU9d7Q2gNx+3X/M1+hlygCgdwRClyyD0vM1NKN7mzEKVQqjFOzZo1Y86cOfTv35+VK1fy6quvAnDq1CkqV65s837mz59f7Pr4+Phi19vTu+XxGtwEOxaowKlXbhVAc+AkczkJIYQoljlNr1JtNf+So5i/2ZdUPeEImZfVbVlT9fzyFPjKSAH/sLLtTwgblKrH6fXXX+fDDz+ke/fuDB48mFatWgHw888/W1L4hJ3q3QA6PZz9Fy6dtCy2TIIrPU5CCCGK44zxTSCpesKxMnMC8LIGTl6+4OWn7ku6nnCRUvU4de/enfPnz5OcnEylSpUsy0ePHu0RcyOVSwHhUL0tnNgMB1ZB2xEAljFOiWky+ZkQQohiOC1wkuIQwoHMPU5lHeME6tzMTldjxIVwgVL1OF25coWMjAxL0HT06FHefvtt9u7dS9WqVR3awAqlfi91eyB3nFN4gPQ4CSGEsEFiTmGIygWn5igTc4+TXJwKR8hwUFU9yFMgQs5N4RqlCpxuvfVWvvzySwCSkpLo0KEDb775JgMHDuSDDz5waAMrlAY5gdPBeMhWgVKlnFQ9KUcuhBCiWJYepzqO3a+flH0WDpTpoOIQkOfclFQ94RqlCpy2bt1Kly5dAFi4cCHVqlXj6NGjfPnll7z77rsObWCFEtUaAiNU/m9OWXIZ4ySEEKJEJlNuj5Ok6glPZilHHlz2fVnOTQnqhWuUKnBKS0sjOFid8CtWrOC2225Dr9dz3XXXcfToUYc2sELR66FeTlnynHQ9KUcuhBCiRCkJkH0F9F4QWtOx+5aLU+FIjipHDpKqJ1yuVIFT/fr1Wbx4McePH2f58uXcdNNNAJw9e5aQkJASni2KZU7Xy5nPydLjJKl6QgghimJO0wurCYZS1X0qml+eHifN5Nh9i4rHUeXIQVL1hMuVKnB66aWXGD9+PLVr16Z9+/Z07NgRUL1Pbdq0cWgDKxxLWfLdcOmEZYzTxctZaJrm5sYJIYTwSM6qqAd5Uqq03IteIUrLkWOcZHJm4WKlCpzuuOMOjh07xpYtW1i+fLll+Y033shbb73lsMZVSAHhUL2dun9glaWqXqbRxOVMmRlbCCFEIZwZOHn5gV5NjSHpeqLMHDnGyS9M3UqqnnCRUgVOAJGRkbRp04ZTp05x4sQJANq3b0/jxo0d1rgKK0+6nr+PAV8vdZikQIQQQohCWQInB5ciB9DprNP1hCgLh45xklQ94VqlCpxMJhOvvPIKoaGh1KpVi1q1ahEWFsarr76KyST5z2VWv6e6PRQP2ZkyzkkIIUTxnFVRzyynd0AnPU6irBw5xkkKlwgXK9UI0kmTJvHpp58yffp0OnfuDMDatWuZPHky6enpTJkyxaGNrHDMZckvn4PjG6kU4EPCpXSprCeEEKIgTXNuqh7kXqBKSpQoK0ek6sVNA70BqjVXj/Oel6tngMkIPSaWfv9CFKFUPU5ffPEFn3zyCY888ggtW7akZcuWjBkzho8//pi5c+c6uIkVkF6f2+u0f6X0OAkhhCha6hnIuqwKC4U5uBS5mTlwypRUPVEGmuaY4hB6A8RNgb1L1GNzj9PqGWq53lC2dgpRhFIFTomJiYWOZWrcuDGJiYllbpTAKnAyV9ZLvJzlxgYJIYTwSObeptAY8PJxzmv4SY+TcICsK7kl7cuSqtdtAvSYBP98rR6nX8oNmnpMUuuFcIJSBU6tWrXivffeK7D8vffeo2XLlmVulCC3LPm5/6jtpYJRKQ4hhBCiAGen6YGlx0knPU6iLMy9TQDeAWXbV7cJcN0YdT/1jARNwiVKNcZpxowZ9O/fn1WrVlnmcNqwYQPHjx9n6dKlDm1ghRUQDjWuheN/0SpjM9CCREnVE0IIkZ9LAqec8SjpEjiJMrCk6QWpYQlldcMLsPF9dV/vLUGTcLpSnbXdunVj3759DBo0iKSkJJKSkrjtttv4999/+eqrrxzdxoqrvipL3jB5IyA9TkIIIQphDpwqO6EUuZmfVC8TDuDIUuQAG/6Xe9+UpdL1hHCiUvU4AURHRxeonrd9+3Y+/fRTPvroozI3TAANekLca0Qn/oU390lVPSGEEAW5sMdJl5kCMu5elJYjS5GbxzQ17Av7lkFwlHoM0vMknMYB/aTCaSJbQWBVvLLTaKffK1X1hBBCWNM058/hBFKOXDiGpRR5GQOnvIUgbpmtxoSnJMB1Y9Vy6XkSTiKBkyfLU5a8u34bF9Okqp4QQog8Lp/PSZ/TQVgt572OX6i6leIQoiwycs6fsvY4mYy5hSCCIqCWmlOU4Ei13GQs2/6FKEKpU/WEizToCdvn0V2/nTcuZ6JpGjqdzt2tEkII4QkspchrgLef817HUhxCepxEGTgqVS//5LbNBsKRNbD7J3jw97LtW4hi2BU43XbbbcWuT0pKKktbRGHq9kDT6WmkP0FV0zlSMrIJ8fN2d6uEEEJ4Asv4pjrOfR1zOXIpDiHKwhGT3xam8QBYMh5OboGk4xAW49j9C5HDrlS90NDQYn9q1arF8OHDndXWiikgHF2N9gB0N2yXynpCCCFyuaIwBORW1cs7D48Q9nLUGKf8gqtBrU7q/n+/OHbfQuRhV4/T559/7qx2iKLETQMvX0CNc/pp20murV2Z9nXCMax5IyfPd2IJOxFCCHFVsgROTixFDpKqJxwjI888To7W9FY4ug52L4aOYxy/fyGQ4hCeT2+Aw6sB6KzfxXsrdzP44418OuVhVTlGL3VhhRCiwnJVj5M5Vc+Ygd4khYpEKTmyHHl+TQao2+N/QfIpx+9fCCRw8ni/VR7GrKzbAQjUZdBOv5fHDIsYbZzPrKw7+K3yMDe3UAghhNu4LHAKttz1Ml5x7muJq5ezUvUAQqIh5jp1X9L1hJNI4OTBjCaN2F92867xdnYZVZnZr7yn8bT3Qt7MuoPZxtuI/WU3RpPm5pYKIYRwubRESE9S9yvVdu5r6Q2WXgJvkwROopQs5cgdXBzCrOmt6nb3T87Zf0URN63oubBWz1DrKygJnDzYpsOJJFxKB+Cl7PsAMOg0MjUDs423oQEJl9LZdDjRja0UQgjhFubepuBo8Alw/uvlpOtJj5MoNUuqXnDx25WWOV3v6HpIOe2c13A2Twha9IbCJxI2TzxcgYeJSODkwc6mpFvud9bvstz30Rl5zLCo0O2EEEJUEK5K0zPLSdfzNqa55vXE1cdZ5cjNwmKgejtAK7/pep4QtHSboCYSjpsC8a+DyZT7+uaJhysomQDXg1UNVpMZPmZYxNPeC/kiuxfDDKvQ6zSe9l4IwGzjbZbthBBCVCCumsPJzE96nEQZmXucnDHGyazZQDWf0+6foP2DznsdZzEHJXFT0BuNoDVBv2Ym/DndtUFLtwmQlQbxU9UPQIu7ofOTrnl9DyWBkwdrXyec5wN/ZrQxd0xTkO4KtxvWcsRUlae9FxLs50X7Ov3c3VQhhBCuZg6cKju5FLmZpcdJAidRSs4sR27W5BZY8YIqTZ56DoIibH9u3DTVo1NYcLJ6huumgOk2AS4cxPDndG4BdOD6nh5jNiRst162cwHsX65SIpvfBrW7wp9veMZn5iKSqufBDHodNzSszKysO3jPeBsAb2XfSaZmoLb+LAuzu3BDw8oY9Do3t1QIIYTLuTxVL6fHySSpeqKUMl0QOFWqBdFtQDPBnl/te64npMldPg+LRsOO+YAKmjSd3vXpcb9PhoN/qPv6nH4W70BVkOafr+CrQfBmI9i/Iielb7r186/S8VASOHm4+ndPpeng14gMVel4J7QIvjH2BKBXxEXq3zXFnc0TQgjhLq4OnHJS9byNMq5WlJIzy5HnZamut9i+5+Ud2/PLk6rHxVVjezQNtn0L710LOxaQ08+EBug0Eyxw4fQzO76D9bPV/aaD4KUL6v1nXYbW90Lb+8A/HNLOw6mtarv4afBJT9d+Zm4ggVM50Kd5FGufvYFvH7yOjnXDeS97IBl6f0Iv7pKSm0IIURFdSYK0C+p+JReNcbJU1ZMeJ1EK2ZlgzFT3nVUcwswcOB1eA5cv2PfcbhNUcPD35/BhV9cEAImH4MtbYfHDcCURAqsCGsauz7EnSmUc8d/P8NtzzmuD2al/YPEj6n7NTnDXXHXfHFRu+0bNmTV+Hwz9AVoPBb9Qtc2JzbmfWddnr7qgCSRwKjcMeh0d61Xm8RsbcoFQPjP2Vyv+eFXloQohhKg4zL1NQdWc/+29ma+5x0nGOIlSMPc2gXNT9UD1wka2BM0Ie5fY99y0RDgYZ73smhFla09RJcaNWfDlQJjdDg6vBi8/qNsDLp+FHpMwdRnPvmq3YDJP7LvxA+eWI089B/OHgikbwuvByHypjubgyWQEgzfU7wkD/wfjD8DgBaDLE1bsXgwntzqvrW4igVM506FOOFGhfvwvow+ZPpXgwgHY9rW7myWEEMKVXJmmZ77oyykOYVVVr4JPhinsYA6cDL7qotvZSjMZrqbBT2Mh5VTOgpwx5J/2KtuX1IWNnTr5N8xqCofiVIBXpxuM2QAxHax7uHR6jLfOAd+cXp3Dq0vfjuJkZ8J3wyH5BFSuD6PjCh+f1G1CwWIPXj5weocaV2YeD3V+r0rdi5umAsSrhFsDp8mTJ6PT6ax+GjduXOT2H3/8MV26dKFSpUpUqlSJnj17smnTJhe22P30eh23tI4mlQAWBw9WC+OnQ5Z8AyiEEBVG4mF164rAyXzRd3QdAN7m4hBX6eBv4SSuKEWeV9OB6vZQvOpFssXmT2DvUnW/3SgY+xfovSHpKHxxc+nbknfs1O+vwrLn4OMbVc+Slz8MnAPDf1K/zz0mFkxxC60BA95W949thCNrS9+Wovz2HBxbr3qW7/k2N/3OFnnHNL10Aa4fp5ZrRlg9XQVQZ/c4vs1u4PYep2bNmpGQkGD5Wbu26JMhPj6ewYMHExcXx4YNG4iJieGmm27i5MmTLmyx+w1sXR2AV05fhymkBqQkwKaP3NwqIYQQLuPKHifzRV9OhTIv4xU1r8xVOvhbOEmGkye/za9KfajaTKWd7V1W8vand8GyZ9X9+r3g5lkQ0Qhu+1AtO7YBfnig9O3pNgE6PAxrZsJfHwAaVGsO43ZB68GgK6FCcvPboM1Q9bxFo+HKxdK3Jb+/58KWTwEd3PYxRDS0/bmFFYLoOVk9BpV+mLBNjX36cmDB6ntW+/H83mu3B05eXl5ERkZafqpUqVLktt988w1jxoyhdevWNG7cmE8++QSTycTvv//uwha7X5OoEBpVCybV6MXm2g+phWtmqcHCQgghrn6urqjXbQK0UlkO4Zf3Y3D1ZJyi/LOUIg923Ws2G6huS0rXy0yDhferHpLw+nDv97nrmt8O7XOutXb/nNvba6+Tf8POPPvVe8Ej6yCw6OveAvq8rsYeJZ+EX55QqYVldewvWDJe3b9hEjTqY9/zTcbC/xaYv3BpN0oFosYMlZYYPw1+y5fqV456r90+Ae7+/fuJjo7Gz8+Pjh07Mm3aNGrWrGnTc9PS0sjKyiI8PLzIbTIyMsjIyLA8Tk5OBiArK4usLMfnXJr36Yx95zWgZSR7V6Yw60wb5ldphO78Xoxr3sLU4wWnvu7VzFXHTjiWHLfySY5b2XglHkIHZIXUBFd9hu1G4739WzWvjMGH7E7jXPfaokw84fdNl3YJL8DkE4jRVe1o2B/vuCloB/8gO+WCpaR+foalE9Cf34sWVI3s4b9Cdr7xTDe8jOHk3+hPbkH7bjjZI5aqnhQb6Q7+juGH+9BlqTRXzeCNzpiF8Y9pmLqML/J5BY6b3hfdrXMwfNEX3e6fyN4yF631UJvbUUByAl4LhqIzZWFqfAvG656w/3f6+vHmxhZc18mcsqeh2/YVhlUvosu8DBvfx3jhEKY7v0K/9k0Mf07H2PU5TG76m2LP74VO0xwRrpbOsmXLSE1NpVGjRiQkJBAbG8vJkyfZtWsXwcElfyMxZswYli9fzr///oufX+En8OTJk4mNjS2wfN68eQQEBJT5PbhLYgbEblVx76cN/uLG4++QrfNhVbOZZHiHubdxQgghnMbLeIX+O9Q34EtaziHb4Jr/ZQ0TfqTJ6R8tj/+Luo19kQNd8tqi/Iu5sJZrjn3E2eDmbKjvup7KHv9NJCT9JH/XeogT4Z0LrI++uIlrj7yHho719Z/lfHDTQvfjl3mB7ntfwjc7hSOVu7O95v02vX6NxHW0OfoJeowA7K12C3ui76Dh6cU0SVhUqt+j+meW0OzUArL1Pqxu9CqpflElPqdRwiI0nd7yWnpTJtfvn0qltEOke4VwLLwr/1W/y6522Csg4xxtjn1EldS9AGjo0KG5/W9JWloaQ4YM4dKlS4SEFB5cm7k1cMovKSmJWrVqMWvWLEaNGlXsttOnT2fGjBnEx8fTsmXLIrcrrMcpJiaG8+fPl/jhlEZWVhYrV66kV69eeHs7t2rMkE83s/nIRZ7pVZ9HDo1Bf3ILxmvuw9T3Dae+7tXKlcdOOI4ct/KpPBw3/Z+vg85Q6DfC+jUzQTNi6vqs6xt2egfen96AFlCF7HGuGXCtXzMTw5/Tya7ZGa9j6zCFxKBPPq6+JS7mG3PhGTzh902/5TMMyydgajwA4+2fu+51V0/HsHYmpgZ9MN6VrwrxpeN4fdwNXUYyxk7jMJnH5RRBdygew7d3okMje8B7aC3vKXpjTUO/8T0Mf+R+eW/s8ozV3wzz71VRv0dFHjfNhGHe7eiPrEGLbEn2yN/A4FP855D3ta5/GsOvj6HfMR/Nyw9ddrrrfpc1E/pNH6Jf9aLqvdZ7kz0xwfmvW4zk5GSqVKliU+Dk9lS9vMLCwmjYsCEHDhwodruZM2cyffp0Vq1aVWzQBODr64uvr2+B5d7e3k794+Hs/QMMalODzUcu8svOM4wdGAtz+2PY9hWGzo9B5XpOfe2rmSuOnXA8OW7lk0cfNy8fiJuCwWCwzt9fPQNyxvgY3NH25GMA6MLruuazy/N+teZ3o81uhT75OHR4GMOf0wt+PkINctcX8bmsnpEzLmRiwXVO5tbft5yJk/W+wehd2YYWt8HamegPxaE3XslN1zNmw08PQ0Yy1LgWw42TMJRUJr1RL+g+EeKn4rXsGahxDVRrVnA7kwlWvAAb/6ce17gW6vfC0P1ZrEbx3DARDAYMJmOxf0sKPW63fQTvtkF3egfef06Hm161Xp//PDO/VtwUDEfXwtG1gA5ddrr6W9ZtAi4bYWRMV7d6L3SmLLzXv+XWvyH2/E64vThEXqmpqRw8eJCoqKK7HGfMmMGrr77Kb7/9Rrt27VzYOs/Tr0Uk3gYde06nsMevJVSqq6rHxE0puHE5qVYihBAeI28JYfP8K4VVkHI1VxeGyDv4OySaMyE5X1h6+eZOhimsFTZvD5SrQfAO5+py5GZVm0LlBqo4wf4VuctXT4fjf6ny27d/YvvcUl2fURO/Zl+BBcMg/ZL1+uxMWPRgbtB002vwwCroXkTvdGHzItkiJBoa55RIX/+u9aS9ec+z5FOw4zv4+THYPl+tP2quYK25/m9Z/tLl+f/Geji3Bk7jx49n9erVHDlyhPXr1zNo0CAMBgODB6vKPcOHD2fixNyT6fXXX+fFF1/ks88+o3bt2pw+fZrTp0+Tmppa1Etc1cICfOjRqCoAi/85BfV6qBW7foCE7bkbVuQ/1EIIURbdJkCX8epv6CuV3R80QW7g5KrMgnzzyhyt3F3d2TZPzdfihp4Tj+epQbc7ubocuZlOl2cy3MXq9vAa+HOmuj/gbahU2/b96fWqZLdPMCQeVBPmmke9ZKTAvDth10JAB4M+gk6POeZ9FOaOTyH6GnV/wVC4fB6Wv6DOs6jWsP1bmNVEBXJbv1Tt1emxTOxr8HFf0GR+3cJ+VzyYWwOnEydOMHjwYBo1asRdd91F5cqV2bhxIxEREQAcO3aMhITcvMcPPviAzMxM7rjjDqKioiw/M2fOdNdbcLuBbdScTj9vO4mp35vqmxWA70eq24r+h1oIIcrK/A25Kdv1FxqFceXkt4U4E9oKLbAqXD4H+35zSxvKhW4T1EVz3BSIDZP/xZZy5C7ucYqbljvn0f6VkHRMBRJoENUKzu2zf58B4dDiDnX/v19gw/8g9SzM7a8m3AVoeTe0utsR76B4I5dAQBX1+b5RDzbMVssTtqkvWXR6iG6jzsXBC6Dzk4Cm/pYZM10brJRUurwc9F67dYzT/Pnzi10fHx9v9fjIkSPOa0w5dUPjqgT7enHqUjqbjyTS4e6v4b126pfllcrqH31F/kMthBBlkZ2Z+8005F5oeEKPU3gdt7y8pvPC1GowhvXvwN9fQJMBbmmHx0tLhP2r1H1zj0Tl+u5rj7uZAydfF87jBCrbZsun4BcG6UnwWV9ISQD/cJWdY053s9eAt1Ua3P7lajzTX3Pg0nG1ru19ar0r+ATA8J9gTp6KgdHXQO3r1U/N68AvVC1fPQPWzsq9LjR/uQ6u+ZtWXO90OblO9agxTsJ+ft4G+raIBGDxtlMqdaNdTolMT/l2VAghyquF9+de8AGExrg3pSTzsrroA7f1OAGYWg1Rdw6sgksn3NYOj5WZBt/eA+f+y1mQkxq18D748RGV0lXRuCtVz9ybkZ6kHiefAJ0BriSW/YvlIQtyMn203KCpwyOuC5rM9i5Vt/qc/pBGfVWxiIa9rYOmcp4m5wkkcLoKDGyt0vWW7DhFRrZRDXQ0M2ZC/OtuapkQQpRj8a/Dnl/U/fajVcrLJVVNzm0XGuY0Pf9K6sddwutB7S6ABv984752eCJjlkqXP/6Xenztg/DiOah1vXq8fR7MuR6Ob3ZbE8skblrR535xhajMxSFcnaoHKkBol2feJa2IlDF76XQwaiW5Y4a8oe/0su3TXrYWW7gK0uQ8gQROV4EOdStTLcSX5PRsjv04WXXDtr0v95uH+KnyTYIQQtjrQs7UGN6B0ON5VUkLwNvffRcarq6oV5xrRqjbf76Siy4zkwl+elSlbwFcMxz6z1QX1PctgTbD1PKLR+Cz3up/szHbbc0tldJWDMzM6WVzR+AE0H+W6mkCx2bjbHyf3DFDWa693rKnFylfkRcrpa3sVwF51DxOonQMeh23tIrGb/2bNPh3Ye4vUOX6sGKS+kPhyhxWIYS4GqSdV7fXDFe9O22GqnLG276Fcf+CwQ3/Qj0pcGoyQI0buXQcDsXlBpYVlaapsS475gM6aHEn3DLbeptb34PACNi7TKXxxU2Bv+dC04HQZ2rBfbpxzqcima8j8l5X2FKIyl3lyM3+fEP1NOUtilDWa6L879vVY4aK60UyrxcOJT1OV4mBbapj0Jl423gnyR3GqYUdx0LDPuoPhX84ZKW5t5FCCFFenN4FB/9Q6XnXPaKWNewLAZUh9bQa2+MOlsDJAyY59/ZTlcNAlTqu6Na9nTt3z6A5cPvHhW/X82UYuzG3pHXySfW8BcOtt/PkqUS6TYBuz6n2TQ5Tt9c9UvACPm9aX/4xTq6cXzJvgPPiOceM6/GEMUPSi+RyEjhdJZpGhbAkfCRvZw3it12n1UKdDgZ+ACHV1SDI5FO5lX2EEEIUbcN76rbprVCplrrv5QMt71H3//nKPe3ypB4nUL1xAHuWQuo597bFnbZ+Casmq/u9p0Kre0p+Tsu74JG1ENNBPf7vJ3i/k5pQtTxMJWIJ6HKuKzZ+ALPbwm/Pq8lYszOs0/ryjnFyZVDorABHxgxVSBI4XSV0Op1lTqfF/5zMXREQDrd/qtL1dixQExYKIYQ7lHZQuasln4Kd36v7+SevbDNU3e77Tc3b4mpunsOpgMjmUL0tmLLUZJvljSPOyf9+hV+eUPevH6eyPWxVqTaMXArdnwd0cPZfmF5TXdB3Hue5QdO5vRCfUwRBp8+9vXBA9Z59NRBm1FXlvhv1U+8nKydw+nuua4NCZwU40ttTIUngdBW5pVU0AOsPXmDJjgR+2naSDQcvYIy5Tg1sBlg6Hs7ucWMrhRAVVmkHlbvaXx+q6RxqdVZBQV7VmuYECtnqyyhXyrqiSimD5wROkNvrtPXL8pfVYM85WViQdWSdKlmvmSCyBdz4sv1tMHhB92dh1Arr5X/NgSVP5/YyegqTCb66TQ0DCK8PL+WU9dZM0Ox29eVCUDVVxn/Pr7mlss3Wve3anjQJcIQDSXGIq0hMeAD1IgI5eO4yY+dttSyPCvXj5ZsH06fuWjWAd+F98MDvatI0IYRwlTyDyvVn9xBkuhb9mpnw53TPSUnKSIEtn6v7+XubzNoMg5N/w9avoOOjKi3aHnHT1AV5Ye+3uGIAF4+oW99QlU3gKZrfrtKzLuyHYxugVid3t8h29hQ60OcrtHR6p5qryZihljW62f5zIa9D8Tmv46UC8+wrsPkT2PypKsTR+QnYv7J0544jzR+sAniDDwxfrN5z3s+xxyR4ag+c3qHau385nNiCJaVP5pcU5Zj0OF1FftuVwMFzlwssP30pnUe+2cYfTV+FwKpwdjf89pwbWiiEqPC6TYAmt2D49wdu+O85DH9Oh+7FfCPsalu/goxLULkBNOhd+DbNbwMvfzi/N+eC0E6l7XmzjG+qU7YLdEfzDVafCZTPIhHdJkC7UTmFDkLVbZWGKmUzbqoKXnb/DHW6qslN46bAbxNVr0tGstpH1wnQowz/V/PPxdM9J0skvB6gwX8/wyc3wrZv1Hb552d0Va/tpZNw4A91/6YpEBaTuy5v6pteD9Gtodsz8MAqFfQB6L1zK9oJUQ5Jj9NVwmjSiP1ld6HrNNTUbJNWnmXtnR9h+HoQbP1C/RNocYdL2ymEqOBMRvXlDZYpI1X1uhZ3QmU3V4ozZqsB7qDGqeiL+G7RLxSaDVRjev75EmKute918n47n3gIOjykvpkvadyHpxWGyOuaEapgxr+Loc908A9zd4tsYzKpMTn5A77z+9RPUTa+n3u/y9Nww6TSt6GwHq7uz6rgOG6KmkA3Kw12fKdKv4OanzFhO9zxGax/1zVjhjRNpQ6aMqFGe7h2VMFtiuoJy5ue5+qS3UI4kAROV4lNhxNJuJRe5HoNSLiUzibddXTsOl7NZ7D4EYhuU/BixRPnjRBCXB3+/dEysawJPXpMcPwvmNMFer+mJu92V2/Kfz/BpWMQUKXkqmhthqrAadciFSiYSyzbqtsEOLVN7cNcVKFRP7huTNHPMQdO7g4wC1OjHUQ0UXMT7fwe2j/o7haVLOU0/PiwSmE3M6fJNeitekxSz8Llc5B6Jvd+3qk9DN5w40tla4ctc/H0mAk3vKDGPW35XPV07V0CU6qpbbo+6/wgZPdi2LdM9Rrd8q5tvVtFVbQDCZ5EuSSpeleJsylFB00Ftuv2HITGqO7yz/upkqFmnjZIWwhx9TCZYNmz6m6tLvzSZi7GDjlzJGVdhl/HwTd3qgtaV9M0WPeuut9+NHj7F799rc6q5yczVfWy2OvcPusLdlCD6N9srL7VP/OvWpa3IEH+HidPqkSo00HbEep+eUjX2/sbfNBJHQN9znfI3Z9XaXI9JqlxOXovGPA23PONSjd7cgdMSoAu49X2Bh8wZpU97czW4gUh0dDrFTX58k1TrLf750v46yPIsu1awG5pibD0GXW/y9NQtYltz5OS3eIqI4HTVaJqsJ/t2xm84P7lKkc/9TTM7a9Wlod5I4QQ5dcPoyDtPBh8Md4xFwBTz1dzx3PoDHBgJbx/HXw33LWly4+ug4Rt4OVXeApSfjodtL5X3f/na/teKztDfRbmnguDt7r1rwSZKWpMzQed4NObVFqjeTxU3sDJE7/kanm3CiZO71C9aZ4o64oKAL69G9IuqHG/pmz1f6+7CuqLneNn9QxYM9OxE6nayy8k99wxH/+UBFj2DLzbOjeAcmT5/5Uvqt62Ko2gy1O2P08q2omrjKTqXSXa1wknKtSP05fSKawYrA6IDPWjfZ2cSkyh1eGuL2DeXXBiM8SGq9KiEjQJUX6UtjqbO2gaHFmr7nd+Qo0TMjOP50g5rf4end4Bu39SP1lXoGeeEs95v+BxpPU5E962HgKBVWx7Tushqi3H1sP5A1Clvm3P+/0V9R4BOj0ON72a+75aD1EThe5ZolIYQQVzcVOwjArbuxTWveN5f68DwlX1t10/qF6n6NbuaUdRvxdndsOXt6gAAOC6sapn0cu3+DQ5M09JO8vfjripsPp18A3JDaDWzlLl0ffnlDjvNK7w59viUHzOlwM6uGW2+ryEqKCkx+kqYdDreHlAUyDPgOt8Xh7QFIM+z9qGvdU/bVBBE7rcGcyFEJ6vvMyLBGrC2MtnwScIrnuk4PpuE+DmWWqqhK7P5E6quXaWGocCzusVP7dPjd1Apy6mbRUSDfV7qvvbbOx1OrAKNuQEaS3uVEET5PZybJsH1ZqrdKwbXlBp1dnm9Kucr8U8MWgyuyYnXW/n9yoAdIf8vxeaBps+hjnXq6DJOwDu/QH6TIUbX7S9R8QT0s4K+x3o8bx6nJEMDftASA0VQO1foX7f4qagX60mq9WvmWnf71BmGvzypLp/7QNQU64RRMUmPU5XkT7No/hg6DXE/rLbqlCEj0HHu4Pb0Kd5VMEn+QTleaCpb+OaDoSbXrMuMyqE8Dz2zEHjTpqmvhEHdfEVEA5ZWYVv6+WjAoYGveHH0So9bfu3qqKYs3rFzYFM4/629xqZtRmmLlC3fQs9XlCp0EVJPQc/5gSN1dvC7Z9Yr8/byxEcqQLI659SwdaWz1TwCZ49D07tLlCptppzavdPqgfN1fL+XmRehnN7cj+78Hpw/28QVNX+/RbXe+uq42FLIYm7vlQ9RGtmWSZMNqydyQBzMRZ7fodWT4eLhyGketmLYAhxFZAep6tMn+ZRrH32Br598DpeuaUZeh1kGjWqhxUy2e3qGaqkaY9J8OwRqN5OLd+9GN67VlXec9ZAUyGEY3QZD83vUBeJseGeFzQBHPgdTv2jxlV2fNS258RcCw+vVYEWqKBJV0RaYlmknoXt89V9W9uWV8M+qgpf6mkV4BTFZFKVTC+fhapNYeSSwrfL38uhN6jsgOpt1WODj2fPg7P6dQirpe7nLxLhymIWbe9TQdy6t3ODpvq94LG/Sxc0eQpbxgx5+apxeo9vhf6zVA8UoMek+iwzU9V8TCU5tS03hbX/LDW2SogKTgKnq5BBr6NjvcoM71SbW1tXB+DTtYesN8r/rbR/JXjw99yLlOwr8Mdr8H4HWDjKtYO0hRAlMxnVWJI518OuhWqZlpMqdGqbGpegFTbi0cU0Df7M+fvR7n4IirD9uT6BEFQtz76M8OWtjm3f5k/AmKG+OKp5nf3P9/LJLV3+z1dFb7fpQ1X4wssPbv+05Kp9eeX9e+2uggS20hvg8GpAB8c2wLm9armr0kfP7IafxsJbzeDImjzt8oahCz1r4mBnMwdQbVQRE/Ocjqx7B95pCT88qOaCgoKFJIzZ8PNj6ncuoon64kMIIal6V7tR19fhx39O8uuOBJ7t25io0Jx/1kV19/d/U1UZOr0TTm5R6RYXj6h1aYnQd3ruts4apC2EKJoxS40fWfOmZT4kSy8EOkBT87vsXaIueNo/qC7s173rnkISh/9URQ4MvtD5cfuem/dvjMEHVr2sAsKv71AXwaWRt3BAZpoa+wLQ6THVy16az6HNUJXut+831YOVv0cjYQeszElzuuk1qNbU9n17SkECW+Vv29YvVSGQsvaEFlcIJf51uLAfLp+3LvEeHA0pp6x76Tzps3KF1TNg9esYuz7Hr8mNuTnrFwz//qAqCe78Tv3U7gLBUeo+qM9o4/9UARMvPzU3l/42974PITyEBE5XuebVQ7mubjgbDyXyxfqjPNe3sVpR3IWBuSRrRoq6kNjwPpiy4K8P1LdTQxfChv95ZkqQEOVdUReI2Rnw3QhVNjsjWS3zC4PIlnDkz9zfxaUTVO+G3ltd8Cx5ClbFQkQjOLFJPS/vvp39Bcifb6jbtiPUuB1bFRYwZF1RYy4OrIR598CQ+fa3x1w4ANRYqyuJKrXs3B6In1a6z6FqE9VjdXKLSvvLGyBmXlalx42ZaoJbc6++rWwZ0+Jpuk2A8/tUgG8eP1bW/xV5j5t5P5lpsPD+nMIeOXR6aHKLCta2fpH7uubzKe/zr3Z5fodMncbB0qWYBn6IoWpjtbxqU9UjaO6ZC6islqeeze09zU6X//NC5CGBUwXwwPV12XgokXl/HeWxG+oT6GvjYfcNVpPttRkGyybAwT9U2d2p0Wq9/DEVwvHyXyBmpqkLwD+mqDl+AAIj1HicjJTcOWXMv4v9Zqhy2nFT1JiOCwfU4G5z0BQ3BS4chIEfqOc68wuQo+vVRZneW5Ugt0dhAUP359T8NevfVRfL2+fnpsnZKm+PiH8ldT+iUW7QVNrPoc1QFTj987XqvTKnhC1/XgURwVFwy3v2p4p5QkGC0hj0kUol1UzqcWnSIPPKe9wyUlQv0ob/qbRyUKW4rxmuJi/esaB89dI5S97fobzFWPIG3UOGqi9a/v5CzWsFsPnj3G27P18xPishbCSBUwVwQ+Oq1KkSyOHzl1n49wlGdKpt3w6qNIChi9S8IgvuzV1+5l9IToCQQqr1CeFM5Wn+InvlvcA7tkGlzZrnnfEJUhXnrhkBPgHqcyipN2LId6powaYPc4sX7JivLi7RnPsFiHnMRJt7IbSGfc8t7PjpdOrLnOx02PSRKrbg5QvNBtm+X02DKg1V0HTlolq2f0XZP4fmt8FvE+H8XjixRRW32P0z/D0X0MGgDyGwcun3X96smamCJp1OfeZf3QYjfoFaHUu/z24T1ITA69/NXeYXCt2eU4GruXhBeeylcwZbg+6bXoOuE1Qv08Y5cOmYWq73zs1AEUIAUhyiQtDrddx/fR0APlt3GKOpFAPGdTr1Dwty51fZvRj+116NEago/4iEZyhP8xeVRvvRqqTzwT9yg6aGfWHCITUHkk9OlUxbKmzp9dDwJhj6Azy6Bdo/lLNBzt+BmPbOeQ8ntqjxJjoDXD+u5O1tpdNBn9dVT7hmgh8egL3LSn4eqB6wT3rC9yNygyZwTHnvDe/nljL/50u4dEINrgfV23J0fdn2X57kTbOcdAYq1VXp3l/eAsc3l26fJpMqWPTvj7nL9F4w4TB0HGNd8c2W3wthzS8EOo6F1jlfjuq91THzxAIkQriRBE4VxO3XVCcswJujF9JY9d8Z+3eQ9x/hyxeh3Si1PCMZlo6HT29S34wL4QrmCSfjpqgJHSnFxI6eKvEQfNortygLqAv7IfNV70pZVGmg0vgAy1TZX96qBtc7+ssP8wVXq8EqCHQkvR4GvKMmkDVlw3fDVZBZlHN74dsh8HlflU7nHagGxIPjynvrDbl/A3ctUgFdepJK0Tu2ofwH87bKPzbNyxfGrFfjyIyZMLe//RXa0pNh/pDc8XKgjpspWxVJEY6xegaszunFfum8Z1dvFMJNJHCqIAJ8vLi3Q00APl1z2L4nFzZI++ZZ0D3nWzuDj7oY+bAbfNJLfStY5H6kdLlwkG4ToMt4DH9OZ8C2+zD8Ob38B01HN8DHN6oxMT7Bapkj5+2x6glIgKhWann8VPj6NjVBqyOc+gf2L1e9012ecsw+89MbYOAcaDJAfT7f3AlH1lpvk3IaPuquesb3LlG9X23vUyWaj6xxbHnvbhPUeBBQ8+Qc26COXUpC+T8v7VFYmpy3P4zZAKExqvT7lwNt/6LtwkH1RcK+Zer4Qfkoy17eFFW9UT5jIaxI4FSBDO9YG2+Djk1HEtl+PMn2JxaVL979ObX82gdVFSPNqAag//kGLBptve3VkkIlPIfJqMrlAnrNiKb3Kt8Xp9sXqFSmK4kQFKkKQTjyAjH/hZG3Pzz0JzQeoNYfildzQh1ZV/b38qfqBaT5HVC5Xtn3VxSDF9z+GYTXU70PXw1SqWAZKRA3Fd5qntu70ai/ungPiVZjZJxxgdj9WajTLfexMbNiBU1QdJqcT6D6/Gu0Vz1xX94KZ/8rfl8HfoePe6iKhz5B6n+MXNg7R3HjwnpMknR8IXJIcYgKpFqIHwNaRbNo60k+XXuYdwe3se2Jtg4w3bsMlj4Dl46rgecJO+De71Tlq6shhUp4lhUvqEH9OXSmbJh7sxqAXp4muTSZVI+POQ2pSiNVYMDRFcGKujC652v1e7vzB0g9DV8MgNrXQ63OhQ8ML6n4xuldsOdXQAddx9vfTnt5+cAj6+B/HSDpqEoF8wvJHRsWUl1NOGsuSuDswgF3fAZv1Ac0x4ydupr4BqvpLL68VQW0X9wC9y1VKaR5aZqqmLfyRTWOrca1ENMhpxBEBS/44CzltXqjEC4mgVMFM+r6OizaepIlOxN4rm9josPsmL2+JI36qnED8dPUP71z/8HbLdS668bIH1/hOJs/hY3vA2BsciuHLmTR4OxSlX71fkcYHad6VDxd1hVVGc484L3zk2qiWEMhvWdlvUAs7sKo3xtw48uw5GlVce/wavWTfQV6Ts7drrA5n/JXOMwZc0bTW2H3T66pcGhOBftfB/XFjTloanabCmTyBtLOvkDc8hmWoKmiTrpaHL9QVaX1y1tUut5H3VXPp7lnMisdfn0Stn+rHrceqlLDixvfJ5+vEMJFJFWvgmkWHUqnepUxmjS+WH/E8S/gGwS9p8BDq7EMPgf460P48RE4f8DxrykqloNx6gIfoE43TLd9yu7q95Dd/x01pubcf/DuNWp8i6eIm1YwlSj1rOoh+/dHQA+3/g96xcINxcyb4syKYL5BMGgODHgXvPzUsrVvwc858y8VNgYCrCscntsL/y5Wy81zSbkqPdcnEB5Zn1v10+ADd37u2t7HvJ+RjMEpWkA4DPsJAqqo8WAfdYeLRyH5lCrgYQ6aGtwEt75X9qIoQgjhIBI4VUCjckqTz9t0jNSMbOe8yL7lgKZKmoLKTd8+D/53LSwcpXLbC7uYNMtfSMJZ24ry5dw++G4EoEG15jD8J8sqrfW9Kk3Pyw9STsHHN6h0UU+Qv3z6mX9V+05uUY/bDFHz0LibTgdtR8ADq9S4IYCtc2FymGp/jfaADjZ/oiY3PRgHDXuryXjjpsD39wE58yRt/sT16bl/zVGpXY4sqGErGVxvn8DKqpfQP1xVZ53TRQVQp7aq9a2HwL3fl6+0WyHEVU9S9SqgHo2qUrdKIIfOX+b7Lce5r3Mdx75A/gsI8+PKDeDCfti1UF10RTRSg37B+uKqsHQg84Wno7cV5cflCzDvTsi4BDHXwYifC15U1b5e9TrMu1uda5/1gds/gcb9HN8eeybhzTtG6fwB2LtUFX8A6PAI9J3u+PaVRWQLGB0Pvzye0yOWM+fTiU3qpyhn/1W35/e5Pmgq6u8OuKYdMumq/YKqqt/XDzqqebUyLqnl142BPvIFlxDC80jgVAGZJ8R9YfEuPl17iIbVgjmfmkHVYD/a1wnHoC/DN3xFfesKanm7UXD5LPz3S27QFDdFpWjc8IJKDdrwnqrUV/9GNWlkdjpEtlTjFeKmwKlt6lvufctVieFG/VWlrH++URfSoTGqUljcFPXNfqfH1YXqmpkFL2zsufh1Fk9og6fLzoAFQ9XcRmG14J5vik7fqVwPHlgJ349UleLmD4a6PWDYjwUDrbJ8vrYE6MkJkLBNnbMJ21RlsJ0Lcre9fpz1GCJP4hcCEU2AH9VEo6ZsNZFr5QbqIvfKRUhLVFUA0xLVZJlmri6KUNLfnbyPnUUG15dOSBQ8vFZVQDSPDZOgSQjhoSRwqqBuv6YGU5f+x4mL6dz7yV+W5VGhfrw8oCl9mkeVbse2fOt68yw4s1sFMrsWARr8/bn6Mdv8sfopzN4l6qeox3ntXqx+APzC1AXsH69B1aZQrRmgy72w6jQu93m2DILPy9kX4J7E1YGepsEvT8Kx9eAbAkO+yzOJaxH8K8G9C2HZs7DlUzgUBx92hQd+V1XYzG0tyzHOf2HeZpiqArbze6hcXxWwMK8rjMHHc4MmUO83fmrBHpx6N6pxJ3lpmvq9WjPTPUURpLenfNs2DymoIYQoDyRwqqBW7ztLWmbBi4nTl9J55OutfDD0mtIFT7Z+61qtqap21e05NfP7jvm563xD1cWtl5/qVch/eyhOXajpdNCgt7qPlnsLufcPxuUuS08qGGQZfFW6SNwUDEfWUd3UBP0vy2DHt3D9U9D1mdxtnRXg5L0AP7dPfYa7fnBtCXd7AgZXB3pr31Lj43QGNdi/amPbnmfwhv5vqpTQZc+qOZ9mt4U758KeX9R+iyp0AEW/N02DpGNqf8ZMNRYobop1kHQhpwiKTq/Ki0e3hug2cGYXbP3S8y8Q7e3B+fMN6x5dV6fJSW9P+eXuFEshhLCDBE4VkNGkEfvL7kLXaahaeLG/7KZX08iype3ZIqJhbhla88Vkp0eL/oe5egYc/CN32+ptbd+29RCIbKXGYZzZrQpUZF1W1c0A/eF42hGf+/y1s1TaYFA1CIxQt1Gt1T/1k3+r1MI9S62/lbeXMRsO/q5SCnUG2PW9+gGo1UmlK5pMoM+p42JPgOOsYKiwC+iiKq6VtXdq98/we6y63/d1qN+z6G0Lo9NBh4cgvC7MHwKXjsEnN6h1Xn4qhfPcHqhUR21T+3qV2ml+b12eht8mwqYP1TwyR9aoUvvpSUW9ILS6R50n0W0gsrmq9mZ+v1u/LB8XiPb04HhCmpwon+TcEUKUM24NnCZPnkxsbKzVskaNGrFnz54in/P999/z4osvcuTIERo0aMDrr79Ov35OGPh9Fdt0OJGES+lFrteAhEvpbDqcSMd6lZ3bGHu+bXTEtj3qwC2z1TYmk5ow8+xuOLMbLX4qOs2Ehg6dXwikX1IB16Xj6ievfb+pH1DjryrXU+M8AsLVspIChuRT4B0AO7/LnXMmv6PrVeW14GhV3KBx/5x9O6FIRt6LlczLcM1wFTRu+Qya36nGFW36WJUOzkhRP5Et1Pbx01Qls3b3q6AjL3vakP8zO/UPLBqt7te4Fi6fL/xzskWDXmqumPc7YumBzE5Xr3Hqn4Lb670L9iId/8t6fdXGENVKBd77V+QG6OF14bqHrfdX3i4Q7enBkTQ5UVpy7gghyhm39zg1a9aMVatWWR57eRXdpPXr1zN48GCmTZvGzTffzLx58xg4cCBbt26lefPmrmjuVeFsStFBU2m2KzV7Liadsa1eD+F11M+Zf9FpJow6Lwxatiqv3OlxVcgi9Ryknsn5OatuzZNcgkrZWni/Ssuq3lb1iqSehr/nWr926ln48WHVw5RXQBVoeZcqgLDl09wL8IjGcOmEKq29+RP14xsKVZup95GdATe+WHRvT973rGnQ/kGIm6rGjjW+WbV3yXhISVBzHqWcVsvWva1+zPL2ghVGM6nbLZ+p91y5fs4YsuZqHNl1Y2zrncobZLUZCt8OVhOwhteDE5vVnC5l8d8vWI2juPZBqNsNEg9D4iG4mHN76YR1oQNQZbijWqpAKbIlVG2i0kZXz4B/vi45mL+aLxAlTU6Ulpw7Qohyxu2Bk5eXF5GRkTZt+84779CnTx+eeUaNO3n11VdZuXIl7733HnPmzHFmM68qVYP9HLpdqdlzMemsbcFysWvs+hy/pjTl5uDdGPJe/IbVLLh93gvwmA6qB+bsbnWBf2Kz2s7LX11EH9+kUsb2r8QSbBl8oFFfaDVEpeOtfavwHrKuz0KNdrDnV5VWdvkcnM0p2btmpvox72/t22o/+cd86fQqnTB+au572POr+ilJlUZqYlTfYPXjE5x7/+TfaryZTq+CJy8/1Ytzfp/6MRflMLcvbooK3Mzz/JzdDT88qMYi6Q2qF6fGtWq7TR+p9xpQBRIPln2sV1E9kEFVC+43O1MVefhrjmqTKUv1WJXUqwlFB/NygSiEEEKUe24PnPbv3090dDR+fn507NiRadOmUbNmzUK33bBhA0899ZTVst69e7N48eIi95+RkUFGRoblcXJyMgBZWVlkZWUV9bRSM+/TGft2lDY1gokM8eVMcob5Mt6KDogM9aVNjWDnvo/rx6vbwl7DXOHOvM5J2+rXzMTw53SMXZ8j47onYOVKMq57Al/AEDcFo9GIqct4y9Pzbm/qMt768d3z0R38Hf2hP9AdjkeXkTNPz4GVluebgqPROj+JqekgVfkN0K/Os49O41TbOo1DbzTmLu/7JvSege7U3+j2LkW/dwm6i4dz35cxU/2UQAOo2hQtKBKCItGCrW91//2E4a//oRl80BkzMTYdZPX+rT6HQ3EFP4frxqLV7oru7G505/5Dd2Y3XNiHztK2nDPOHFwV5fI5Nd4u7bz151KIkn7nrI5R/s+30GP8Joa/5li/t8K2y86EwtqWs2+yMzF58N8BdysPfytFQXLcyic5buWTHDfXsOfz1WmaVti1s0ssW7aM1NRUGjVqREJCArGxsZw8eZJdu3YRHBxcYHsfHx+++OILBg8ebFn2/vvvExsby5kzZwp9jcLGUQHMmzePgIAAx72Zcmb7BR2f7cspOED+AhAa9zc00aqy204Nl2mUsAhNp2df5MAC6xqeXoxOM7E36jbL4yYJi/gv6jar7QtbrtOyqXT5IFWTd9LwzC/o0DDpDPzS+vMCr2NPGyzLExbT5PQiTDoDes3IwYibOBTRC3UsdWg58xVp6Kh7dgUNzi2zpCHmb39R78Oe91vccp2WTfMT86h7fhUm9OgxkRDShnMhzdBrRnSaEb1mQqdl5zw2Ue/sMvSo1MlfW39WoK32cNYxFkIIIUT5l5aWxpAhQ7h06RIhISHFbuvWwCm/pKQkatWqxaxZsxg1alSB9aUJnArrcYqJieH8+fMlfjilkZWVxcqVK+nVqxfe3t4O378jLf/3DK8t3cPp5Ayr5WH+XvzxVFeC/dzeIelSJR07/Z+vg85QZA8MmhFT12cLLDf8OT23ByenF6Msiu31yrdvW7e1Z7m9n4M97S3NZ+bI37nSHGNROuXpb6XIJcetfJLjVj7JcXON5ORkqlSpYlPg5FFXxmFhYTRs2JADBw4Uuj4yMrJAgHTmzJlix0j5+vri6+tbYLm3t7dTT0Jn798Rbm5dg74tq7PpcCJnU9IJ8/fmhcW7OH7xCu/8cZDYWytmwY0ij92NLwBgKOxJN0wsuG71DPhzOvSYhC5nXI0hbgoGQxHV9myRZ5+GbhPU690wEQyGgvu2Z1sd1tvlfV8GAwaTEYP5M7Hnc7CnDWX8zBzyO2fvMRZlVh7+VoqC5LiVT3Lcyic5bs5lz2frUYFTamoqBw8eZNiwYYWu79ixI7///jtPPvmkZdnKlSvp2LGji1p49THodVYlx6fd1pKhn/7FlxuPckvr6rStVcmNrSvHnFV+2llFMpxVvEDmAxJCCCHEVcKtgdP48eMZMGAAtWrV4tSpU7z88ssYDAZLKt7w4cOpXr0606ZNA+CJJ56gW7duvPnmm/Tv35/58+ezZcsWPvroI3e+javK9Q2qcEfbGiz8+wQTF+3g18e64OOlL/mJwpqzyk/bE+B4QiU3mQ9ICCGEEFcJtwZOJ06cYPDgwVy4cIGIiAiuv/56Nm7cSEREBADHjh1Dr8+9aO/UqRPz5s3jhRde4Pnnn6dBgwYsXrxY5nBysEn9mhC35yz7zqQyZ/VBHr+xgbubVP54QtBS3shnJoQQQggP5tbAaf78+cWuj4+PL7Dszjvv5M4773RSiwRApUAfXhrQlCfmb+O9Pw7Qr0UU9asGubtZQgghhBBCuI3kYIlC3dIqmh6NIsg0mpi4aAcmk8cUXxRCCCGEEMLlJHAShdLpdLw2qAUBPgY2H7nIt5uPubtJQgghhBBCuI0ETqJI1cP8GX9TIwCmL93DqaQrbDh4gZ+2nWTDwQsYpRdKCCGEEEJUEB5Vjlx4nhGdavPT9lNsP55Ej5nxZGSbLOuiQv14eUBT+jSPcmMLhRBCCCGEcD7pcRLFMuh1DGilAqO8QRPA6UvpPPL1Vn7bleCOpgkhhBBCCOEyEjiJYhlNGp+uOVzoOnOiXuwvuyVtTwghhBBCXNUkcBLF2nQ4kYRL6UWu14CES+lsOpzoukYJIYQQQgjhYhI4iWKdTSk6aCrNdkIIIYQQQpRHEjiJYlUN9nPodkIIIYQQQpRHEjiJYrWvE05UqB+6YraJCvWjfZ1wl7VJCCGEEEIIV5PASRTLoNfx8oCmAEUGTy/2b4pBX1xoJYQQQgghRPkmgZMoUZ/mUXww9BoiQwtPx/s34ZKLWySEEEIIIYRryQS4wiZ9mkfRq2kkmw4ncjYlnarBfpxJTufJBdv4X9xBWsdUolfTau5uphBCCCGEEE4hgZOwmUGvo2O9ylbLth1PYu76Izz13TZ+efR6alcJdFPrhBBCCCGEcB5J1RNl8ny/JrStVYmU9Gwe/vpvrmQa3d0kIYQQQgghHE4CJ1EmPl56/jfkGqoE+bDndAqTFu9E0zR3N0sIIYQQQgiHksBJlFlkqB/vDm6DXgeLtp7km7+OYTRpbDh4gZ+2nWTDwQsYTRJMCSGEEEKI8kvGOAmH6FSvChP6NGb6sj1M/vlf3lq5jwuXMy3ro0L9eHlAU/o0j3JjK4UQQgghhCgd6XESDvNQ17q0jgkl26RZBU0Apy+l88jXW/ltV4KbWieEEEIIIUTpSeAkHMakQcKl9ELXmRP1Yn/ZLWl7QgghhBCi3JHASTjMpsOJnEnOKHK9xv/bu/O4ps58f+CfhISwyCa7iGjdEFFcqBTRmVZcUEs3Z1pbbG07U39aam17e6+t1aJ37Oh0cew2tHWqnY5VO/bWrXUpddeqoIJiwR3FBURECDshOb8/aCJIyDmBhCTweb9evF5yzuHk8TwnzznfZ20IrNLzStovUUREREREFsDAiSymqNx4a1NrjyMiIiIishcMnMhiAjxcLHocEREREZG9YOBEFjOiV1cEe7lAZuKYYC8XjOjVtd3SRERERERkCQycyGKc5DKkJEYAQIvB02vj+sFJbiq0IiIie6TVCTiSV4JjxTIcySvhRD9E1OkwcCKLSogMRuq0YQjyatodz+m3WOk/R6+gtl5rg5QREVFrbT9VgFF/24VpK4/i63NOmLbyKEb9bReXmCCiToUL4JLFJUQGY1xEENLzSlBUXoMADxf4uCnxx88OIePSbbzxf9lY9ngUZDK2PBER2bvtpwowa/Vx3N2+pF+fL3XaMC5uTkSdAlucyCqc5DLE9vbFw0NCENvbF+HBnvjHtGFwksuwIfMaPt513tZJJCIiEVqdgEVbcpoFTQDX5yOizoeBE7Wb0X39sfiRSADAsrSz2JR1zcYpIiIiU9LzSlpc2Bzg+nxE1LkwcKJ29eSIHpjxu3sAAP+9/iSOXmoYYHzowi1syrqGQxduseaSiMhOcH0+IqI7OMaJ2t3chHBcKq7ETzk38OyqDLgqnXCzotawP9jLBSmJEewzT0RkY1yfj4joDrY4UbtzksuwfOoQhHZ1RUVtfZOgCbgz4JizNRER2daIXl0R5NlyUCQD1+cjos6DgRPZhErhhFqNzug+DjgmIrIPTnIZxkUEmDwmJTGC6/MRUafAwIlsomGq8toW93PAMRGR7alrNNh2qhAA4OHStHe/m7MTpyInok6FgRPZBAccExHZv092nUdxRR3u8XNH+ryxWP18NOK7NfQWcHaSYUx4oI1TSETUfuwmcFq6dClkMhleeeUVk8ctX74c/fv3h6urK0JDQ/Hqq6+ipoYv146GA46JiOxbXnElVh3MAwAseDACrs5OiOnVFZN76ODfxRml1fXYe/amjVNJRNR+7CJwysjIwOeff47BgwebPG7NmjV44403kJKSgtzcXHz55Zf49ttvMW/evHZKKVnKiF5dEezlAlO94n3dnTngmIjIRt75MQcarYD7+/vjgfA745ycZEDi4IbueRsyr9oqeURE7c7mgVNFRQWSkpKwYsUK+Pj4mDz2l19+QVxcHJ566in07NkT48ePx5NPPon09PR2Si1ZipNchpTECABoMXgqq9bgx2zOrEdE1N72nb2Jn3OLoJDLMH9yRLP9Dw9pCJx+zi1CWbWmvZNHBABcB5Lanc3XcUpOTsbkyZMxduxYLF682OSxI0eOxOrVq5Geno4RI0bg4sWL2Lp1K55++ukW/6a2tha1tXcmIVCr1QAAjUYDjcbyhb3+nNY4d0cT398PH0+NwuKtp1GovpNHQZ4qBHiocPKaGi+vzUR+cQVmjO4JmUwGrU7A0cu3UVReiwAPFaLDfCw2mxPzzjEx3xwT881+1Wt1+N8tvwIApsWEIsxH1Sy/+vi6oF9AF5wtqsCWrKt4Irq7zdJL4jri923HrzeMvj/MnxSOCQM7xti7jphv9sic6ysTBMFm4fm6devwzjvvICMjAy4uLrj//vsxZMgQLF++vMW/+eijj/D6669DEATU19dj5syZSE1NbfH4hQsXYtGiRc22r1mzBm5ubpb4b1Ab6QTggloGtQbwVAK9PRtuyU2X5dhT0NAoOjJAh37eAjZekqO07k6g5O0s4LGeOkT5spaJiMgS9hXI8H+XnOCuEDB/qBZuLVSx7rwmw+Z8J/T2EPBypLZ9E0md2olbMqw8q+801bjytOFd4Pl+fC8g6aqqqvDUU0+hrKwMnp6eJo+1WeB05coVREdHIy0tzTC2SSxw2rNnD6ZOnYrFixcjJiYG58+fx5w5c/DCCy9gwYIFRv/GWItTaGgoiouLRS9Oa2g0GqSlpWHcuHFQKpUWP39n8/XhfCzeehot3aX64vLjqVFtrmFi3jkm5ptjYr7Zp9tVdRi3/ADKquuxKHEAnhoR2mR/43wrrtLi9x/sgyAAu18bje4+rjZKNYnpSN83rU7A/R/sa9LS1JgMQJCXCrtf+53Dry/WkfLNnqnVavj5+UkKnGzWVe/YsWMoKirCsGHDDNu0Wi327duHTz75BLW1tXBycmryNwsWLMDTTz+NP//5zwCAQYMGobKyEjNmzMBbb70Fubz5kC2VSgWVStVsu1KptOpNaO3zdxZ/Gt0bId5umPnNcaP7BTQUku9sO4OJg0MsUkgy7xwT880xMd/sy6d7zqCsuh7hQR5Iuq8nFE7Gh0IrlUr08HPDyN6+OHj+Fn7IvoHZ8X3bObVkro7wfTt64VaLQROgXweyFplXyxHb27f9EmZFHSHf7Jk519Zmk0PEx8cjOzsbWVlZhp/o6GgkJSUhKyurWdAENDSl3R0c6Y+zYY9DsjIvN2eT+7lYLhFR250pLMfqI/kAgLcfjGgxaGrs0aENY5s2ZF7jc5jaBdeBJFuyWYuTh4cHIiMjm2xzd3eHr6+vYfszzzyDkJAQLFmyBACQmJiIZcuWYejQoYauegsWLEBiYqLRQIs6BhaSRETWodUJSM8rQZG6Biv2X4RWJyBhYBBG9vGT9PcJkUGYvzEbF4srceJqGYaEels3wdTpBXg070Vk/DiuA0mWZ/NZ9UzJz89v0sI0f/58yGQyzJ8/H9euXYO/vz8SExPxzjvv2DCVZG1cLJeIyPK2nyrAoi05KChrWukUJzFoAoAuKgUmDAzCpqzr2HD8KgMnsipBEHDgfLHJYxrGOLlwHUiyCrsKnPbs2WPyd4VCgZSUFKSkpLRfosjm9IvlFpbVoKWOIP4eKhaSREQSbT9VgFmrjxstU9/edAr+Hs5IiAyWdK5Hh4ZgU9Z1bDlZgPkPRkApoYsfkbkEQcD7P53Bp7svGLbJgGb3sAAgJTHC4SeGIPvE0o3snpTFcsurNUjLKWy/RBEROSitTsCiLTktVkQBwKItOZIXEx3Vxw9+XVQoqazD3jM3LZNIokYEQcC7O+4ETQsejMBn04YhyKt5TxP/Ls4YE94x1nEi+8PAiRxCQmQwUo0UkoEeKvT2d0dNvQ4zVx/H4h9yoNHqAHBFcSIiY9LzSpp1z2vM3Al3FE5yPBTVDUDDJBFEbXH3s7teq8PS7aeRuqchaEpJjMCfRvVCQmQwDswdg7Uv3IcPpw7BqmfvhV8XZ9ysqMM3Ry7b+H9BHZVdddUjMiUhMhjjIoIaBjKX1yDAo6EPs04Q8O7201ixPw//PJCHrCulmDK8Oz7aea7Jy0GwlwtSEiMkdz8hIuqIrDHhzmPDQrDyYB7Scm+grFoDL1dOnUzmMzbuzt3ZCZV1DQss/+/DA/FMbE/DPie5rMmU46+N6495G7Lx0c5zeGxYd96HZHFscSKHoi8kHx4SgtjevnCSy6B0kuOtyQ3N9h4qBY5evo03v89uVqNaWFaDWauPY/upAhulnojI9qwx4c7Abp7oG9AFdfU6bMtmGUvm04+7u/vZrQ+apt4b2iRoMubx6O7oE9AFt6s0+GzvBZPHErUGAyfqMBIig7EhOQ6KFgaE6jvqmdN3n4ioo9FPuNPSmFEZGlrozZlwRyaT4dFhIQCA79ldj8wkZdzd3rM3RZ/dCic53kgIBwCsPJCH66XVFkwlEQMn6mBultei3kTBysVyiaiz00+4Y6yk1AdTrZmV7JEhIZDJGsZQXSmpanM6qfMQG3cHSH92xw8IQEyvrqit1+GDn85aKolEABg4UQfDxXKJiMQlRAYjxkiLUpCXC1KnDWvVWNBu3q64r1fDeJNNWWx1Iuks+eyWyWSYN2kAAOD7zKvIua5uU9qIGmPgRB2K1D75KkXTW1+rE3AkrwTHimU4klfCrnxE1KHVa3U4c6McALBg8gB8OHUI1r5wHw7MHdOmCXQad9cTBJajJI2lx91FhXojMaobBAFYsi23LUkjaoKz6lGHImWxXAB47dssnL1RgT+P7oV9Z282msXHCV+fO8oZ+IioQzt6+TZKqzTwdlNi+sieUFho0dqJkUFYsPEULt6sxDdH8uHhojDMgMoFSaklYs9uGRpaQ80Zd/c/E/pj+6kC7D9XjH1nb+J3/fwtll7qvNjiRB2KqcVy9b+H+bqhSqPDsrSziF2yEzONzOLDGfiIqCNLy7kBABjTP8BiQRMAeLgoMSjECwAwf+MpzFmXhSdXHMaov+1ieUotssa4u9CuboZZ+P66NZc9ScgiGDhRh9PSYrlBXi74bNow7P6v+/HRk0MR4u2Csup6o+fgDHxE1FEJgmAInMZFBFr03NtPFeDo5dvNtrMyisQkRAZjYmRQs+1tGXc3e0wfeLoocLqwnIszk0Wwqx51SC0tlquvrXooqhu8XRV4ZmVGi+doPANf4wX2tDqhxfMSEdm7szcqkF9SBWeF3KLdl/RTShsjoKHlYNGWHIyLCGKZSc0IgoDcgoaJHGaP6YM+AV3a/Iz1dnNG8gN9sGTbaby/4zT8PZxRWqXhs5tajYETdVh3ryh+t9tVGknnSb90CzG9ukIulxld1ZzjoYjIkaTlFAIA4nr7wl1ludcAsSmlW6qMIgKAX6+rcelWFVyUcsz8fW+L3ZvTR/bE53svolBdi+mNKkv57KbWYFc96rSkzs7z97RzGLl0F55blc7xUETk8O5002veLaotuBwEtcUPJxueoWPCAywa0O85U4SSqrpm2/nsptZg4ESdln4WH1MN9S5KOdyUchSqa7D7zE2jx3A8FBE5ihvqGpy4WgYAGDsgwKLntvSU0tR5CIKAH7OvAwAmD+pmsfOKdR8F+Owm8zBwok5LbAY+GYDlTwzB8bfH4/Xx/Uyeq3EXFCIie6VvbRoS6o0AT8sGMFIqo4I8VWZNKU2dw8mrZbhSUg1XpRPGhFsuoDen+yiRFAycqFMzNQOffhYfF6UTQru6STpfkbppAa3VCTh04RY2ZV3DoQu3WKtFRDZlrdn0ANOVUXoKuRy3Kmst/tnk2H7MbuguFz8gAK7OThY7L7uPkqVxcgjq9PQz8B06X4Sf9h/B+NExiO0T0GS2HaldSz5IOwu5XIZJg4KRllPIiSSIyG5U1Nbj0IVbAIDxVgicgDuVUXeXfX5dnFFbr8PV0mr8IfUQ/v2nEQjzdbdKGsixCIKAH38b3/TgYMt10wOkP7v9u6gs+rnUcTFwIkJDTWlMr664lSsgxsgUpWKrmgMNNaz5JVWYvTYTf/khB0XlzWtV9YNRW7smBRFRa+09cxN1Wh16+rqhT0AXq31OS8tBXCmpwjMr05FfUoUpqb/gq+dGIDLEi0s8dHKZV0pxrbQa7s5OuL+/5abHB6Q9uwHgs70X0DfQA/4eDKDINAZORBLou6DMWn0cMqBJAax/vL/3h8G4WlqNVQfzjAZNANcyISLb0U9DPi4iEDKZdcseY8tB9PRzx3ezYjF9ZQZyC9SY+sVh/Hl0L3ybcYUt853YDycaWpvGRQTCRWm5bnqA+LNbAKCQy7DvXDEmfrgP7/8xCvf3D2AwTy1i4EQkUUtdUILueshHdffGc19xYV0ish8arQ67ThcBsPw05OYI8HDBt//vPrzwr6M4kleC5T+fa3YMW+Y7D51OwNbfxjdNtnA3PT2xZ3dv/y6YvTYTpwvL8eyqDIwJD0DO9TIUqu9UgDKYJz0GTkRmaKkLSuMAR10jbWHd/eduGv6WC+sSkTVl5JVAXVOPru7OGB7mY9O0eLoosfLZezHsL2mordc122+qZd6cCiZWRtm/Y/m3UaiugYdKgd/187Pa54g9uzcmx2HpttP46pdLhgqGxhjMkx4DJyIzGeuC0pjUwaj/2HMB649dRWSIJ3afbr5GFAtqIrKUn36bTW9MeIBdBA8nr5YZDZr0jLXMm1PBxMoox6CfFGLcwECoFJbtpnc3U89uF6UTFjwYgU1Z13C7qnnlJ7vZkx6nIyeyMClrmbg5O8HLVYGb5bVGgybA9OJ8nOaciKQSBMGq05C3htTpn7/NyEfWlVL8cPI6Zq0+3mxNHn0F0/ZTBYZt208VSD6WbEerEwzTkCdaqZueOdLzSowGTXotrfnE53HnwhYnIguTMpHEssejMCY8EP/cfwHv7jjb4rnaWusKsLsKUWeXW1COa6XVUCnkGN3Xet2hzCG1ZX5j1nVszLre4n59+TpvwynIIYNGq8NbG08ZnUGNrQb2JeNSCW6W18LLVYm4Pra/L6UG8/88cBH+Hs7oE+DBls1OiIETkRVInUgixEfawrrfZuSjl587sq7cxqzVx5u9FLTUrY+FOhHpW5tG9/WDm7N9PPalTBPt4aLAvWE+OJJXgso6rcnzlVTWYcbqY6Kf29LkPNT+fjjZEBBPGBgIZ4XtO0BJDeZ35hZhZ24RwnzdcPlWVbP97GbfsdlHCUrUAUmZSMLcWldnJ5nkmlR9dxWpQRYRdUxpuXemIbcXUpd4SIgMxsbMa3jl2yzRc/bo6gaFXIaLxZWix0ptXSDrqNfqsC274b601mx65hIL5mUAvN2UGNbDB7vPFBkNmgC2bHZ0tg/xiTow/WDUh4eEILa3b4sL65oqVj1dFYgO8wYA1Glb7jutr0ndkHkVN8trsXBzTotBFsCxU0SdwfXSapy6poZMBowJt5/ACbjTMh/k1bQCKcjLpUnFTqCntAqmv00ZjHceHSTp2MMXb6FGc6cVi2Vf+zqSV4JblXXwcVNipJ20/OmDeQDNnsn635c8NghfPnsv/pE0zOS5WhoPZQ6tTsCRvBIcK5bhSF4J70k7wRYnIhuSUuv67pSGWtevfsnDws05oud8ff1J0WMsMXaKiOzfz7kN3fSG9fCBv4fKxqlpTkrLvJSWgCCvhr8DINoFEADWpl/BvrPFeH1CP6icnPCXH1n2tSd9N72EyCAoneynDl9qN3tTM0I21tqWzabPYyd8fe4o70k7wcCJyMakFtT9Az0lnc9NKUeVRlqhvjY9HwonGQpKqzFnXRa79RF1MPY2m54xYks8SKlgSkmMMARbYsc+ExuGn3Ju4FppNV799oTRz2TZZz0arQ7bTzV003vQTrrpNWbJbvbVd43NkzJZU2u62XMSqPbDwInIDliy1vXA3DE4dKEY075MF/3czSeuY/MJ0zNWWWIhSnJMzGPHpq7R4PDFWwDsO3CSQmoFk9Rj35w0ACv2X8Syn86aPQMfF+Ftm18u3MLtKg183Z0R81srob0RC+alTG4CAPM2ZOPCzQq8MrYf9p+7KdqrQ6sTsGhLy93sjd2T9tJbpLPc6wyciOyEJWtdY3v7iRbqni4K3HdPVxzJu42yamlrV3BKdPtkjetrLw9jc/A+a2rPmZvQaAXc4++O3v5dbJ2cNpNSwST1WBelE6LDupp86b1T9t1CbO+G6bK5CG/b/fhbN72Jg4KgsKNueuYQex4LAIb18Mbx/FKs2J+H745dNbpG1N2tSOl5Jc3WH2tMf0/+cr4Yo/v5280kUJ3pXmfgRORApNa6Sho79duMVZsyr2GOhBmr1h+9gjBfN5y8WmrVKdGt9fLraC/VUtNrjetrLw9jqenVp7kjP7hbc/86Qjc9c4lVMJlzrNTxJzO+PoYHwgPg5arAvw/nN9tv7HthT92tGk8y4JtXgtg+ATYr++rq73TTmzzI/rrpmUPK83j36SLM35iNa6XG7zX9/fE/353EtuwCHJE4mcTTK9MR4OGM21Uam69ZZk/3entg4ETkYKTWukoNsgIkzlj1feY1fJ95DUorTonemiBAyguBo71US02vNa5va7qK6P/OVq1e9hTomcOawfEv54uR9mvDC2q8nc2mZy+kjlMpr60X7dIMAG9+nw2lXA6VUo63Npi3CK+1KpjsbZKBg+eLoa6ph7+HyjCZhyMTex4/EB6Avz46CNNXZZg8j7qmHptOFJj12UXldSb3t8eaZY7ctbC1GDgROSCpta6WGDsFNHTr6x/ogYzLt6GRMCX6y2uPI8zXHV8futxOQVbLLwT2VBtmydYecx9YUs47YWAQtp8qkNRVxNozMlrrOujZumWzPYPjl9dmYuFDjvFS0p6kjBsN9HLBsj9G4btjV/B9ZsvBEwDcrtLgT18fFf3cu7sAWquCydoVCq0Z6/WPPecBAAkDAx2mhUGM2PO41ERX+MYmRQbhsWEhmLfhFG6W15ocy7wxOQ7/ybiCD9LOip7XmmuWSe1auPt0EcZGBDpsJVdjDJyIOjhLjJ3Sd+v79+FLWLDxV9HP/PG3hQ1N0ReoM/59FPf29MHney9aPMjS1OuQsvlXO6z5NX5esSAAAOZvPAV3ZwWO59+W9MBadTAP9/bsigUbW74OADB7bSZUCjkqarVGjmru7z+fxfmb3VBVW4+l206bHZiaaimUch3++7uTSMu5gZNXS60e6NkqGLJUcHxD7TgvJe1JStm3MDECI/v44WZFrWjgBAChPq7QaHUoVNeKHjvj38cQe09XHLpYYvGyT6sTTK7l19ZuXG0d67U1uxBxffw6xf0otWXz6dieiO3ti3qdIDqWOdDTBdE9pbXYOclaH6CKlX3Z10olnefPXx9FiLcLiivqbN61sK1kgiDYxYpaS5cuxZtvvok5c+Zg+fLlLR5XWlqKt956C99//z1KSkoQFhaG5cuXY9KkSZI+R61Ww8vLC2VlZfD0lDa9szk0Gg22bt2KSZMmQalUWvz8ZD2dPe+kPAgPXbiFJ1ccFj3Xg4ODoa7WYN+5Youm8b57uiLE2xXbThWiqq7lF3wnuQyeLgqUttD/+24fPzkUDw4Oxo5fC42+lOiLcEvX/DY+74SBQfjxZAFeWpspIcXWI5cBllpnsfFMj+YEplLvM3N083JB4pBucFU64cOfz9kkj/UvtKP+tstksOftqsSs+3vj1+tqk13E9CZGBqG3vzv+degyymvqjR5jLC9aoyOWk5a8J9e+cB8AWPz+ffq+MIQHe+C97WdMtmC4KOToF+SBq7erUFIp3tKx9oX7mlSstaVV3Nh3yJxjOyr9d17KjLjmlJNi59VzVcrx3xPCMX1kTzjJZW2uCHr7wQh4uirxz/0XsfvMzdZcEpPuvifbgzmxgV0EThkZGXj88cfh6emJBx54oMXAqa6uDnFxcQgICMC8efMQEhKCy5cvw9vbG1FRUZI+i4ETtYR5J/7QNOcBkJ5XIunl4dGh3XD5VhWO55da7P/RGr7uSlTUaltc2PDuh5slX5SdneRwdZajrNr4S+/dgjxV8HJV4syNCtFju3m7oKK2HmoJ556b0B/TR/ZE/Ad7TT6MfdyUeCqmB/advYnsa2rR8ybFhCIhMhgFZTWY+91Jo9dMAPBQVDCqNTocybslKb2TIoPQJ7ALPtp5XvRYKVqbx+pqDeI/2IubFS23MqgUckR190JRRS0uFVdZJL2t0daXko5aTlqy7AMgemyglws+fGII1qTnY1OWeHBsLQsmD8CfRt8DwLyXdVPlWYCHChuT4+Akl+Ghjw/gRrnx74WlgnlHoC9LAOOtSC21zB86X4Sf9h/B+NExRsfwmjqvAKC3vzsu3KwEAAzu7oUHBwVj1S+XWl0RZIxKIRd9bv4wexRWHczDJ7sviJ7vw6lD8PCQEAmfbDnmxAY276pXUVGBpKQkrFixAosXLzZ57MqVK1FSUoJffvnFUGD37NmzHVJJ1DlYckp0qetOvf/HIZKDrOmxYSip1GDLSfEXjbkJ/RHm644XvzkueqxcBtwSqZ3Vd/lK/PgAgr1UOHjhlsmuZK9+ewKbs66jUF1j8iUDAOq0OtRV6yS39vz9iaEY0aurpBe5/f8jPYgdEuoDN2eFaB4veWwQEiKD0S/QA3PWZYme95sjV/DNkSst7td/xmYzB0c/HdsTI3p1xfqjV01ehwBPFd5ICMf3mdew30QrqD6Pf/fuLoR4u+LktTKTeZy8JhPOTlmolrDgdG29DumXbkv4XzWIDvOGbxcVdvx6Q/TYxKhuuF1ZhwPnxVt4rTnewZG19yK8CxMjEHOPL3QCJAVOcb19UVatwanr4hUVfxrVC7383DF/4ynRY//yYy72nL2JiG6e+MJId+nGXQBH9fXHuvR80fKsqLwWI5fuEv3s9pi8wF6Ysw6ZnpNchpheXXErV0CMiWn3TZ13fEQQ1mbkY+m20zh5tQwnr5Y1O4c5XYQbm3ZfD/x51D04Xag2GRSmJEbAt4sKcX38JQVOUrs22orNA6fk5GRMnjwZY8eOFQ2cNm/ejNjYWCQnJ2PTpk3w9/fHU089hblz58LJycno39TW1qK29k5th1rdUOhoNBpoNNIG7JlDf05rnJusi3knTXx/P3w8NQqLt55u0o8/yEuFtyaGI76/n+EavjWxP2avO9Hiy8NbE/tDp63H0O4eCPJU4Yba1IBYFd5M6Iejl29LCpwGdfNAdJiPpPNumx2HlQcv4yMJhXpOgRo5Et7vqzVabD0lPtZL77WxfTA9NgwTPjwgmt6h3T2g09Zb/PoO7e4BjUYjOY993aQ9Qu7t6YP8kirckDDuI2lEKCZFBuK19dkoMjlAWvp1WDApHBMGBkIQdCYDJ71rpTUtTh/cmFYnoNqMfo1P3xeKQA8V3k8TbyF7Jb4PosN8cP8H+0Tz7b3HBuLo5duSAidfN0WbyrjOXE6aU/ZJPVbqd/PLZ4bh6OXbmLZSfPKJB/r5IjrMB5/sOtfieYE7LQX7zxW3+L3Q/+1LazJRb8a9LpMBUvszFZRWQqOxfA8gexPf3w/39x2No5dvo6i8FgEeKkSH+cBJLmvx+yTl+2bqvFptPR4f1g2je3fF+OUHUGOkZUifTXPWZSE86DxuqGsljdFLiAhAiJczQrwse6/rn0PtyZzPs2lXvXXr1uGdd95BRkYGXFxccP/992PIkCEtdtULDw/HpUuXkJSUhBdffBHnz5/Hiy++iJdffhkpKSlG/2bhwoVYtGhRs+1r1qyBm5ubJf87RJ2KTgAuqGVQawBPJdDbU4Cx3hYnbsnw/SU5Suvu7PR2FvBYTx2ifIUmx608q18MsfGJGo55vl/D8ToBWHTcCaV1dx9353hvZyBlmBZymfTzniuT4ZMc4xUwjU0I0aJMI8PhIvGFG0f46eCuFLC7QPy8L0Vo0ddLkJxePUtf38bE8ticvMi8JcPX58SvwzN9tRjuZ53rIDWPH+6hRUmdDPsLxfP4kTAtAl2Bz09Ly+PenoJV7l9zvxfUelLLPqnH2rLsC3EX8GO+HMdvSVuItotCQEW9+A30UoQWggB8miu97CPrkVr2mUNfVutZ8l5vb1VVVXjqqafse4zTlStXEB0djbS0NAwePBgARAOnfv36oaamBnl5eYYWpmXLluG9995DQYHxKmBjLU6hoaEoLi622hintLQ0jBs3rkP1/+4MmHfWo9UJRmvD7rbj1xvNaq2Cf6u1mjAwsMlxs9edAGC8heHjqVHNjhc7r1YnSKrd3/3a7yTX/K5+Plpyq8Hu135nuCZSr4Oepa+vOaTmxZG8EsnXLOa39V0sfR3sJY+tcf/qjzPnvK3BctI6bFn2bTlZgNfWZ4umceGDAzD13u6S73UAZpd91JSlvm9S8/j5kWHo5u2CxVvPiB7buKw2hzWeQ22lVqvh5+dn32Ocjh07hqKiIgwbNsywTavVYt++ffjkk09QW1vbrPtdcHAwlEplk+0DBgxAYWEh6urq4Ozs3OxzVCoVVCpVs+1KpdKqhb61z0/Ww7yzPCWAUf3EC8QHh3THxMEhojP+PDikOxQKJ8n9xaWcVwlg4UMDRcYwDISLyhmxfQIkjd/SD+aVel5zr0PjtFvy+ppDal6Ye81ak16x62AveWyN+7c1520LlpOWZe2yz9QkA8He7pLS2D/YCy4qZ7PudXPLPjKurd83qXk8bmAwRvTqii8PXjarrDaHNZ5DbWXOtbVZ4BQfH4/s7KbR73PPPYfw8PAWxyzFxcVhzZo10Ol0kMsbmvrOnj2L4OBgo0ETETkecxf3FZt1yJzzSh3Aa+5A8dYODLbGgGlrnFfKQsvmXjNrpdde8ljKNWvMkotek32yVh6LTTIgdSKfEb+1Lphzr7em7CPLMyePW1tWm8Naz7f2YBfTkevd3VXvmWeeQUhICJYsWQKgoXvfwIEDMX36dMyePRvnzp3D888/j5dffhlvvfWWpM/gdOTUEuadY7JGvll6wVNzz9uRmXvNrIV53DosJx2TWL61drpsqfd6R/9eWIslv2/m5rG9lNXtwaGmIzclPz/f0LIEAKGhodixYwdeffVVDB48GCEhIZgzZw7mzp1rw1QSUUdjzZpfR61lsxRzWwqthXlMdIe1W8X5vbA9a7eKdxZ2FTjt2bPH5O8AEBsbi8OHLbsiNxFRa/GFwHxS1iexJ8xj6gz4otzxsSKo7ewqcCIiIiIi2+CLcsfHPG4baRP3ExERERERdWIMnIiIiIiIiEQwcCIiIiIiIhLBwImIiIiIiEgEAyciIiIiIiIRDJyIiIiIiIhEMHAiIiIiIiISwcCJiIiIiIhIBAMnIiIiIiIiEQyciIiIiIiIRChsnYD2JggCAECtVlvl/BqNBlVVVVCr1VAqlVb5DLIO5p1jYr45JuabY2K+OSbmm2NivrUPfUygjxFM6XSBU3l5OQAgNDTUxikhIiIiIiJ7UF5eDi8vL5PHyAQp4VUHotPpcP36dXh4eEAmk1n8/Gq1GqGhobhy5Qo8PT0tfn6yHuadY2K+OSbmm2Nivjkm5ptjYr61D0EQUF5ejm7dukEuNz2KqdO1OMnlcnTv3t3qn+Pp6cmb3EEx7xwT880xMd8cE/PNMTHfHBPzzfrEWpr0ODkEERERERGRCAZOREREREREIhg4WZhKpUJKSgpUKpWtk0JmYt45JuabY2K+OSbmm2Nivjkm5pv96XSTQxAREREREZmLLU5EREREREQiGDgRERERERGJYOBEREREREQkgoETERERERGRCAZOFvbpp5+iZ8+ecHFxQUxMDNLT022dJGpk3759SExMRLdu3SCTybBx48Ym+wVBwNtvv43g4GC4urpi7NixOHfunG0SSwZLlizBvffeCw8PDwQEBOCRRx7BmTNnmhxTU1OD5ORk+Pr6okuXLpgyZQpu3LhhoxQTAKSmpmLw4MGGxRtjY2Oxbds2w37mmWNYunQpZDIZXnnlFcM25p39WbhwIWQyWZOf8PBww37mmf26du0apk2bBl9fX7i6umLQoEE4evSoYT/fTewHAycL+vbbb/Haa68hJSUFx48fR1RUFCZMmICioiJbJ41+U1lZiaioKHz66adG97/77rv46KOP8Nlnn+HIkSNwd3fHhAkTUFNT084ppcb27t2L5ORkHD58GGlpadBoNBg/fjwqKysNx7z66qvYsmUL1q9fj7179+L69et47LHHbJhq6t69O5YuXYpjx47h6NGjGDNmDB5++GH8+uuvAJhnjiAjIwOff/45Bg8e3GQ7884+DRw4EAUFBYafAwcOGPYxz+zT7du3ERcXB6VSiW3btiEnJwcffPABfHx8DMfw3cSOCGQxI0aMEJKTkw2/a7VaoVu3bsKSJUtsmCpqCQBhw4YNht91Op0QFBQkvPfee4ZtpaWlgkqlEtauXWuDFFJLioqKBADC3r17BUFoyCelUimsX7/ecExubq4AQDh06JCtkklG+Pj4CP/85z+ZZw6gvLxc6Nu3r5CWlib8/ve/F+bMmSMIAr9v9iolJUWIiooyuo95Zr/mzp0rjBo1qsX9fDexL2xxspC6ujocO3YMY8eONWyTy+UYO3YsDh06ZMOUkVR5eXkoLCxskodeXl6IiYlhHtqZsrIyAEDXrl0BAMeOHYNGo2mSd+Hh4ejRowfzzk5otVqsW7cOlZWViI2NZZ45gOTkZEyePLlJHgH8vtmzc+fOoVu3brjnnnuQlJSE/Px8AMwze7Z582ZER0fjj3/8IwICAjB06FCsWLHCsJ/vJvaFgZOFFBcXQ6vVIjAwsMn2wMBAFBYW2ihVZA59PjEP7ZtOp8Mrr7yCuLg4REZGAmjIO2dnZ3h7ezc5lnlne9nZ2ejSpQtUKhVmzpyJDRs2ICIignlm59atW4fjx49jyZIlzfYx7+xTTEwMvvrqK2zfvh2pqanIy8vD6NGjUV5ezjyzYxcvXkRqair69u2LHTt2YNasWXj55Zfxr3/9CwDfTeyNwtYJICIyR3JyMk6dOtWk7z7Zr/79+yMrKwtlZWX47rvvMH36dOzdu9fWySITrly5gjlz5iAtLQ0uLi62Tg5JNHHiRMO/Bw8ejJiYGISFheE///kPXF1dbZgyMkWn0yE6Ohp//etfAQBDhw7FqVOn8Nlnn2H69Ok2Th3djS1OFuLn5wcnJ6dmM9TcuHEDQUFBNkoVmUOfT8xD+/XSSy/hhx9+wO7du9G9e3fD9qCgINTV1aG0tLTJ8cw723N2dkafPn0wfPhwLFmyBFFRUfjwww+ZZ3bs2LFjKCoqwrBhw6BQKKBQKLB371589NFHUCgUCAwMZN45AG9vb/Tr1w/nz5/n982OBQcHIyIiosm2AQMGGLpZ8t3EvjBwshBnZ2cMHz4cO3fuNGzT6XTYuXMnYmNjbZgykqpXr14ICgpqkodqtRpHjhxhHtqYIAh46aWXsGHDBuzatQu9evVqsn/48OFQKpVN8u7MmTPIz89n3tkZnU6H2tpa5pkdi4+PR3Z2NrKysgw/0dHRSEpKMvybeWf/KioqcOHCBQQHB/P7Zsfi4uKaLa9x9uxZhIWFAeC7id2x9ewUHcm6desElUolfPXVV0JOTo4wY8YMwdvbWygsLLR10ug35eXlQmZmppCZmSkAEJYtWyZkZmYKly9fFgRBEJYuXSp4e3sLmzZtEk6ePCk8/PDDQq9evYTq6mobp7xzmzVrluDl5SXs2bNHKCgoMPxUVVUZjpk5c6bQo0cPYdeuXcLRo0eF2NhYITY21oappjfeeEPYu3evkJeXJ5w8eVJ44403BJlMJvz000+CIDDPHEnjWfUEgXlnj/7rv/5L2LNnj5CXlyccPHhQGDt2rODn5ycUFRUJgsA8s1fp6emCQqEQ3nnnHeHcuXPCN998I7i5uQmrV682HMN3E/vBwMnCPv74Y6FHjx6Cs7OzMGLECOHw4cO2ThI1snv3bgFAs5/p06cLgtAw7eeCBQuEwMBAQaVSCfHx8cKZM2dsm2gymmcAhFWrVhmOqa6uFl588UXBx8dHcHNzEx599FGhoKDAdokm4fnnnxfCwsIEZ2dnwd/fX4iPjzcETYLAPHMkdwdOzDv788QTTwjBwcGCs7OzEBISIjzxxBPC+fPnDfuZZ/Zry5YtQmRkpKBSqYTw8HDhiy++aLKf7yb2QyYIgmCbti4iIiIiIiLHwDFOREREREREIhg4ERERERERiWDgREREREREJIKBExERERERkQgGTkRERERERCIYOBEREREREYlg4ERERERERCSCgRMREREREZEIBk5EREQmyGQybNy40dbJICIiG2PgREREduvZZ5+FTCZr9pOQkGDrpBERUSejsHUCiIiITElISMCqVauabFOpVDZKDRERdVZscSIiIrumUqkQFBTU5MfHxwdAQze61NRUTJw4Ea6urrjnnnvw3XffNfn77OxsjBkzBq6urvD19cWMGTNQUVHR5JiVK1di4MCBUKlUCA4OxksvvdRkf3FxMR599FG4ubmhb9++2Lx5s2Hf7du3kZSUBH9/f7i6uqJv377NAj0iInJ8DJyIiMihLViwAFOmTMGJEyeQlJSEqVOnIjc3FwBQWVmJCRMmwMfHBxkZGVi/fj1+/vnnJoFRamoqkpOTMWPGDGRnZ2Pz5s3o06dPk89YtGgRHn/8cZw8eRKTJk1CUlISSkpKDJ+fk5ODbdu2ITc3F6mpqfDz82u/C0BERO1CJgiCYOtEEBERGfPss89i9erVcHFxabJ93rx5mDdvHmQyGWbOnInU1FTDvvvuuw/Dhg3DP/7xD6xYsQJz587FlStX4O7uDgDYunUrEhMTcf36dQQGBiIkJATPPfccFi9ebDQNMpkM8+fPx1/+8hcADcFYly5dsG3bNiQkJOChhx6Cn58fVq5caaWrQERE9oBjnIiIyK498MADTQIjAOjatavh37GxsU32xcbGIisrCwCQm5uLqKgoQ9AEAHFxcdDpdDhz5gxkMhmuX7+O+Ph4k2kYPHiw4d/u7u7w9PREUVERAGDWrFmYMmUKjh8/jvHjx+ORRx7ByJEjW/V/JSIi+8XAiYiI7Jq7u3uzrnOW4urqKuk4pVLZ5HeZTAadTgcAmDhxIi5fvoytW7ciLS0N8fHxSE5Oxvvvv2/x9BIRke1wjBMRETm0w4cPN/t9wIABAIABAwbgxIkTqKysNOw/ePAg5HI5+vfvDw8PD/Ts2RM7d+5sUxr8/f0xffp0rF69GsuXL8cXX3zRpvMREZH9YYsTERHZtdraWhQWFjbZplAoDBMwrF+/HtHR0Rg1ahS++eYbpKen48svvwQAJCUlISUlBdOnT8fChQtx8+ZNzJ49G08//TQCAwMBAAsXLsTMmTMREBCAiRMnory8HAcPHsTs2bMlpe/tt9/G8OHDMXDgQNTW1uKHH34wBG5ERNRxMHAiIiK7tn37dgQHBzfZ1r9/f5w+fRpAw4x369atw4svvojg4GCsXbsWERERAAA3Nzfs2LEDc+bMwb333gs3NzdMmTIFy5YtM5xr+vTpqKmpwd///ne8/vrr8PPzwx/+8AfJ6XN2dsabb76JS5cuwdXVFaNHj8a6dess8D8nIiJ7wln1iIjIYclkMmzYsAGPPPKIrZNCREQdHMc4ERERERERiWDgREREREREJIJjnIiIyGGxtzkREbUXtjgRERERERGJYOBEREREREQkgoETERERERGRCAZOREREREREIhg4ERERERERiWDgREREREREJIKBExERERERkQgGTkRERERERCL+P1s4zBAKu3hUAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs = list(range(1, 66))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, tr_loss, label='Training Loss', marker='o')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss', marker='x')\n",
        "plt.title('Training and Validation Losses Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjBThPABtwwp"
      },
      "outputs": [],
      "source": [
        "save_path = save_base_path + '{}_{}_{}.cp'.format(RUNNAME, 'final_model', '96_iterations')\n",
        "torch.save(net,save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krgj0fikuR1L"
      },
      "outputs": [],
      "source": [
        "save_path = save_base_path + '{}_{}_{}.cp'.format(RUNNAME, 'entire_model', '101_iterations')\n",
        "\n",
        "\n",
        "torch.save({'epoch': epoch,\n",
        "            'model_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'lr': lr}, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lfOedG6qEYO"
      },
      "source": [
        "## 6. Look at outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeuVbA-BqF8V"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def visualize_segmentation_example_multilabel(net, test_data_loader):\n",
        "    net.eval()  # Ensure the model is in evaluation mode.\n",
        "    net.cuda()  # Ensure the model operates on the GPU.\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for efficiency.\n",
        "        # Iterating over the test dataset to get a single batch.\n",
        "        for images, labels in tqdm(test_data_loader):\n",
        "\n",
        "            images = images.cuda()\n",
        "\n",
        "            # separate it out into the three labels\n",
        "            label_built = labels[:, 0, :, :].unsqueeze(1)  # dimension as [batch_size, 1, height, width]\n",
        "            label_pop = labels[:, 1, :, :].unsqueeze(1) # dimension as [batch_size, 1, height, width]\n",
        "            label_lc = labels[:, 2, :, :] # dimension as [batch_size, height, width], i.e. removed the single dimension as cross entropy expects [batch size, height, width]\n",
        "\n",
        "            # move them to GPU\n",
        "            label_built = label_built.cuda()\n",
        "            label_pop = label_pop.cuda()\n",
        "            label_lc = label_lc.cuda()\n",
        "\n",
        "            # Obtain the model's predictions.\n",
        "            outputs = net(images) # [6, 25, 256, 256]\n",
        "            outputs_built, outputs_pop, outputs_lc = process_outputs(outputs) # built & pop: [6, 1, 256, 256], lc: [6, 23, 256, 256]\n",
        "\n",
        "            # Assuming the outputs of the classification task are raw logits, apply softmax to obtain probabilities.\n",
        "            probs_lc = torch.softmax(outputs_lc, dim=1)\n",
        "\n",
        "            # Convert probabilities to predicted class labels.\n",
        "            predicted_masks_lc = torch.argmax(probs_lc, dim=1)\n",
        "\n",
        "            # Move the tensors to the CPU for visualization.\n",
        "            images, label_built, label_pop, label_lc, predicted_masks_lc = images.cpu(), label_built.cpu(), label_pop.cpu(), label_lc.cpu(), predicted_masks_lc.cpu()\n",
        "\n",
        "            # Convert the first image and masks to PIL images for easy visualization.\n",
        "            original_image_band1 = to_pil_image(images[0][0])\n",
        "            original_image_band2 = to_pil_image(images[0][1])\n",
        "            true_mask_built = to_pil_image(label_built[0].float())  # Adding channel dimension for compatibility.\n",
        "            true_mask_pop = to_pil_image(label_pop[0].float())  # Adding channel dimension for compatibility.\n",
        "            true_mask_lc = to_pil_image(label_lc[0].unsqueeze(0).float())  # Adding channel dimension for compatibility. # this could be an error, maybe leave the unsqueeze part away\n",
        "\n",
        "            predicted_mask_built = to_pil_image(outputs_built[0])\n",
        "            predicted_mask_pop = to_pil_image(outputs_pop[0])\n",
        "            predicted_mask_lc = to_pil_image(predicted_masks_lc[0].unsqueeze(0).byte())\n",
        "\n",
        "            # Visualization\n",
        "            fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "            ax[0,0].imshow(original_image_band1)\n",
        "            ax[0,0].set_title('Original Image Band 1')\n",
        "            ax[0,0].axis('off')\n",
        "\n",
        "            ax[1,0].imshow(original_image_band2) # second row, first column\n",
        "            ax[1,0].set_title('Original Image Band 2')\n",
        "            ax[1,0].axis('off')\n",
        "\n",
        "            ax[0,1].imshow(true_mask_built)\n",
        "            ax[0,1].set_title('True Mask BUILT')\n",
        "            ax[0,1].axis('off')\n",
        "\n",
        "            ax[1,1].imshow(predicted_mask_built)\n",
        "            ax[1,1].set_title('Predicted Mask BUILT')\n",
        "            ax[1,1].axis('off')\n",
        "\n",
        "            ax[0,2].imshow(true_mask_pop)\n",
        "            ax[0,2].set_title('True Mask POP')\n",
        "            ax[0,2].axis('off')\n",
        "\n",
        "            ax[1,2].imshow(predicted_mask_pop)\n",
        "            ax[1,2].set_title('Predicted Mask POP')\n",
        "            ax[1,2].axis('off')\n",
        "\n",
        "            ax[0,3].imshow(true_mask_lc)\n",
        "            ax[0,3].set_title('True Mask LC')\n",
        "            ax[0,3].axis('off')\n",
        "\n",
        "            ax[1,3].imshow(predicted_mask_lc)\n",
        "            ax[1,3].set_title('Predicted Mask LC')\n",
        "            ax[1,3].axis('off')\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            # Break after the first batch to only visualize one example.\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlUT_vTSwVfs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOhx3+sJsOe8pAUoq2XhNh8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}